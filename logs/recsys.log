2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.131 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:19.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.148 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.156 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.160 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.179 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:19.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.209 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.211 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.238 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:19.271 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.273 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.277 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.281 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.292 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.299 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.303 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.316 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.322 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.327 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.336 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.339 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:49:19.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.348 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.356 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.363 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.370 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.372 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.385 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.387 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.390 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.402 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.409 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.411 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.418 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.423 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.425 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:19.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.433 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.437 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.443 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.445 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.451 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.453 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.455 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.458 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.459 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.465 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.472 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.475 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.477 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.484 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:49:19.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.502 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.504 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.506 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.509 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.511 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.518 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.521 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.534 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.540 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.541 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.543 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.551 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.560 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.566 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:49:19.568 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.570 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.574 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.576 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.577 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.583 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.588 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.591 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.595 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.597 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.607 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.609 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.611 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:49:19.612 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.614 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.617 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.621 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.623 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.625 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.627 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.628 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.634 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.636 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.638 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.640 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.642 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.646 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.652 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:49:19.660 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.662 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.665 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.668 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.672 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.674 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.677 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.679 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.681 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.683 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.685 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.686 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.688 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.690 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:49:19.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.700 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.703 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.705 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:49:19.712 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.714 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.716 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.724 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:49:19.737 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.749 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:49:19.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:50:26.248 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 13:50:26.624 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:26.722 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:27.267 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 13:50:27.504 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 13:50:27.511 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 13:50:27.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 13:50:27.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 13:50:27.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 13:50:27.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 13:50:27.517 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 13:50:27.546 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:50:27.569 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:50:27.583 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa059f, negotiated timeout = 40000
2016-12-14 13:50:27.706 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:28.852 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 13:50:28.864 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 13:50:28.875 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 13:50:28.882 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 13:50:28.884 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 13:50:28.885 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 13:50:28.885 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 13:50:28.920 [main] INFO  org.apache.hadoop.http.HttpServer2 - HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:8089
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:963) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:900) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	at com.wankun.logcount.spark.LogStream.openHBase(LogStream.java:63) [classes/:na]
	at com.wankun.logcount.spark.LogStream.main(LogStream.java:90) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_45]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_45]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_45]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_45]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147) [idea_rt.jar:na]
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_45]
	at sun.nio.ch.Net.bind(Net.java:437) ~[na:1.8.0_45]
	at sun.nio.ch.Net.bind(Net.java:429) ~[na:1.8.0_45]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_45]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_45]
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216) ~[jetty-6.1.26.hwx.jar:6.1.26.hwx]
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:958) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	... 8 common frames omitted
2016-12-14 13:50:28.921 [main] ERROR com.wankun.logcount.spark.LogStream - 建立HBase 连接失败
java.net.BindException: Port in use: 0.0.0.0:8089
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:963) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:900) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	at com.wankun.logcount.spark.LogStream.openHBase(LogStream.java:63) ~[classes/:na]
	at com.wankun.logcount.spark.LogStream.main(LogStream.java:90) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_45]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_45]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_45]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_45]
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147) [idea_rt.jar:na]
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_45]
	at sun.nio.ch.Net.bind(Net.java:437) ~[na:1.8.0_45]
	at sun.nio.ch.Net.bind(Net.java:429) ~[na:1.8.0_45]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_45]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_45]
	at org.mortbay.jetty.nio.SelectChannelConnector.open(SelectChannelConnector.java:216) ~[jetty-6.1.26.hwx.jar:6.1.26.hwx]
	at org.apache.hadoop.http.HttpServer2.openListeners(HttpServer2.java:958) ~[hadoop-common-2.7.3.2.5.0.0-1245.jar:na]
	... 8 common frames omitted
2016-12-14 13:50:57.235 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 13:50:57.665 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:57.712 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:58.257 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 13:50:58.511 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 13:50:58.518 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 13:50:58.519 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 13:50:58.520 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 13:50:58.521 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 13:50:58.549 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:50:58.572 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:50:58.583 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a1, negotiated timeout = 40000
2016-12-14 13:50:58.672 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:50:59.901 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 13:50:59.912 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 13:50:59.919 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 13:50:59.924 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 13:50:59.926 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 13:50:59.926 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 13:50:59.926 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 13:50:59.938 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 13:50:59.938 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 13:51:00.302 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 13:51:00.595 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 13:51:00.642 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 13:51:00.643 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 13:51:00.643 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 13:51:01.161 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59788.
2016-12-14 13:51:01.604 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 13:51:01.656 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 13:51:01.832 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:59789]
2016-12-14 13:51:01.843 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 59789.
2016-12-14 13:51:01.857 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 13:51:01.879 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 13:51:01.896 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-d3800926-4aca-4a6d-b7a0-b5f64a953a83
2016-12-14 13:51:01.907 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 13:51:01.969 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 13:51:02.165 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 13:51:02.211 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 13:51:02.212 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 13:51:02.213 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 13:51:02.319 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 13:51:02.340 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59790.
2016-12-14 13:51:02.341 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 59790
2016-12-14 13:51:02.342 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 13:51:02.345 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:59790 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 59790)
2016-12-14 13:51:02.348 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 13:51:51.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.655 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.661 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.666 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:51.681 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.685 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.758 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.764 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:51.776 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.780 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:51.784 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.788 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:51.793 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.797 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.801 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.805 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.809 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.812 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:51.816 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.820 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.826 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.831 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:51.836 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.841 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.845 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.854 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:51.860 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.866 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.875 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.879 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:51.883 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.888 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:51.894 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.901 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.907 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.914 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:51.918 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.922 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:51.928 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.931 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:51.935 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.948 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:51.955 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.968 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:51.982 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:51.987 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:51.994 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:51:)
)
2016-12-14 13:51:52.006 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.010 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.016 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.020 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.023 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.026 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.029 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:52.032 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.036 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.039 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.042 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.045 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.052 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.055 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.057 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:52.061 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.064 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.074 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.087 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.106 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:52.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:52.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.204 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.231 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.252 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.264 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:52.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.275 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.288 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.297 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.306 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:52.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.336 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.347 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.354 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.357 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.362 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.365 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.373 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.391 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.395 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.399 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.401 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.408 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.411 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.419 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.423 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.428 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.430 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.433 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:52.435 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.436 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.449 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.451 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.454 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.458 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.462 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.464 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.466 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.468 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.475 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.477 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.481 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.483 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.490 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.492 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.494 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.496 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.504 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.506 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.510 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:52.520 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.524 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.535 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.539 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.542 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.544 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.546 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.549 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.552 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.553 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.557 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.565 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.571 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.573 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.581 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.584 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.586 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.589 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.605 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.609 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.612 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.616 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.620 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.623 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:52.629 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.631 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.634 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.636 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.646 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.648 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.651 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.653 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.656 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.661 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.663 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.667 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.706 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.713 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.719 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.734 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.740 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.745 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.747 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.750 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.759 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.762 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.764 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.767 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.784 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.787 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.790 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:52.796 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.798 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.802 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.807 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.809 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.812 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.815 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.817 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.820 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.822 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.825 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.828 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.830 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.832 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.834 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.836 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.838 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.840 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.843 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.845 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.847 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.849 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.852 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.864 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.867 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.869 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.871 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.873 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.876 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.886 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.888 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.890 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:52.892 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.894 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.897 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.904 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.906 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.912 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.918 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.921 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:52.923 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.925 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.937 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.949 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:52.959 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.963 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:52.965 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:52.972 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:52.988 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:52:)
)
2016-12-14 13:51:53.015 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.018 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.029 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.031 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.033 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.035 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.037 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.040 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.042 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.044 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.046 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.048 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.050 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.052 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.054 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:53.058 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.060 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.062 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.067 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.072 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.074 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.078 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.082 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.087 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.094 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.096 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:53.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.152 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:53.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.226 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.231 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.238 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.262 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.264 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.268 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:53.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.317 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.332 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.337 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.339 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.343 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.345 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.347 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.349 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.352 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.356 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.359 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.362 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.367 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.369 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.373 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.378 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:53.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.385 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.388 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.390 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.392 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.397 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.401 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.403 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.408 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.410 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.412 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.419 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.422 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.424 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.427 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.432 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.434 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.435 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.437 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.442 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.444 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.445 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:53.447 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.450 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.453 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.457 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.458 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.460 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.464 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.466 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.471 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.473 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.476 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.478 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.481 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.483 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.485 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.488 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.492 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.494 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:53.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.503 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.505 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.507 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.510 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.512 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.515 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.517 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.518 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.520 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.522 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.526 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.528 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.529 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.531 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.535 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.539 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.540 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.542 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.544 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.545 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.546 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.548 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.549 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.553 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.556 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.559 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.561 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.565 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.567 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.570 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.572 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.574 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.575 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.577 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.580 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.582 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.583 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.587 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.588 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.590 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.592 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.594 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.595 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.597 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.600 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.603 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.605 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.606 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.608 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.610 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.613 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.615 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.131 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:53.617 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.619 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.620 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.622 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.624 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.627 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.630 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.632 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.633 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.635 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.637 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.638 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.640 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.642 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.645 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.646 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.648 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.650 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.651 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.653 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.148 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.655 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.658 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.660 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.661 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.663 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.664 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.666 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.668 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.669 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.672 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.156 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.674 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.677 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.678 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.160 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.683 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.684 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.686 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.688 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.690 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.692 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.693 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.695 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.696 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.699 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.701 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.703 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.704 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.706 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.710 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.712 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.713 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.715 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.716 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.179 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.717 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.719 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.721 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.722 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.723 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.725 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.726 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.728 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:53.730 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.732 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.733 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.742 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.744 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.746 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.748 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.750 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.752 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.754 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.756 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.760 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.761 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.763 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.764 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.766 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.767 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.769 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.209 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.770 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.772 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.211 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.779 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.783 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.785 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.787 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.789 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.791 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.793 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.794 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.796 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.797 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.799 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.800 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.804 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.808 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.810 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.811 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.813 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.815 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.817 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.819 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.238 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.824 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.826 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.827 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.829 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.833 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.836 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.838 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.839 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.841 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.843 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.845 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.846 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.850 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.863 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.864 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.866 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.867 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.869 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.870 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.871 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.873 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.874 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.876 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.878 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:53.880 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.882 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.271 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.884 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.885 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.273 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.887 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.888 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.277 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.890 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.892 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.893 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.895 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.281 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.897 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.898 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.900 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.901 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.902 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.904 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.905 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.907 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.909 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.910 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.292 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.912 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.913 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.915 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.916 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.918 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.919 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.920 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.922 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.299 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.923 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.925 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.927 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.928 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.303 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:53.929 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.931 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.932 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.933 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.935 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.936 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.937 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.939 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.940 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.945 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.947 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.949 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.316 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.950 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.952 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.954 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.956 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.322 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:53.957 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.959 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.963 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.964 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.327 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.966 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.967 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.969 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.971 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:53.972 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.974 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.976 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.978 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.336 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.981 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.982 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.339 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.984 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.985 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 13:51:53.988 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.990 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:53.991 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.993 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:53.995 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:)
)
2016-12-14 13:51:53.998 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:53:2016-12-14 13:49:19.348 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.000 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.001 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.356 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.003 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.005 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.363 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.006 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.008 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.011 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.012 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.013 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.015 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.370 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.016 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.026 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.372 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.027 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.028 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.030 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.032 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.033 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.034 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.037 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.040 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.385 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.041 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.043 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.387 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.045 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.046 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.390 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.048 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.051 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:54.053 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.054 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.056 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.057 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.058 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.060 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.402 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.061 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.064 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.066 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.067 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.069 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.071 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.409 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.072 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.074 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.411 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.077 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.080 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.082 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.418 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.094 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.423 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.425 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:54.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.106 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.433 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.437 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.113 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.121 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.443 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.445 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.131 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.451 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.453 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.455 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.458 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.148 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.459 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:54.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.465 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.160 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.170 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.472 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.475 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.477 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.188 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.194 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.484 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.196 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.198 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.211 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 13:51:54.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.219 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.502 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.235 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.240 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.504 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.506 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.246 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.509 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.252 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.511 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.256 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.262 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.518 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.275 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.521 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.277 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.281 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:54.284 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.288 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.297 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.534 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.303 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.540 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.308 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.541 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.312 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.543 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.316 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.551 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.319 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.321 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.322 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.325 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.327 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.560 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.332 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.334 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.566 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 13:51:54.336 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.337 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.568 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.340 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.570 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.342 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.574 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.345 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.576 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.577 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.352 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.354 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.355 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.357 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.583 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.359 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.360 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.588 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.362 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.591 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.367 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.370 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.595 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.373 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.375 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.597 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.378 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.380 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.382 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.607 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.385 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.609 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.388 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.611 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 13:51:54.391 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.393 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.612 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.614 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.399 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.401 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.617 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.403 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.621 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.407 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.623 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.409 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.625 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.627 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.418 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.628 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.422 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.423 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.634 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.428 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.636 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.638 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.433 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.435 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.640 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.436 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.642 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.443 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.445 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.446 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.646 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.450 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.652 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 13:51:54.454 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.660 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.457 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.459 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.662 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.665 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.668 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.472 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.476 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.672 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.481 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.674 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.483 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.485 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.488 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.677 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.679 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.681 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.496 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.498 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.683 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.685 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.503 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.505 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.686 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.507 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.509 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.688 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.511 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.512 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.690 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 13:51:54.514 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.517 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.520 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.700 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.522 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.703 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.529 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.705 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.534 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.536 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.539 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.540 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.542 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 13:51:54.544 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.546 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.712 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.549 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.550 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.714 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.552 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.554 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.716 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.556 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.724 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 13:51:54.560 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.737 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.567 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.749 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.570 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.571 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:49:19.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 13:51:54.573 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:)
)
2016-12-14 13:51:54.575 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:26.248 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
)
2016-12-14 13:51:54.580 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:26.624 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
)
2016-12-14 13:51:54.587 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:26.722 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
)
2016-12-14 13:51:54.589 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.267 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
)
2016-12-14 13:51:54.591 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.504 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
)
2016-12-14 13:51:54.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.511 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
)
2016-12-14 13:51:54.596 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
)
2016-12-14 13:51:54.598 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
)
2016-12-14 13:51:54.600 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
)
2016-12-14 13:51:54.603 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:51:54:2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
)
2016-12-14 13:52:08.842 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 13:52:08.864 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 13:52:08.865 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 13:52:08.865 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 13:52:08.865 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 13:52:08.866 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 13:52:08.866 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 13:52:08.867 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 13:52:08.867 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 13:52:08.867 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 13:52:08.867 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 13:52:08.868 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 13:52:08.868 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 13:52:08.868 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 13:52:08.868 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 13:52:08.869 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 13:52:08.869 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 13:52:08.869 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 13:52:08.869 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 13:52:08.870 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 13:52:08.870 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 13:52:08.870 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 13:52:08.871 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 13:52:08.871 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 13:52:08.871 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 13:52:08.871 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 13:52:08.924 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 13:52:08.941 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 13:52:08.952 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 13:52:08.953 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 13:52:08.954 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 13:52:08.959 [dispatcher-event-loop-0] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 13:52:08.966 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 13:52:08.968 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 13:52:08.969 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-6d55d075-9ef4-4be0-8bb0-881f43900cd2
2016-12-14 13:52:08.987 [sparkDriverActorSystem-akka.actor.default-dispatcher-14] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 13:52:08.987 [sparkDriverActorSystem-akka.actor.default-dispatcher-14] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 13:52:19.647 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 13:52:20.124 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:52:20.171 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:52:20.723 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 13:52:21.061 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 13:52:21.085 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 13:52:21.086 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 13:52:21.086 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 13:52:21.086 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 13:52:21.086 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 13:52:21.086 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 13:52:21.087 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 13:52:21.088 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 13:52:21.088 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 13:52:21.088 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 13:52:21.101 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 13:52:21.145 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:52:21.173 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:52:21.186 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a3, negotiated timeout = 40000
2016-12-14 13:52:21.419 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:52:22.898 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 13:52:22.911 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 13:52:22.920 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 13:52:22.925 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 13:52:22.928 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 13:52:22.928 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 13:52:22.928 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 13:52:22.942 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 13:52:22.942 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 13:52:23.464 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 13:52:23.873 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 13:52:23.983 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 13:52:23.984 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 13:52:23.985 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 13:52:24.709 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59854.
2016-12-14 13:52:25.245 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 13:52:25.302 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 13:52:25.496 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:59855]
2016-12-14 13:52:25.503 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 59855.
2016-12-14 13:52:25.520 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 13:52:25.536 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 13:52:25.550 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-b39610ac-0ced-4851-a851-95ecfdb4ce1a
2016-12-14 13:52:25.561 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 13:52:25.618 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 13:52:25.838 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 13:52:25.896 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 13:52:25.897 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 13:52:25.900 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 13:52:26.020 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 13:52:26.050 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59856.
2016-12-14 13:52:26.051 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 59856
2016-12-14 13:52:26.053 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 13:52:26.057 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:59856 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 59856)
2016-12-14 13:52:26.060 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 13:55:59.749 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 13:55:59.769 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 13:55:59.769 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 13:55:59.770 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 13:55:59.770 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 13:55:59.771 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 13:55:59.771 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 13:55:59.772 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 13:55:59.772 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 13:55:59.772 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 13:55:59.773 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 13:55:59.773 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 13:55:59.773 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 13:55:59.774 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 13:55:59.774 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 13:55:59.775 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 13:55:59.775 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 13:55:59.776 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 13:55:59.776 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 13:55:59.776 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 13:55:59.777 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 13:55:59.777 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 13:55:59.777 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 13:55:59.777 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 13:55:59.778 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 13:55:59.778 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 13:55:59.831 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 13:55:59.842 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 13:55:59.853 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 13:55:59.855 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 13:55:59.856 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 13:55:59.860 [dispatcher-event-loop-0] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 13:55:59.864 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 13:55:59.867 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 13:55:59.868 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-efce9576-c198-4a93-8c38-3a81cc31b8a2
2016-12-14 13:55:59.875 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 13:55:59.880 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 13:58:40.095 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 13:58:40.929 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:41.036 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:41.511 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 13:58:41.760 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x655ef322 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 13:58:41.776 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 13:58:41.777 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 13:58:41.777 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 13:58:41.777 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 13:58:41.777 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 13:58:41.777 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 13:58:41.778 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 13:58:41.780 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 13:58:41.780 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 13:58:41.780 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 13:58:41.780 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 13:58:41.781 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 13:58:41.781 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 13:58:41.781 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 13:58:41.781 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 13:58:41.783 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@2974f221
2016-12-14 13:58:41.828 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:58:41.858 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:58:41.872 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a5, negotiated timeout = 40000
2016-12-14 13:58:41.996 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:43.320 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 13:58:43.338 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 13:58:43.350 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 13:58:43.360 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 13:58:43.364 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 13:58:43.364 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 13:58:43.364 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 13:58:43.387 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 13:58:43.387 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 13:58:43.811 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 13:58:44.280 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 13:58:44.349 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 13:58:44.350 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 13:58:44.351 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 13:58:45.122 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60107.
2016-12-14 13:58:45.711 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 13:58:45.785 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 13:58:46.052 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60108]
2016-12-14 13:58:46.061 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60108.
2016-12-14 13:58:46.081 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 13:58:46.106 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 13:58:46.124 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-6619b14f-bb63-4b21-9449-a32a11442e3c
2016-12-14 13:58:46.139 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 13:58:46.211 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 13:58:46.386 [pool-2-thread-1] INFO  o.a.spark.storage.DiskBlockManager - Shutdown hook called
2016-12-14 13:58:46.390 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 13:58:46.392 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-50a4e1f9-c8f2-4b62-83fc-be4eda8a5dcf
2016-12-14 13:58:46.393 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-50a4e1f9-c8f2-4b62-83fc-be4eda8a5dcf/userFiles-9f72012b-614b-4711-b42a-0c359c6982b1
2016-12-14 13:58:52.987 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 13:58:53.438 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:53.570 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:54.088 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 13:58:54.322 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 13:58:54.329 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 13:58:54.330 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 13:58:54.330 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 13:58:54.331 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 13:58:54.332 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 13:58:54.335 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 13:58:54.360 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:58:54.375 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:58:54.383 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a6, negotiated timeout = 40000
2016-12-14 13:58:54.437 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 13:58:55.464 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 13:58:55.474 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 13:58:55.480 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 13:58:55.484 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 13:58:55.486 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 13:58:55.486 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 13:58:55.486 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 13:58:55.497 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 13:58:55.497 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 13:58:55.870 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 13:58:56.248 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 13:58:56.299 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 13:58:56.300 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 13:58:56.301 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 13:58:56.813 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60120.
2016-12-14 13:58:57.273 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 13:58:57.345 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 13:58:57.525 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60121]
2016-12-14 13:58:57.533 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60121.
2016-12-14 13:58:57.548 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 13:58:57.569 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 13:58:57.586 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-f5f48e27-1170-49df-bf56-8e77064433b0
2016-12-14 13:58:57.596 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 13:58:57.681 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 13:58:57.946 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 13:58:58.008 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 13:58:58.009 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 13:58:58.013 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 13:58:58.109 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 13:58:58.136 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60122.
2016-12-14 13:58:58.138 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60122
2016-12-14 13:58:58.139 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 13:58:58.142 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60122 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60122)
2016-12-14 13:58:58.146 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 13:58:58.896 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 13:58:58.897 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 13:58:58.904 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 13:58:58.905 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 13:58:58.905 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 13:58:58.906 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 13:58:58.907 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 13:58:58.907 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@105a1fee
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 13:58:58.908 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@21d22d71
2016-12-14 13:58:58.980 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695139000
2016-12-14 13:58:58.981 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695139000 ms
2016-12-14 13:58:58.981 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 13:58:58.990 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 13:58:59.010 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 13:58:59.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 13:58:59.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 13:58:59.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 13:58:59.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 13:58:59.074 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 13:58:59.078 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695139000 ms
2016-12-14 13:58:59.088 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695139000 ms.0 from job set of time 1481695139000 ms
2016-12-14 13:58:59.095 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695139000 ms.0 from job set of time 1481695139000 ms
2016-12-14 13:58:59.096 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.089 s for time 1481695139000 ms (execution: 0.009 s)
2016-12-14 13:58:59.105 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 13:58:59.107 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 13:58:59.217 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 13:58:59.229 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 13:58:59.232 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60122 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 13:58:59.235 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 13:58:59.239 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 13:58:59.241 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 13:58:59.287 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 13:58:59.298 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 13:58:59.384 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695139400
2016-12-14 13:58:59.385 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 13:58:59.385 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 13:58:59.395 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60120
2016-12-14 13:58:59.396 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 13:58:59.398 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 13:58:59.399 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 13:58:59.451 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@5eed8157
2016-12-14 13:58:59.452 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 13:58:59.452 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 13:58:59.456 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a7, negotiated timeout = 6000
2016-12-14 13:58:59.472 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 13:58:59.732 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 13:58:59.732 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 13:58:59.732 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 13:58:59.733 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 13:58:59.734 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 13:59:00.028 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695140000 ms
2016-12-14 13:59:00.029 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695140000 ms.0 from job set of time 1481695140000 ms
2016-12-14 13:59:00.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695140000 ms.0 from job set of time 1481695140000 ms
2016-12-14 13:59:00.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.030 s for time 1481695140000 ms (execution: 0.002 s)
2016-12-14 13:59:00.031 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 13:59:00.046 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695140000 ms
2016-12-14 13:59:00.046 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 13:59:00.047 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 13:59:00.047 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 13:59:00.397 [Thread-23] INFO  org.apache.spark.storage.MemoryStore - Block input-0-1481695140000 stored as bytes in memory (estimated size 227.6 KB, free 329.7 KB)
2016-12-14 13:59:00.398 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added input-0-1481695140000 in memory on localhost:60122 (size: 227.6 KB, free: 1140.1 MB)
2016-12-14 13:59:00.401 [Thread-23] WARN  o.apache.spark.storage.BlockManager - Block input-0-1481695140000 replicated to only 0 peer(s) instead of 1 peers
2016-12-14 13:59:00.408 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushed block input-0-1481695140000
2016-12-14 13:59:01.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695141000 ms
2016-12-14 13:59:01.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695141000 ms.0 from job set of time 1481695141000 ms
2016-12-14 13:59:01.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: print at LogStream.java:102
2016-12-14 13:59:01.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (print at LogStream.java:102) with 1 output partitions
2016-12-14 13:59:01.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (print at LogStream.java:102)
2016-12-14 13:59:01.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 13:59:01.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 13:59:01.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (BlockRDD[3] at createStream at LogStream.java:100), which has no missing parents
2016-12-14 13:59:01.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 1104.0 B, free 330.8 KB)
2016-12-14 13:59:01.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 741.0 B, free 331.5 KB)
2016-12-14 13:59:01.026 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:60122 (size: 741.0 B, free: 1140.1 MB)
2016-12-14 13:59:01.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1008
2016-12-14 13:59:01.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (BlockRDD[3] at createStream at LogStream.java:100)
2016-12-14 13:59:01.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2016-12-14 13:59:01.031 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 2017 bytes)
2016-12-14 13:59:01.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 13:59:01.036 [Executor task launch worker-1] INFO  o.apache.spark.storage.BlockManager - Found block input-0-1481695140000 locally
2016-12-14 13:59:01.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2567 bytes result sent to driver
2016-12-14 13:59:01.049 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 18 ms on localhost (1/1)
2016-12-14 13:59:01.050 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 13:59:01.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (print at LogStream.java:102) finished in 0.021 s
2016-12-14 13:59:01.055 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: print at LogStream.java:102, took 0.036846 s
2016-12-14 13:59:01.057 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695141000 ms.0 from job set of time 1481695141000 ms
2016-12-14 13:59:01.057 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 2 from persistence list
2016-12-14 13:59:01.057 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.057 s for time 1481695141000 ms (execution: 0.049 s)
2016-12-14 13:59:01.058 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 13:59:01.058 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[2] at createStream at LogStream.java:100 of time 1481695141000 ms
2016-12-14 13:59:01.058 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695139000 ms)
2016-12-14 13:59:01.058 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695139000 ms
2016-12-14 13:59:02.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695142000 ms
2016-12-14 13:59:02.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695142000 ms.0 from job set of time 1481695142000 ms
2016-12-14 13:59:02.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695142000 ms.0 from job set of time 1481695142000 ms
2016-12-14 13:59:02.009 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 3 from persistence list
2016-12-14 13:59:02.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.008 s for time 1481695142000 ms (execution: 0.002 s)
2016-12-14 13:59:02.009 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 13:59:02.010 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[3] at createStream at LogStream.java:100 of time 1481695142000 ms
2016-12-14 13:59:02.013 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695140000 ms)
2016-12-14 13:59:02.013 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695140000 ms
2016-12-14 13:59:02.016 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed input-0-1481695140000 on localhost:60122 in memory (size: 227.6 KB, free: 1140.3 MB)
2016-12-14 13:59:03.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695143000 ms
2016-12-14 13:59:03.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695143000 ms.0 from job set of time 1481695143000 ms
2016-12-14 13:59:03.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695143000 ms.0 from job set of time 1481695143000 ms
2016-12-14 13:59:03.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 4 from persistence list
2016-12-14 13:59:03.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695143000 ms (execution: 0.000 s)
2016-12-14 13:59:03.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 13:59:03.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[4] at createStream at LogStream.java:100 of time 1481695143000 ms
2016-12-14 13:59:03.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695141000 ms)
2016-12-14 13:59:03.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695141000 ms
2016-12-14 13:59:04.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695144000 ms
2016-12-14 13:59:04.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695144000 ms.0 from job set of time 1481695144000 ms
2016-12-14 13:59:04.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695144000 ms.0 from job set of time 1481695144000 ms
2016-12-14 13:59:04.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 5 from persistence list
2016-12-14 13:59:04.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695144000 ms (execution: 0.001 s)
2016-12-14 13:59:04.006 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 5
2016-12-14 13:59:04.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[5] at createStream at LogStream.java:100 of time 1481695144000 ms
2016-12-14 13:59:04.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695142000 ms)
2016-12-14 13:59:04.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695142000 ms
2016-12-14 13:59:05.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695145000 ms
2016-12-14 13:59:05.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695145000 ms.0 from job set of time 1481695145000 ms
2016-12-14 13:59:05.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695145000 ms.0 from job set of time 1481695145000 ms
2016-12-14 13:59:05.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 6 from persistence list
2016-12-14 13:59:05.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695145000 ms (execution: 0.001 s)
2016-12-14 13:59:05.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 13:59:05.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[6] at createStream at LogStream.java:100 of time 1481695145000 ms
2016-12-14 13:59:05.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695143000 ms)
2016-12-14 13:59:05.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695143000 ms
2016-12-14 13:59:06.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695146000 ms
2016-12-14 13:59:06.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695146000 ms.0 from job set of time 1481695146000 ms
2016-12-14 13:59:06.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695146000 ms.0 from job set of time 1481695146000 ms
2016-12-14 13:59:06.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695146000 ms (execution: 0.000 s)
2016-12-14 13:59:06.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 7 from persistence list
2016-12-14 13:59:06.006 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 7
2016-12-14 13:59:06.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[7] at createStream at LogStream.java:100 of time 1481695146000 ms
2016-12-14 13:59:06.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695144000 ms)
2016-12-14 13:59:06.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695144000 ms
2016-12-14 13:59:07.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695147000 ms
2016-12-14 13:59:07.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695147000 ms.0 from job set of time 1481695147000 ms
2016-12-14 13:59:07.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695147000 ms.0 from job set of time 1481695147000 ms
2016-12-14 13:59:07.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 8 from persistence list
2016-12-14 13:59:07.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695147000 ms (execution: 0.001 s)
2016-12-14 13:59:07.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 8
2016-12-14 13:59:07.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[8] at createStream at LogStream.java:100 of time 1481695147000 ms
2016-12-14 13:59:07.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695145000 ms)
2016-12-14 13:59:07.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695145000 ms
2016-12-14 13:59:08.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695148000 ms
2016-12-14 13:59:08.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695148000 ms.0 from job set of time 1481695148000 ms
2016-12-14 13:59:08.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695148000 ms.0 from job set of time 1481695148000 ms
2016-12-14 13:59:08.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 9 from persistence list
2016-12-14 13:59:08.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695148000 ms (execution: 0.001 s)
2016-12-14 13:59:08.003 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 9
2016-12-14 13:59:08.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[9] at createStream at LogStream.java:100 of time 1481695148000 ms
2016-12-14 13:59:08.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695146000 ms)
2016-12-14 13:59:08.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695146000 ms
2016-12-14 13:59:09.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695149000 ms
2016-12-14 13:59:09.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695149000 ms.0 from job set of time 1481695149000 ms
2016-12-14 13:59:09.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695149000 ms.0 from job set of time 1481695149000 ms
2016-12-14 13:59:09.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 10 from persistence list
2016-12-14 13:59:09.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695149000 ms (execution: 0.001 s)
2016-12-14 13:59:09.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 10
2016-12-14 13:59:09.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[10] at createStream at LogStream.java:100 of time 1481695149000 ms
2016-12-14 13:59:09.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695147000 ms)
2016-12-14 13:59:09.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695147000 ms
2016-12-14 13:59:10.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695150000 ms
2016-12-14 13:59:10.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695150000 ms.0 from job set of time 1481695150000 ms
2016-12-14 13:59:10.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695150000 ms.0 from job set of time 1481695150000 ms
2016-12-14 13:59:10.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695150000 ms (execution: 0.001 s)
2016-12-14 13:59:10.009 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 11 from persistence list
2016-12-14 13:59:10.016 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 11
2016-12-14 13:59:10.016 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[11] at createStream at LogStream.java:100 of time 1481695150000 ms
2016-12-14 13:59:10.016 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695148000 ms)
2016-12-14 13:59:10.016 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695148000 ms
2016-12-14 13:59:11.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695151000 ms
2016-12-14 13:59:11.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695151000 ms.0 from job set of time 1481695151000 ms
2016-12-14 13:59:11.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695151000 ms.0 from job set of time 1481695151000 ms
2016-12-14 13:59:11.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695151000 ms (execution: 0.001 s)
2016-12-14 13:59:11.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 12 from persistence list
2016-12-14 13:59:11.009 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 12
2016-12-14 13:59:11.009 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[12] at createStream at LogStream.java:100 of time 1481695151000 ms
2016-12-14 13:59:11.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695149000 ms)
2016-12-14 13:59:11.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695149000 ms
2016-12-14 13:59:11.239 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 13:59:11.244 [dispatcher-event-loop-2] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 13:59:11.245 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 13:59:11.246 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 13:59:11.268 [dispatcher-event-loop-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05a7 closed
2016-12-14 13:59:11.268 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 13:59:11.270 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 13:59:11.270 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 13:59:11.275 [dispatcher-event-loop-0] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 13:59:11.275 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 13:59:11.276 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 13:59:11.602 [dispatcher-event-loop-3] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695151600
2016-12-14 13:59:11.603 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 13:59:11.613 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 13:59:11.614 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 13:59:11.614 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 13:59:11.616 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 13:59:11.617 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 13:59:11.619 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 12354 ms on localhost (1/1)
2016-12-14 13:59:11.619 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 12.362 s
2016-12-14 13:59:11.619 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 13:59:11.621 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 13:59:11.622 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 13:59:11.623 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 13:59:11.623 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695151000
2016-12-14 13:59:11.625 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 13:59:11.627 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 13:59:11.633 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 13:59:11.635 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 13:59:11.638 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 13:59:11.639 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 13:59:11.640 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 13:59:11.653 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 13:59:11.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 13:59:11.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 13:59:11.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 13:59:11.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 13:59:11.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 13:59:11.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 13:59:11.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 13:59:11.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 13:59:11.656 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 13:59:11.656 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 13:59:11.656 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 13:59:11.656 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 13:59:11.657 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 13:59:11.657 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 13:59:11.657 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 13:59:11.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 13:59:11.659 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 13:59:11.712 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 13:59:11.721 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 13:59:11.725 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 13:59:11.726 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 13:59:11.728 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 13:59:11.730 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 13:59:11.732 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 13:59:11.733 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 13:59:11.734 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-291117b5-7e1b-4502-9f03-29346bbccbde
2016-12-14 13:59:11.738 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 13:59:11.740 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:00:08.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.706 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.715 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.720 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:08.724 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.728 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.734 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.738 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.742 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.747 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:08.765 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.769 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.774 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.778 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.782 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.796 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.799 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.806 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.809 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.813 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.818 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.822 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:08.831 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.835 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.839 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.845 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.853 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.877 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.881 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.885 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:08.888 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.891 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.896 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.899 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.902 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.905 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.909 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.916 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.920 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.923 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.926 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.929 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.932 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.937 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.939 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.942 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:08.946 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.949 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.955 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.958 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.961 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.964 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.970 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.973 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:08.976 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.979 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:08.983 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.987 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:08.990 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->)
)
2016-12-14 14:00:08.995 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:08---------->2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.001 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.004 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:09.008 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.011 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.014 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.017 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.019 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.024 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.027 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.029 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.034 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.038 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.040 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.043 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.046 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.050 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.054 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.057 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:09.059 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.061 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.064 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.066 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.078 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.084 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.094 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.096 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:09.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.106 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.121 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.131 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:09.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.156 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.179 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.188 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:09.194 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.219 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.226 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.246 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.256 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.262 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.268 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:09.288 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.292 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.295 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.297 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.299 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.303 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.312 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.334 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.337 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.340 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.342 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.349 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.354 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.360 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.362 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.365 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.367 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.372 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.375 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.377 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.384 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:09.391 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.401 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.405 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.407 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.408 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.410 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.412 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.414 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.418 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.422 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.424 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.436 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.444 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.446 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.450 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.452 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.457 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.460 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.462 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.464 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:09.472 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.478 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.481 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.483 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.485 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.503 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.505 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.507 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.510 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.522 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.533 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.538 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.544 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.553 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.556 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.561 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.567 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.575 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:09.589 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.594 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.596 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.599 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.604 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.607 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.609 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.611 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.615 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.617 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.621 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.624 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.627 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.630 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.632 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.636 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.638 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.641 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.645 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.647 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.649 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.651 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.654 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.657 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.659 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.661 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.662 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.664 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.666 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.674 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.676 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.679 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.681 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.685 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.687 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.690 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.693 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.696 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.700 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.703 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.705 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.713 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.715 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.718 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.720 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.723 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.729 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.731 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.734 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.737 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.739 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.744 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.747 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.749 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.751 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.757 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:09.760 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.763 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.771 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.773 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.775 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.779 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.782 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.835 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.839 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.853 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.855 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.857 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.859 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.861 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.863 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.865 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.867 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.869 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.871 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.873 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.875 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.878 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.880 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.882 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.884 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.887 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.889 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.892 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.894 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.896 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.898 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.903 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:09.904 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.907 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.909 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.911 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.913 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.914 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.916 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.918 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.920 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.922 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.924 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.926 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.929 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.931 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.933 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.935 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:09.937 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.939 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.940 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.942 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.945 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.948 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.951 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.953 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:09.955 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.957 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.960 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.962 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.965 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.967 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.969 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.972 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:09.975 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.977 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.988 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.991 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:09.995 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:09.997 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:09.999 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:09---------->)
)
2016-12-14 14:00:10.001 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.003 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.007 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.009 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.012 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.014 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.016 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.018 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.021 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.023 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.026 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.029 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.031 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.033 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.037 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.039 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.041 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.043 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.045 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.047 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.051 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.053 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.055 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.058 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.060 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:10.064 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.066 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.067 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.075 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.077 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.078 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.082 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.087 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.096 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.113 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.121 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:10.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.156 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.170 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.188 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.194 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.196 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:10.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.219 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.224 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.226 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.235 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.271 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.273 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.275 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.281 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:10.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.322 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.330 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.332 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.343 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.347 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.349 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.351 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.357 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.360 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.362 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.365 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.367 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.369 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.373 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.088 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.384 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.387 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.391 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.109 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.092 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.408 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.411 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.414 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.101 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.416 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.419 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.421 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.103 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.428 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.434 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.436 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.442 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.444 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.446 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.450 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.453 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.457 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.459 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.465 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.131 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.105 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:10.468 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.471 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.473 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.475 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.477 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.480 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.484 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.485 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.112 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.503 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.506 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.148 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.510 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.512 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.515 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.517 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.519 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.521 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.156 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.529 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.531 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.533 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.160 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.535 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.539 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.544 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.545 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.549 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.553 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.556 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.565 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.567 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.107 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.569 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.571 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.573 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.575 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.577 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.582 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.585 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.179 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.141 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.133 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.587 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.589 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.591 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.596 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.598 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.600 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.136 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:10.605 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.607 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.611 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.612 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.615 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.618 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.620 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.623 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.149 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.626 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.628 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.630 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.632 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.635 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.639 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.641 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.144 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.645 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.647 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.209 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.650 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.653 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.211 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.155 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.655 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.656 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.658 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.661 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.664 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.665 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.668 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.672 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.678 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.691 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.118 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.695 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.697 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.699 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.163 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.705 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.238 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.165 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.713 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.715 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.717 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.719 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.167 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.721 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.723 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.725 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.727 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.158 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.729 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.731 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.733 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.735 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.171 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.737 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.739 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.740 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.742 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.173 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.745 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.747 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.749 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.751 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.755 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.757 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.759 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.169 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.124 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:10.761 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.764 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.271 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.766 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.768 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.273 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.769 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.771 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.277 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.773 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.775 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.781 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.785 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.281 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.787 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.789 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.791 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.793 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.794 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.796 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.174 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.799 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.800 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.802 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.804 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.292 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.806 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.808 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.810 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.813 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.177 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.815 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.816 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.818 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.820 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.299 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.189 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.823 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.825 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.827 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.829 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.303 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.191 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.181 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.129 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.115 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.831 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.832 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.834 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.836 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.838 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.842 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.843 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.845 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.185 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.847 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.849 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.850 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.853 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.316 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.855 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.857 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.859 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.861 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.322 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.863 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.865 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.324 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.869 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.871 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.327 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.872 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.874 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.875 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.877 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.880 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.882 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.883 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.885 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.336 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.206 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.887 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.888 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.339 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.889 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.891 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.341 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.195 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:)
)
2016-12-14 14:00:10.896 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.901 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.344 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.904 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.906 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.210 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.908 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.910 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.348 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.912 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.914 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.356 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.212 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.200 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.916 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.919 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.363 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.920 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.922 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.924 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.926 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.927 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.929 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.370 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.216 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.138 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.931 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.933 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.372 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.934 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.936 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.218 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.937 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.939 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.941 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.943 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.208 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.945 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.946 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.385 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.950 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.952 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.387 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.221 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.954 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.956 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.390 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.957 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.959 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.394 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.223 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.213 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:10.961 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.963 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.966 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.970 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.972 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.973 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.402 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.975 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.977 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.404 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.227 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:10.978 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.980 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.981 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.982 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.409 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.229 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.985 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.987 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.411 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.989 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.990 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.220 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:10.992 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.994 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:10.995 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:10.997 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->2016-12-14 13:49:19.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:10.999 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:10---------->)
)
2016-12-14 14:00:11.002 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.418 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.004 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.006 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.007 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.010 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.423 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.011 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.014 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.425 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.237 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.016 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.018 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.019 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.022 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.225 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.147 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.126 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:11.024 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.026 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.431 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.028 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.030 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.433 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.031 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.033 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.437 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.035 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.037 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.039 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.042 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.044 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.045 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.443 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.245 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.047 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.048 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.445 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.050 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.051 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.448 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.150 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.053 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.056 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.451 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.058 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.059 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.453 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.061 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.063 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.455 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.064 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.066 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.456 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.251 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.233 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.070 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.072 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.458 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.075 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.459 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.254 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.077 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.080 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.461 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.087 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.463 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.153 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:11.089 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.465 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.091 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.257 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.094 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.096 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.098 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.099 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.470 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.259 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.102 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.106 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.472 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.110 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.261 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.111 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.113 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.475 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.114 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.116 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.477 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.117 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.119 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.479 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.120 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.122 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.265 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.123 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.125 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.484 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.127 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.128 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.267 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.243 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.130 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.132 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.135 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.137 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.140 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.142 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.247 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.161 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.134 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.104 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.095 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:)
)
2016-12-14 14:00:11.145 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.148 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.151 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.154 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.497 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.157 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.159 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.162 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.250 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.166 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.502 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.170 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.504 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.176 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.506 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.182 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.253 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.164 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.186 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.509 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.188 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.190 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.511 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.193 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.197 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.199 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.201 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.203 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.205 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.518 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.207 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.211 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.521 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.285 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.214 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.215 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.217 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.219 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.287 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.168 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.139 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:11.222 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.224 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.226 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.228 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.289 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.230 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.232 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.234 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.236 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.534 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.291 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.239 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.241 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.242 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.244 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.540 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.246 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.248 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.541 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.249 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.252 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.543 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.296 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.263 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.172 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.255 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.258 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.260 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.262 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.551 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.298 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.264 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.555 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.269 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.271 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.558 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.300 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.266 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.273 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.560 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.278 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.280 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.282 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.288 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.566 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.305 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.270 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.175 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.143 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.108 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:)
)
2016-12-14 14:00:11.292 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.294 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.568 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.295 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.297 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.570 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.309 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.299 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.574 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.302 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.576 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.272 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.308 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.311 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.577 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.316 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.579 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.321 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.583 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.325 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.329 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.588 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.315 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.274 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.178 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.334 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.591 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.340 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.343 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.593 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.318 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.345 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.347 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.595 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.351 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.354 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.597 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.320 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.276 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.357 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.359 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.602 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.363 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.607 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.323 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.365 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.367 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.609 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.369 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.370 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.611 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.326 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.279 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.180 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.146 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:)
)
2016-12-14 14:00:11.372 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.612 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.377 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.614 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.328 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.384 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.617 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.388 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.621 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.331 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.283 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.391 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.623 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.393 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.395 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.625 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.333 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.396 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.398 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.627 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.399 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.402 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.628 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.335 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.286 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.184 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.403 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.405 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.634 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.406 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.408 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.636 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.338 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.410 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.413 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.638 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.415 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.417 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.640 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.346 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.290 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.419 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.420 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.642 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.422 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.424 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.643 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.350 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.426 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.429 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.646 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.430 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.432 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.652 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.353 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.293 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.187 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:16.081 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:2016-12-14 13:49:15.076 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:15:2016-12-14 13:49:14.073 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:14:2016-12-14 13:49:13.068 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:13:2016-12-14 13:49:12.065 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:12:2016-12-14 13:49:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:11:2016-12-14 13:36:15.440 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
)
2016-12-14 14:00:11.435 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.437 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.660 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.439 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.441 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.662 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.358 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.443 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.446 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.665 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.449 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.452 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.668 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.361 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.301 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.454 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.455 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.670 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.457 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.460 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.672 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.364 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.462 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.464 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.674 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.465 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.467 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.675 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.366 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.304 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.192 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.469 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.471 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.677 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.473 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.474 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.679 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.368 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.476 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.478 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.681 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.482 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.484 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.683 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.371 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.307 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.486 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.487 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.685 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.489 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.491 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.686 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.374 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.492 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.493 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.688 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.495 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.498 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.690 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.376 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.310 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:17.083 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:2016-12-14 13:49:16.085 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:16:)
)
2016-12-14 14:00:11.499 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.501 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.698 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.502 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.503 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.700 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.379 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.505 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.507 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.702 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.508 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.510 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.703 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.381 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.313 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.511 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.513 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.705 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.514 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.516 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.707 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.383 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.519 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.520 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.709 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.522 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.523 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.711 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.386 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:18.090 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:2016-12-14 13:49:17.086 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:17:)
)
2016-12-14 14:00:11.525 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.527 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.712 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.528 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.530 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.714 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.389 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.532 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.533 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.716 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.535 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.537 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.724 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.097 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:18.093 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:18:)
)
2016-12-14 14:00:11.539 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.541 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.737 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.543 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.545 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.749 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:2016-12-14 13:49:19.100 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.546 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.547 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:49:19.753 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 13:49:19:)
)
2016-12-14 14:00:11.549 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->)
)
2016-12-14 14:00:11.550 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:26.248 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
)
2016-12-14 14:00:11.552 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:26.624 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
)
2016-12-14 14:00:11.553 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:26.722 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
)
2016-12-14 14:00:11.554 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.267 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
)
2016-12-14 14:00:11.556 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.504 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
)
2016-12-14 14:00:11.557 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.511 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
)
2016-12-14 14:00:11.559 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
)
2016-12-14 14:00:11.560 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
)
2016-12-14 14:00:11.562 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
)
2016-12-14 14:00:11.564 [Thread-2] INFO  com.wankun.logcount.kafka.MsgSender - sending kv :(20161214 14:00:11---------->2016-12-14 13:50:27.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
)
2016-12-14 14:00:20.051 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:00:20.533 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:00:20.626 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:00:21.238 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:00:21.524 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:00:21.532 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:00:21.533 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:00:21.533 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:00:21.533 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:00:21.533 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:00:21.533 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:00:21.534 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:00:21.535 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:00:21.535 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:00:21.536 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:00:21.604 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:00:21.626 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:00:21.638 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a8, negotiated timeout = 40000
2016-12-14 14:00:21.876 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:00:23.196 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:00:23.205 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:00:23.212 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:00:23.217 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:00:23.220 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:00:23.220 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:00:23.220 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:00:23.243 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:00:23.243 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:00:23.856 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:00:24.225 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:00:24.322 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:00:24.324 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:00:24.329 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:00:24.966 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60188.
2016-12-14 14:00:25.522 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:00:25.571 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 14:00:25.779 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60189]
2016-12-14 14:00:25.790 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60189.
2016-12-14 14:00:25.804 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:00:25.830 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:00:25.848 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-4ea91829-6cab-4c6f-840b-d24a2c3d57b9
2016-12-14 14:00:25.858 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:00:25.923 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:00:26.155 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:00:26.201 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:00:26.201 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:00:26.203 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:00:26.327 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:00:26.351 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60191.
2016-12-14 14:00:26.352 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60191
2016-12-14 14:00:26.353 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:00:26.356 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60191 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60191)
2016-12-14 14:00:26.360 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:00:27.307 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 14:00:27.310 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 14:00:27.320 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:00:27.321 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:00:27.322 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:00:27.323 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:00:27.324 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:00:27.324 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:00:27.325 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@21a35f0a
2016-12-14 14:00:27.326 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:00:27.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:00:27.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:00:27.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:00:27.328 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@7853c67
2016-12-14 14:00:27.410 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695228000
2016-12-14 14:00:27.411 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695228000 ms
2016-12-14 14:00:27.412 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 14:00:27.439 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 14:00:27.448 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 14:00:27.450 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 14:00:27.450 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:00:27.452 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:00:27.467 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 14:00:27.478 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 14:00:27.616 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 14:00:27.640 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 14:00:27.644 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60191 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 14:00:27.658 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:00:27.663 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 14:00:27.665 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 14:00:27.765 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 14:00:27.788 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:00:27.879 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695228000
2016-12-14 14:00:27.880 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 14:00:27.880 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 14:00:27.892 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60188
2016-12-14 14:00:27.893 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 14:00:27.894 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 14:00:27.896 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 14:00:27.973 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4ecc4103
2016-12-14 14:00:27.976 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:00:27.978 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:00:27.982 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05a9, negotiated timeout = 6000
2016-12-14 14:00:28.008 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 14:00:28.091 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695228000 ms
2016-12-14 14:00:28.097 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695228000 ms.0 from job set of time 1481695228000 ms
2016-12-14 14:00:28.102 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695228000 ms.0 from job set of time 1481695228000 ms
2016-12-14 14:00:28.104 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.101 s for time 1481695228000 ms (execution: 0.007 s)
2016-12-14 14:00:28.110 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:00:28.113 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:00:28.437 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:00:28.437 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:00:28.437 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:00:28.438 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 14:00:28.440 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 14:00:29.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695229000 ms
2016-12-14 14:00:29.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695229000 ms.0 from job set of time 1481695229000 ms
2016-12-14 14:00:29.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695229000 ms.0 from job set of time 1481695229000 ms
2016-12-14 14:00:29.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695229000 ms (execution: 0.001 s)
2016-12-14 14:00:29.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 14:00:29.008 [Thread-23] INFO  org.apache.spark.storage.MemoryStore - Block input-0-1481695228600 stored as bytes in memory (estimated size 152.3 KB, free 254.3 KB)
2016-12-14 14:00:29.014 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added input-0-1481695228600 in memory on localhost:60191 (size: 152.3 KB, free: 1140.2 MB)
2016-12-14 14:00:29.016 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695229000 ms
2016-12-14 14:00:29.017 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:00:29.017 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:00:29.017 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 14:00:29.019 [Thread-23] WARN  o.apache.spark.storage.BlockManager - Block input-0-1481695228600 replicated to only 0 peer(s) instead of 1 peers
2016-12-14 14:00:29.028 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushed block input-0-1481695228600
2016-12-14 14:00:30.019 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695230000 ms
2016-12-14 14:00:30.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695230000 ms.0 from job set of time 1481695230000 ms
2016-12-14 14:00:30.053 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: print at LogStream.java:102
2016-12-14 14:00:30.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (print at LogStream.java:102) with 1 output partitions
2016-12-14 14:00:30.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (print at LogStream.java:102)
2016-12-14 14:00:30.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:00:30.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:00:30.057 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (BlockRDD[3] at createStream at LogStream.java:100), which has no missing parents
2016-12-14 14:00:30.063 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 1104.0 B, free 255.4 KB)
2016-12-14 14:00:30.065 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 741.0 B, free 256.1 KB)
2016-12-14 14:00:30.066 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:60191 (size: 741.0 B, free: 1140.2 MB)
2016-12-14 14:00:30.067 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:00:30.068 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (BlockRDD[3] at createStream at LogStream.java:100)
2016-12-14 14:00:30.068 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2016-12-14 14:00:30.075 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 2017 bytes)
2016-12-14 14:00:30.076 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:00:30.083 [Executor task launch worker-1] INFO  o.apache.spark.storage.BlockManager - Found block input-0-1481695228600 locally
2016-12-14 14:00:30.094 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 2567 bytes result sent to driver
2016-12-14 14:00:30.102 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (1/1)
2016-12-14 14:00:30.104 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:00:30.106 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (print at LogStream.java:102) finished in 0.034 s
2016-12-14 14:00:30.112 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: print at LogStream.java:102, took 0.057684 s
2016-12-14 14:00:30.114 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695230000 ms.0 from job set of time 1481695230000 ms
2016-12-14 14:00:30.115 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.114 s for time 1481695230000 ms (execution: 0.089 s)
2016-12-14 14:00:30.115 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 2 from persistence list
2016-12-14 14:00:30.115 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 14:00:30.116 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[2] at createStream at LogStream.java:100 of time 1481695230000 ms
2016-12-14 14:00:30.116 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695228000 ms)
2016-12-14 14:00:30.116 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695228000 ms
2016-12-14 14:00:31.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695231000 ms
2016-12-14 14:00:31.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695231000 ms.0 from job set of time 1481695231000 ms
2016-12-14 14:00:31.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695231000 ms.0 from job set of time 1481695231000 ms
2016-12-14 14:00:31.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695231000 ms (execution: 0.002 s)
2016-12-14 14:00:31.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 3 from persistence list
2016-12-14 14:00:31.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 14:00:31.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[3] at createStream at LogStream.java:100 of time 1481695231000 ms
2016-12-14 14:00:31.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695229000 ms)
2016-12-14 14:00:31.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695229000 ms
2016-12-14 14:00:31.010 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed input-0-1481695228600 on localhost:60191 in memory (size: 152.3 KB, free: 1140.3 MB)
2016-12-14 14:00:32.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695232000 ms
2016-12-14 14:00:32.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695232000 ms.0 from job set of time 1481695232000 ms
2016-12-14 14:00:32.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695232000 ms.0 from job set of time 1481695232000 ms
2016-12-14 14:00:32.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695232000 ms (execution: 0.000 s)
2016-12-14 14:00:32.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 4 from persistence list
2016-12-14 14:00:32.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 14:00:32.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[4] at createStream at LogStream.java:100 of time 1481695232000 ms
2016-12-14 14:00:32.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695230000 ms)
2016-12-14 14:00:32.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695230000 ms
2016-12-14 14:00:33.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695233000 ms
2016-12-14 14:00:33.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695233000 ms.0 from job set of time 1481695233000 ms
2016-12-14 14:00:33.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695233000 ms.0 from job set of time 1481695233000 ms
2016-12-14 14:00:33.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 5 from persistence list
2016-12-14 14:00:33.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695233000 ms (execution: 0.001 s)
2016-12-14 14:00:33.007 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 5
2016-12-14 14:00:33.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[5] at createStream at LogStream.java:100 of time 1481695233000 ms
2016-12-14 14:00:33.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695231000 ms)
2016-12-14 14:00:33.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695231000 ms
2016-12-14 14:00:34.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695234000 ms
2016-12-14 14:00:34.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695234000 ms.0 from job set of time 1481695234000 ms
2016-12-14 14:00:34.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695234000 ms.0 from job set of time 1481695234000 ms
2016-12-14 14:00:34.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695234000 ms (execution: 0.001 s)
2016-12-14 14:00:34.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 6 from persistence list
2016-12-14 14:00:34.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 14:00:34.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[6] at createStream at LogStream.java:100 of time 1481695234000 ms
2016-12-14 14:00:34.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695232000 ms)
2016-12-14 14:00:34.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695232000 ms
2016-12-14 14:00:35.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695235000 ms
2016-12-14 14:00:35.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695235000 ms.0 from job set of time 1481695235000 ms
2016-12-14 14:00:35.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695235000 ms.0 from job set of time 1481695235000 ms
2016-12-14 14:00:35.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 7 from persistence list
2016-12-14 14:00:35.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695235000 ms (execution: 0.001 s)
2016-12-14 14:00:35.005 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 7
2016-12-14 14:00:35.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[7] at createStream at LogStream.java:100 of time 1481695235000 ms
2016-12-14 14:00:35.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695233000 ms)
2016-12-14 14:00:35.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695233000 ms
2016-12-14 14:00:36.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695236000 ms
2016-12-14 14:00:36.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695236000 ms.0 from job set of time 1481695236000 ms
2016-12-14 14:00:36.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695236000 ms.0 from job set of time 1481695236000 ms
2016-12-14 14:00:36.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695236000 ms (execution: 0.000 s)
2016-12-14 14:00:36.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 8 from persistence list
2016-12-14 14:00:36.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[8] at createStream at LogStream.java:100 of time 1481695236000 ms
2016-12-14 14:00:36.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695234000 ms)
2016-12-14 14:00:36.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695234000 ms
2016-12-14 14:00:36.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 8
2016-12-14 14:00:37.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695237000 ms
2016-12-14 14:00:37.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695237000 ms.0 from job set of time 1481695237000 ms
2016-12-14 14:00:37.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695237000 ms.0 from job set of time 1481695237000 ms
2016-12-14 14:00:37.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 9 from persistence list
2016-12-14 14:00:37.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695237000 ms (execution: 0.001 s)
2016-12-14 14:00:37.004 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 9
2016-12-14 14:00:37.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[9] at createStream at LogStream.java:100 of time 1481695237000 ms
2016-12-14 14:00:37.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695235000 ms)
2016-12-14 14:00:37.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695235000 ms
2016-12-14 14:00:38.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695238000 ms
2016-12-14 14:00:38.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695238000 ms.0 from job set of time 1481695238000 ms
2016-12-14 14:00:38.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695238000 ms.0 from job set of time 1481695238000 ms
2016-12-14 14:00:38.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695238000 ms (execution: 0.000 s)
2016-12-14 14:00:38.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 10 from persistence list
2016-12-14 14:00:38.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 10
2016-12-14 14:00:38.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[10] at createStream at LogStream.java:100 of time 1481695238000 ms
2016-12-14 14:00:38.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695236000 ms)
2016-12-14 14:00:38.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695236000 ms
2016-12-14 14:00:39.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695239000 ms
2016-12-14 14:00:39.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695239000 ms.0 from job set of time 1481695239000 ms
2016-12-14 14:00:39.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695239000 ms.0 from job set of time 1481695239000 ms
2016-12-14 14:00:39.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 11 from persistence list
2016-12-14 14:00:39.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695239000 ms (execution: 0.001 s)
2016-12-14 14:00:39.005 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 11
2016-12-14 14:00:39.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[11] at createStream at LogStream.java:100 of time 1481695239000 ms
2016-12-14 14:00:39.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695237000 ms)
2016-12-14 14:00:39.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695237000 ms
2016-12-14 14:00:40.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695240000 ms
2016-12-14 14:00:40.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695240000 ms.0 from job set of time 1481695240000 ms
2016-12-14 14:00:40.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695240000 ms.0 from job set of time 1481695240000 ms
2016-12-14 14:00:40.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695240000 ms (execution: 0.000 s)
2016-12-14 14:00:40.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 12 from persistence list
2016-12-14 14:00:40.010 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[12] at createStream at LogStream.java:100 of time 1481695240000 ms
2016-12-14 14:00:40.010 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695238000 ms)
2016-12-14 14:00:40.010 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 12
2016-12-14 14:00:40.010 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695238000 ms
2016-12-14 14:00:41.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695241000 ms
2016-12-14 14:00:41.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695241000 ms.0 from job set of time 1481695241000 ms
2016-12-14 14:00:41.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695241000 ms.0 from job set of time 1481695241000 ms
2016-12-14 14:00:41.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 13 from persistence list
2016-12-14 14:00:41.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695241000 ms (execution: 0.001 s)
2016-12-14 14:00:41.008 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 13
2016-12-14 14:00:41.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[13] at createStream at LogStream.java:100 of time 1481695241000 ms
2016-12-14 14:00:41.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695239000 ms)
2016-12-14 14:00:41.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695239000 ms
2016-12-14 14:00:42.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695242000 ms
2016-12-14 14:00:42.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695242000 ms.0 from job set of time 1481695242000 ms
2016-12-14 14:00:42.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695242000 ms.0 from job set of time 1481695242000 ms
2016-12-14 14:00:42.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 14 from persistence list
2016-12-14 14:00:42.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695242000 ms (execution: 0.001 s)
2016-12-14 14:00:42.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 14
2016-12-14 14:00:42.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[14] at createStream at LogStream.java:100 of time 1481695242000 ms
2016-12-14 14:00:42.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695240000 ms)
2016-12-14 14:00:42.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695240000 ms
2016-12-14 14:00:43.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695243000 ms
2016-12-14 14:00:43.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695243000 ms.0 from job set of time 1481695243000 ms
2016-12-14 14:00:43.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695243000 ms.0 from job set of time 1481695243000 ms
2016-12-14 14:00:43.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 15 from persistence list
2016-12-14 14:00:43.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695243000 ms (execution: 0.001 s)
2016-12-14 14:00:43.008 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 15
2016-12-14 14:00:43.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[15] at createStream at LogStream.java:100 of time 1481695243000 ms
2016-12-14 14:00:43.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695241000 ms)
2016-12-14 14:00:43.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695241000 ms
2016-12-14 14:00:44.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695244000 ms
2016-12-14 14:00:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695244000 ms.0 from job set of time 1481695244000 ms
2016-12-14 14:00:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695244000 ms.0 from job set of time 1481695244000 ms
2016-12-14 14:00:44.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 16 from persistence list
2016-12-14 14:00:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695244000 ms (execution: 0.000 s)
2016-12-14 14:00:44.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 16
2016-12-14 14:00:44.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[16] at createStream at LogStream.java:100 of time 1481695244000 ms
2016-12-14 14:00:44.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695242000 ms)
2016-12-14 14:00:44.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695242000 ms
2016-12-14 14:00:45.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695245000 ms
2016-12-14 14:00:45.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695245000 ms.0 from job set of time 1481695245000 ms
2016-12-14 14:00:45.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695245000 ms.0 from job set of time 1481695245000 ms
2016-12-14 14:00:45.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 17 from persistence list
2016-12-14 14:00:45.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695245000 ms (execution: 0.000 s)
2016-12-14 14:00:45.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 17
2016-12-14 14:00:45.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[17] at createStream at LogStream.java:100 of time 1481695245000 ms
2016-12-14 14:00:45.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695243000 ms)
2016-12-14 14:00:45.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695243000 ms
2016-12-14 14:00:46.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695246000 ms
2016-12-14 14:00:46.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695246000 ms.0 from job set of time 1481695246000 ms
2016-12-14 14:00:46.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695246000 ms.0 from job set of time 1481695246000 ms
2016-12-14 14:00:46.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 18 from persistence list
2016-12-14 14:00:46.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695246000 ms (execution: 0.001 s)
2016-12-14 14:00:46.008 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 18
2016-12-14 14:00:46.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[18] at createStream at LogStream.java:100 of time 1481695246000 ms
2016-12-14 14:00:46.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695244000 ms)
2016-12-14 14:00:46.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695244000 ms
2016-12-14 14:00:47.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695247000 ms
2016-12-14 14:00:47.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695247000 ms.0 from job set of time 1481695247000 ms
2016-12-14 14:00:47.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695247000 ms.0 from job set of time 1481695247000 ms
2016-12-14 14:00:47.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 19 from persistence list
2016-12-14 14:00:47.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695247000 ms (execution: 0.000 s)
2016-12-14 14:00:47.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 19
2016-12-14 14:00:47.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[19] at createStream at LogStream.java:100 of time 1481695247000 ms
2016-12-14 14:00:47.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695245000 ms)
2016-12-14 14:00:47.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695245000 ms
2016-12-14 14:00:48.007 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695248000 ms
2016-12-14 14:00:48.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695248000 ms.0 from job set of time 1481695248000 ms
2016-12-14 14:00:48.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695248000 ms.0 from job set of time 1481695248000 ms
2016-12-14 14:00:48.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.008 s for time 1481695248000 ms (execution: 0.001 s)
2016-12-14 14:00:48.009 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 20 from persistence list
2016-12-14 14:00:48.010 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 20
2016-12-14 14:00:48.010 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[20] at createStream at LogStream.java:100 of time 1481695248000 ms
2016-12-14 14:00:48.010 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695246000 ms)
2016-12-14 14:00:48.010 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695246000 ms
2016-12-14 14:00:48.123 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 14:00:48.130 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 14:00:48.130 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 14:00:48.133 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 14:00:48.160 [dispatcher-event-loop-0] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05a9 closed
2016-12-14 14:00:48.161 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 14:00:48.162 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 14:00:48.163 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 14:00:48.166 [dispatcher-event-loop-2] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 14:00:48.166 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 14:00:48.167 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 14:00:48.402 [dispatcher-event-loop-0] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695248400
2016-12-14 14:00:48.402 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 14:00:48.414 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 14:00:48.414 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 14:00:48.414 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 14:00:48.415 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 14:00:48.417 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 14:00:48.418 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 20682 ms on localhost (1/1)
2016-12-14 14:00:48.418 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 20.696 s
2016-12-14 14:00:48.418 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:00:48.420 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 14:00:48.421 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 14:00:48.421 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 14:00:48.422 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695248000
2016-12-14 14:00:48.423 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 14:00:48.424 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 14:00:48.427 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 14:00:48.428 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 14:00:48.429 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 14:00:48.430 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 14:00:48.431 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 14:00:48.443 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 14:00:48.443 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 14:00:48.444 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:00:48.444 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:00:48.444 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:00:48.446 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:00:48.446 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:00:48.446 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:00:48.446 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:00:48.447 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:00:48.447 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:00:48.447 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:00:48.447 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:00:48.447 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:00:48.448 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:00:48.449 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:00:48.502 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 14:00:48.510 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:00:48.515 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 14:00:48.516 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 14:00:48.517 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 14:00:48.519 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 14:00:48.521 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 14:00:48.522 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:00:48.523 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-53e7816c-7e7b-4575-af1c-2d764759c085
2016-12-14 14:00:48.527 [sparkDriverActorSystem-akka.actor.default-dispatcher-14] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 14:00:48.529 [sparkDriverActorSystem-akka.actor.default-dispatcher-14] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:02:11.426 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:02:12.011 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:02:12.123 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:02:12.776 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:02:13.043 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:02:13.051 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:02:13.051 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:02:13.051 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:02:13.051 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:02:13.052 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:02:13.053 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:02:13.053 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:02:13.053 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:02:13.053 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:02:13.056 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:02:17.264 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:02:17.278 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:02:17.286 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05aa, negotiated timeout = 40000
2016-12-14 14:02:17.354 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:02:18.655 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:02:18.669 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:02:18.677 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:02:18.683 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:02:18.685 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:02:18.686 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:02:18.686 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:02:18.700 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:02:18.700 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:02:19.147 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:02:19.522 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:02:19.598 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:02:19.599 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:02:19.601 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:02:20.342 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60253.
2016-12-14 14:02:20.858 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:02:20.910 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 14:02:21.083 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60254]
2016-12-14 14:02:21.106 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60254.
2016-12-14 14:02:21.120 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:02:21.143 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:02:21.164 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-d625de2f-07e6-4be1-9e0d-baffc4ae3642
2016-12-14 14:02:21.175 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:02:21.243 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:02:21.467 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:02:21.515 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:02:21.515 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:02:21.517 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:02:21.637 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:02:21.662 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60255.
2016-12-14 14:02:21.662 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60255
2016-12-14 14:02:21.664 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:02:21.667 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60255 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60255)
2016-12-14 14:02:21.670 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:02:22.566 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 14:02:22.568 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 14:02:22.575 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:02:22.577 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:02:22.578 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:02:22.579 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:02:22.580 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:02:22.581 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:02:22.582 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@174df44
2016-12-14 14:02:22.582 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:02:22.583 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:02:22.583 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:02:22.583 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:02:22.583 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@50e71e30
2016-12-14 14:02:22.692 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695343000
2016-12-14 14:02:22.693 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695343000 ms
2016-12-14 14:02:22.695 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 14:02:22.715 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 14:02:22.717 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 14:02:22.726 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 14:02:22.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 14:02:22.728 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:02:22.730 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:02:22.749 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 14:02:22.876 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 14:02:22.932 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 14:02:22.936 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60255 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 14:02:22.940 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:02:22.944 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 14:02:22.946 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 14:02:22.997 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 14:02:23.015 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:02:23.031 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695343000 ms
2016-12-14 14:02:23.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695343000 ms.0 from job set of time 1481695343000 ms
2016-12-14 14:02:23.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695343000 ms.0 from job set of time 1481695343000 ms
2016-12-14 14:02:23.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.040 s for time 1481695343000 ms (execution: 0.007 s)
2016-12-14 14:02:23.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:02:23.055 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:02:23.116 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695343200
2016-12-14 14:02:23.117 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 14:02:23.117 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 14:02:23.126 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60253
2016-12-14 14:02:23.127 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 14:02:23.129 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 14:02:23.130 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 14:02:23.213 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@3a231e2f
2016-12-14 14:02:23.214 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:02:23.215 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:02:23.218 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05ab, negotiated timeout = 6000
2016-12-14 14:02:23.245 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 14:02:23.594 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:02:23.595 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:02:23.597 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:02:23.598 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 14:02:23.599 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 14:02:24.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695344000 ms
2016-12-14 14:02:24.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695344000 ms.0 from job set of time 1481695344000 ms
2016-12-14 14:02:24.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695344000 ms.0 from job set of time 1481695344000 ms
2016-12-14 14:02:24.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695344000 ms (execution: 0.001 s)
2016-12-14 14:02:24.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 14:02:24.014 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695344000 ms
2016-12-14 14:02:24.015 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:02:24.015 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 14:02:24.015 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:02:25.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695345000 ms
2016-12-14 14:02:25.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695345000 ms.0 from job set of time 1481695345000 ms
2016-12-14 14:02:25.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695345000 ms.0 from job set of time 1481695345000 ms
2016-12-14 14:02:25.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695345000 ms (execution: 0.000 s)
2016-12-14 14:02:25.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 2 from persistence list
2016-12-14 14:02:25.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 14:02:25.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[2] at createStream at LogStream.java:100 of time 1481695345000 ms
2016-12-14 14:02:25.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695343000 ms)
2016-12-14 14:02:25.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695343000 ms
2016-12-14 14:02:26.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695346000 ms
2016-12-14 14:02:26.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695346000 ms.0 from job set of time 1481695346000 ms
2016-12-14 14:02:26.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695346000 ms.0 from job set of time 1481695346000 ms
2016-12-14 14:02:26.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695346000 ms (execution: 0.000 s)
2016-12-14 14:02:26.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 3 from persistence list
2016-12-14 14:02:26.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[3] at createStream at LogStream.java:100 of time 1481695346000 ms
2016-12-14 14:02:26.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 14:02:26.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695344000 ms)
2016-12-14 14:02:26.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695344000 ms
2016-12-14 14:02:27.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695347000 ms
2016-12-14 14:02:27.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695347000 ms.0 from job set of time 1481695347000 ms
2016-12-14 14:02:27.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695347000 ms.0 from job set of time 1481695347000 ms
2016-12-14 14:02:27.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695347000 ms (execution: 0.001 s)
2016-12-14 14:02:27.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 4 from persistence list
2016-12-14 14:02:27.008 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 14:02:27.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[4] at createStream at LogStream.java:100 of time 1481695347000 ms
2016-12-14 14:02:27.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695345000 ms)
2016-12-14 14:02:27.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695345000 ms
2016-12-14 14:02:28.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695348000 ms
2016-12-14 14:02:28.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695348000 ms.0 from job set of time 1481695348000 ms
2016-12-14 14:02:28.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695348000 ms.0 from job set of time 1481695348000 ms
2016-12-14 14:02:28.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 5 from persistence list
2016-12-14 14:02:28.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695348000 ms (execution: 0.001 s)
2016-12-14 14:02:28.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 5
2016-12-14 14:02:28.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[5] at createStream at LogStream.java:100 of time 1481695348000 ms
2016-12-14 14:02:28.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695346000 ms)
2016-12-14 14:02:28.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695346000 ms
2016-12-14 14:02:29.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695349000 ms
2016-12-14 14:02:29.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695349000 ms.0 from job set of time 1481695349000 ms
2016-12-14 14:02:29.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695349000 ms.0 from job set of time 1481695349000 ms
2016-12-14 14:02:29.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 6 from persistence list
2016-12-14 14:02:29.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695349000 ms (execution: 0.001 s)
2016-12-14 14:02:29.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 14:02:29.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[6] at createStream at LogStream.java:100 of time 1481695349000 ms
2016-12-14 14:02:29.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695347000 ms)
2016-12-14 14:02:29.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695347000 ms
2016-12-14 14:02:30.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695350000 ms
2016-12-14 14:02:30.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695350000 ms.0 from job set of time 1481695350000 ms
2016-12-14 14:02:30.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695350000 ms.0 from job set of time 1481695350000 ms
2016-12-14 14:02:30.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 7 from persistence list
2016-12-14 14:02:30.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695350000 ms (execution: 0.000 s)
2016-12-14 14:02:30.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 7
2016-12-14 14:02:30.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[7] at createStream at LogStream.java:100 of time 1481695350000 ms
2016-12-14 14:02:30.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695348000 ms)
2016-12-14 14:02:30.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695348000 ms
2016-12-14 14:02:31.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695351000 ms
2016-12-14 14:02:31.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695351000 ms.0 from job set of time 1481695351000 ms
2016-12-14 14:02:31.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695351000 ms.0 from job set of time 1481695351000 ms
2016-12-14 14:02:31.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 8 from persistence list
2016-12-14 14:02:31.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695351000 ms (execution: 0.001 s)
2016-12-14 14:02:31.008 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 8
2016-12-14 14:02:31.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[8] at createStream at LogStream.java:100 of time 1481695351000 ms
2016-12-14 14:02:31.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695349000 ms)
2016-12-14 14:02:31.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695349000 ms
2016-12-14 14:02:32.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695352000 ms
2016-12-14 14:02:32.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695352000 ms.0 from job set of time 1481695352000 ms
2016-12-14 14:02:32.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695352000 ms.0 from job set of time 1481695352000 ms
2016-12-14 14:02:32.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 9 from persistence list
2016-12-14 14:02:32.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695352000 ms (execution: 0.000 s)
2016-12-14 14:02:32.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 9
2016-12-14 14:02:32.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[9] at createStream at LogStream.java:100 of time 1481695352000 ms
2016-12-14 14:02:32.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695350000 ms)
2016-12-14 14:02:32.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695350000 ms
2016-12-14 14:02:33.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695353000 ms
2016-12-14 14:02:33.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695353000 ms.0 from job set of time 1481695353000 ms
2016-12-14 14:02:33.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695353000 ms.0 from job set of time 1481695353000 ms
2016-12-14 14:02:33.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 10 from persistence list
2016-12-14 14:02:33.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695353000 ms (execution: 0.001 s)
2016-12-14 14:02:33.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 10
2016-12-14 14:02:33.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[10] at createStream at LogStream.java:100 of time 1481695353000 ms
2016-12-14 14:02:33.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695351000 ms)
2016-12-14 14:02:33.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695351000 ms
2016-12-14 14:02:34.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695354000 ms
2016-12-14 14:02:34.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695354000 ms.0 from job set of time 1481695354000 ms
2016-12-14 14:02:34.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695354000 ms.0 from job set of time 1481695354000 ms
2016-12-14 14:02:34.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695354000 ms (execution: 0.000 s)
2016-12-14 14:02:34.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 11 from persistence list
2016-12-14 14:02:34.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 11
2016-12-14 14:02:34.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[11] at createStream at LogStream.java:100 of time 1481695354000 ms
2016-12-14 14:02:34.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695352000 ms)
2016-12-14 14:02:34.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695352000 ms
2016-12-14 14:02:35.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695355000 ms
2016-12-14 14:02:35.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695355000 ms.0 from job set of time 1481695355000 ms
2016-12-14 14:02:35.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695355000 ms.0 from job set of time 1481695355000 ms
2016-12-14 14:02:35.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695355000 ms (execution: 0.000 s)
2016-12-14 14:02:35.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 12 from persistence list
2016-12-14 14:02:35.003 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 12
2016-12-14 14:02:35.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[12] at createStream at LogStream.java:100 of time 1481695355000 ms
2016-12-14 14:02:35.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695353000 ms)
2016-12-14 14:02:35.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695353000 ms
2016-12-14 14:02:36.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695356000 ms
2016-12-14 14:02:36.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695356000 ms.0 from job set of time 1481695356000 ms
2016-12-14 14:02:36.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695356000 ms.0 from job set of time 1481695356000 ms
2016-12-14 14:02:36.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695356000 ms (execution: 0.001 s)
2016-12-14 14:02:36.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 13 from persistence list
2016-12-14 14:02:36.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 13
2016-12-14 14:02:36.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[13] at createStream at LogStream.java:100 of time 1481695356000 ms
2016-12-14 14:02:36.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695354000 ms)
2016-12-14 14:02:36.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695354000 ms
2016-12-14 14:02:37.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695357000 ms
2016-12-14 14:02:37.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695357000 ms.0 from job set of time 1481695357000 ms
2016-12-14 14:02:37.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695357000 ms.0 from job set of time 1481695357000 ms
2016-12-14 14:02:37.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 14 from persistence list
2016-12-14 14:02:37.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695357000 ms (execution: 0.001 s)
2016-12-14 14:02:37.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 14
2016-12-14 14:02:37.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[14] at createStream at LogStream.java:100 of time 1481695357000 ms
2016-12-14 14:02:37.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695355000 ms)
2016-12-14 14:02:37.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695355000 ms
2016-12-14 14:02:38.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695358000 ms
2016-12-14 14:02:38.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695358000 ms.0 from job set of time 1481695358000 ms
2016-12-14 14:02:38.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695358000 ms.0 from job set of time 1481695358000 ms
2016-12-14 14:02:38.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 15 from persistence list
2016-12-14 14:02:38.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695358000 ms (execution: 0.000 s)
2016-12-14 14:02:38.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 15
2016-12-14 14:02:38.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[15] at createStream at LogStream.java:100 of time 1481695358000 ms
2016-12-14 14:02:38.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695356000 ms)
2016-12-14 14:02:38.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695356000 ms
2016-12-14 14:02:39.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695359000 ms
2016-12-14 14:02:39.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695359000 ms.0 from job set of time 1481695359000 ms
2016-12-14 14:02:39.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695359000 ms.0 from job set of time 1481695359000 ms
2016-12-14 14:02:39.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 16 from persistence list
2016-12-14 14:02:39.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695359000 ms (execution: 0.001 s)
2016-12-14 14:02:39.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 16
2016-12-14 14:02:39.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[16] at createStream at LogStream.java:100 of time 1481695359000 ms
2016-12-14 14:02:39.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695357000 ms)
2016-12-14 14:02:39.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695357000 ms
2016-12-14 14:02:40.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695360000 ms
2016-12-14 14:02:40.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695360000 ms.0 from job set of time 1481695360000 ms
2016-12-14 14:02:40.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695360000 ms.0 from job set of time 1481695360000 ms
2016-12-14 14:02:40.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695360000 ms (execution: 0.001 s)
2016-12-14 14:02:40.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 17 from persistence list
2016-12-14 14:02:40.008 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 17
2016-12-14 14:02:40.009 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[17] at createStream at LogStream.java:100 of time 1481695360000 ms
2016-12-14 14:02:40.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695358000 ms)
2016-12-14 14:02:40.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695358000 ms
2016-12-14 14:02:41.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695361000 ms
2016-12-14 14:02:41.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695361000 ms.0 from job set of time 1481695361000 ms
2016-12-14 14:02:41.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695361000 ms.0 from job set of time 1481695361000 ms
2016-12-14 14:02:41.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 18 from persistence list
2016-12-14 14:02:41.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695361000 ms (execution: 0.000 s)
2016-12-14 14:02:41.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 18
2016-12-14 14:02:41.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[18] at createStream at LogStream.java:100 of time 1481695361000 ms
2016-12-14 14:02:41.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695359000 ms)
2016-12-14 14:02:41.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695359000 ms
2016-12-14 14:02:42.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695362000 ms
2016-12-14 14:02:42.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695362000 ms.0 from job set of time 1481695362000 ms
2016-12-14 14:02:42.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695362000 ms.0 from job set of time 1481695362000 ms
2016-12-14 14:02:42.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 19 from persistence list
2016-12-14 14:02:42.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695362000 ms (execution: 0.001 s)
2016-12-14 14:02:42.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 19
2016-12-14 14:02:42.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[19] at createStream at LogStream.java:100 of time 1481695362000 ms
2016-12-14 14:02:42.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695360000 ms)
2016-12-14 14:02:42.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695360000 ms
2016-12-14 14:02:43.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695363000 ms
2016-12-14 14:02:43.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695363000 ms.0 from job set of time 1481695363000 ms
2016-12-14 14:02:43.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695363000 ms.0 from job set of time 1481695363000 ms
2016-12-14 14:02:43.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 20 from persistence list
2016-12-14 14:02:43.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695363000 ms (execution: 0.001 s)
2016-12-14 14:02:43.003 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 20
2016-12-14 14:02:43.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[20] at createStream at LogStream.java:100 of time 1481695363000 ms
2016-12-14 14:02:43.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695361000 ms)
2016-12-14 14:02:43.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695361000 ms
2016-12-14 14:02:44.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695364000 ms
2016-12-14 14:02:44.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695364000 ms.0 from job set of time 1481695364000 ms
2016-12-14 14:02:44.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695364000 ms.0 from job set of time 1481695364000 ms
2016-12-14 14:02:44.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 21 from persistence list
2016-12-14 14:02:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695364000 ms (execution: 0.000 s)
2016-12-14 14:02:44.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 21
2016-12-14 14:02:44.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[21] at createStream at LogStream.java:100 of time 1481695364000 ms
2016-12-14 14:02:44.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695362000 ms)
2016-12-14 14:02:44.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695362000 ms
2016-12-14 14:02:45.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695365000 ms
2016-12-14 14:02:45.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695365000 ms.0 from job set of time 1481695365000 ms
2016-12-14 14:02:45.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695365000 ms.0 from job set of time 1481695365000 ms
2016-12-14 14:02:45.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 22 from persistence list
2016-12-14 14:02:45.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695365000 ms (execution: 0.001 s)
2016-12-14 14:02:45.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 22
2016-12-14 14:02:45.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[22] at createStream at LogStream.java:100 of time 1481695365000 ms
2016-12-14 14:02:45.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695363000 ms)
2016-12-14 14:02:45.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695363000 ms
2016-12-14 14:02:46.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695366000 ms
2016-12-14 14:02:46.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695366000 ms.0 from job set of time 1481695366000 ms
2016-12-14 14:02:46.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695366000 ms.0 from job set of time 1481695366000 ms
2016-12-14 14:02:46.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 23 from persistence list
2016-12-14 14:02:46.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695366000 ms (execution: 0.000 s)
2016-12-14 14:02:46.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 23
2016-12-14 14:02:46.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[23] at createStream at LogStream.java:100 of time 1481695366000 ms
2016-12-14 14:02:46.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695364000 ms)
2016-12-14 14:02:46.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695364000 ms
2016-12-14 14:02:47.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695367000 ms
2016-12-14 14:02:47.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695367000 ms.0 from job set of time 1481695367000 ms
2016-12-14 14:02:47.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695367000 ms.0 from job set of time 1481695367000 ms
2016-12-14 14:02:47.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 24 from persistence list
2016-12-14 14:02:47.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695367000 ms (execution: 0.000 s)
2016-12-14 14:02:47.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 24
2016-12-14 14:02:47.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[24] at createStream at LogStream.java:100 of time 1481695367000 ms
2016-12-14 14:02:47.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695365000 ms)
2016-12-14 14:02:47.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695365000 ms
2016-12-14 14:02:48.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695368000 ms
2016-12-14 14:02:48.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695368000 ms.0 from job set of time 1481695368000 ms
2016-12-14 14:02:48.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695368000 ms.0 from job set of time 1481695368000 ms
2016-12-14 14:02:48.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 25 from persistence list
2016-12-14 14:02:48.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695368000 ms (execution: 0.000 s)
2016-12-14 14:02:48.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 25
2016-12-14 14:02:48.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[25] at createStream at LogStream.java:100 of time 1481695368000 ms
2016-12-14 14:02:48.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695366000 ms)
2016-12-14 14:02:48.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695366000 ms
2016-12-14 14:02:49.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695369000 ms
2016-12-14 14:02:49.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695369000 ms.0 from job set of time 1481695369000 ms
2016-12-14 14:02:49.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695369000 ms.0 from job set of time 1481695369000 ms
2016-12-14 14:02:49.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 26 from persistence list
2016-12-14 14:02:49.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695369000 ms (execution: 0.002 s)
2016-12-14 14:02:49.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 26
2016-12-14 14:02:49.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[26] at createStream at LogStream.java:100 of time 1481695369000 ms
2016-12-14 14:02:49.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695367000 ms)
2016-12-14 14:02:49.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695367000 ms
2016-12-14 14:02:50.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695370000 ms
2016-12-14 14:02:50.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695370000 ms.0 from job set of time 1481695370000 ms
2016-12-14 14:02:50.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695370000 ms.0 from job set of time 1481695370000 ms
2016-12-14 14:02:50.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 27 from persistence list
2016-12-14 14:02:50.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695370000 ms (execution: 0.001 s)
2016-12-14 14:02:50.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 27
2016-12-14 14:02:50.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[27] at createStream at LogStream.java:100 of time 1481695370000 ms
2016-12-14 14:02:50.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695368000 ms)
2016-12-14 14:02:50.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695368000 ms
2016-12-14 14:02:51.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695371000 ms
2016-12-14 14:02:51.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695371000 ms.0 from job set of time 1481695371000 ms
2016-12-14 14:02:51.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695371000 ms.0 from job set of time 1481695371000 ms
2016-12-14 14:02:51.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 28 from persistence list
2016-12-14 14:02:51.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695371000 ms (execution: 0.001 s)
2016-12-14 14:02:51.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 28
2016-12-14 14:02:51.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[28] at createStream at LogStream.java:100 of time 1481695371000 ms
2016-12-14 14:02:51.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695369000 ms)
2016-12-14 14:02:51.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695369000 ms
2016-12-14 14:02:52.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695372000 ms
2016-12-14 14:02:52.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695372000 ms.0 from job set of time 1481695372000 ms
2016-12-14 14:02:52.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695372000 ms.0 from job set of time 1481695372000 ms
2016-12-14 14:02:52.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 29 from persistence list
2016-12-14 14:02:52.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695372000 ms (execution: 0.001 s)
2016-12-14 14:02:52.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 29
2016-12-14 14:02:52.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[29] at createStream at LogStream.java:100 of time 1481695372000 ms
2016-12-14 14:02:52.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695370000 ms)
2016-12-14 14:02:52.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695370000 ms
2016-12-14 14:02:53.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695373000 ms
2016-12-14 14:02:53.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695373000 ms.0 from job set of time 1481695373000 ms
2016-12-14 14:02:53.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695373000 ms.0 from job set of time 1481695373000 ms
2016-12-14 14:02:53.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 30 from persistence list
2016-12-14 14:02:53.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695373000 ms (execution: 0.001 s)
2016-12-14 14:02:53.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 30
2016-12-14 14:02:53.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[30] at createStream at LogStream.java:100 of time 1481695373000 ms
2016-12-14 14:02:53.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695371000 ms)
2016-12-14 14:02:53.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695371000 ms
2016-12-14 14:02:54.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695374000 ms
2016-12-14 14:02:54.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695374000 ms.0 from job set of time 1481695374000 ms
2016-12-14 14:02:54.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695374000 ms.0 from job set of time 1481695374000 ms
2016-12-14 14:02:54.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 31 from persistence list
2016-12-14 14:02:54.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695374000 ms (execution: 0.000 s)
2016-12-14 14:02:54.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 31
2016-12-14 14:02:54.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[31] at createStream at LogStream.java:100 of time 1481695374000 ms
2016-12-14 14:02:54.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695372000 ms)
2016-12-14 14:02:54.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695372000 ms
2016-12-14 14:02:55.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695375000 ms.0 from job set of time 1481695375000 ms
2016-12-14 14:02:55.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695375000 ms
2016-12-14 14:02:55.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695375000 ms.0 from job set of time 1481695375000 ms
2016-12-14 14:02:55.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695375000 ms (execution: 0.001 s)
2016-12-14 14:02:55.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 32 from persistence list
2016-12-14 14:02:55.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 32
2016-12-14 14:02:55.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[32] at createStream at LogStream.java:100 of time 1481695375000 ms
2016-12-14 14:02:55.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695373000 ms)
2016-12-14 14:02:55.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695373000 ms
2016-12-14 14:02:56.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695376000 ms
2016-12-14 14:02:56.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695376000 ms.0 from job set of time 1481695376000 ms
2016-12-14 14:02:56.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695376000 ms.0 from job set of time 1481695376000 ms
2016-12-14 14:02:56.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 33 from persistence list
2016-12-14 14:02:56.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695376000 ms (execution: 0.001 s)
2016-12-14 14:02:56.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 33
2016-12-14 14:02:56.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[33] at createStream at LogStream.java:100 of time 1481695376000 ms
2016-12-14 14:02:56.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695374000 ms)
2016-12-14 14:02:56.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695374000 ms
2016-12-14 14:02:57.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695377000 ms
2016-12-14 14:02:57.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695377000 ms.0 from job set of time 1481695377000 ms
2016-12-14 14:02:57.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695377000 ms.0 from job set of time 1481695377000 ms
2016-12-14 14:02:57.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 34 from persistence list
2016-12-14 14:02:57.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695377000 ms (execution: 0.001 s)
2016-12-14 14:02:57.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 34
2016-12-14 14:02:57.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[34] at createStream at LogStream.java:100 of time 1481695377000 ms
2016-12-14 14:02:57.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695375000 ms)
2016-12-14 14:02:57.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695375000 ms
2016-12-14 14:02:58.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695378000 ms
2016-12-14 14:02:58.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695378000 ms.0 from job set of time 1481695378000 ms
2016-12-14 14:02:58.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695378000 ms.0 from job set of time 1481695378000 ms
2016-12-14 14:02:58.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 35 from persistence list
2016-12-14 14:02:58.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695378000 ms (execution: 0.001 s)
2016-12-14 14:02:58.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 35
2016-12-14 14:02:58.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[35] at createStream at LogStream.java:100 of time 1481695378000 ms
2016-12-14 14:02:58.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695376000 ms)
2016-12-14 14:02:58.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695376000 ms
2016-12-14 14:02:59.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695379000 ms
2016-12-14 14:02:59.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695379000 ms.0 from job set of time 1481695379000 ms
2016-12-14 14:02:59.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695379000 ms.0 from job set of time 1481695379000 ms
2016-12-14 14:02:59.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695379000 ms (execution: 0.001 s)
2016-12-14 14:02:59.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 36 from persistence list
2016-12-14 14:02:59.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 36
2016-12-14 14:02:59.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[36] at createStream at LogStream.java:100 of time 1481695379000 ms
2016-12-14 14:02:59.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695377000 ms)
2016-12-14 14:02:59.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695377000 ms
2016-12-14 14:03:00.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695380000 ms
2016-12-14 14:03:00.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695380000 ms.0 from job set of time 1481695380000 ms
2016-12-14 14:03:00.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695380000 ms.0 from job set of time 1481695380000 ms
2016-12-14 14:03:00.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 37 from persistence list
2016-12-14 14:03:00.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695380000 ms (execution: 0.001 s)
2016-12-14 14:03:00.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 37
2016-12-14 14:03:00.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[37] at createStream at LogStream.java:100 of time 1481695380000 ms
2016-12-14 14:03:00.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695378000 ms)
2016-12-14 14:03:00.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695378000 ms
2016-12-14 14:03:01.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695381000 ms
2016-12-14 14:03:01.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695381000 ms.0 from job set of time 1481695381000 ms
2016-12-14 14:03:01.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695381000 ms.0 from job set of time 1481695381000 ms
2016-12-14 14:03:01.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 38 from persistence list
2016-12-14 14:03:01.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695381000 ms (execution: 0.000 s)
2016-12-14 14:03:01.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 38
2016-12-14 14:03:01.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[38] at createStream at LogStream.java:100 of time 1481695381000 ms
2016-12-14 14:03:01.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695379000 ms)
2016-12-14 14:03:01.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695379000 ms
2016-12-14 14:03:02.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695382000 ms
2016-12-14 14:03:02.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695382000 ms.0 from job set of time 1481695382000 ms
2016-12-14 14:03:02.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695382000 ms.0 from job set of time 1481695382000 ms
2016-12-14 14:03:02.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695382000 ms (execution: 0.000 s)
2016-12-14 14:03:02.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 39 from persistence list
2016-12-14 14:03:02.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 39
2016-12-14 14:03:02.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[39] at createStream at LogStream.java:100 of time 1481695382000 ms
2016-12-14 14:03:02.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695380000 ms)
2016-12-14 14:03:02.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695380000 ms
2016-12-14 14:03:03.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695383000 ms
2016-12-14 14:03:03.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695383000 ms.0 from job set of time 1481695383000 ms
2016-12-14 14:03:03.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695383000 ms.0 from job set of time 1481695383000 ms
2016-12-14 14:03:03.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 40 from persistence list
2016-12-14 14:03:03.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695383000 ms (execution: 0.001 s)
2016-12-14 14:03:03.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 40
2016-12-14 14:03:03.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[40] at createStream at LogStream.java:100 of time 1481695383000 ms
2016-12-14 14:03:03.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695381000 ms)
2016-12-14 14:03:03.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695381000 ms
2016-12-14 14:03:04.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695384000 ms
2016-12-14 14:03:04.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695384000 ms.0 from job set of time 1481695384000 ms
2016-12-14 14:03:04.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695384000 ms.0 from job set of time 1481695384000 ms
2016-12-14 14:03:04.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 41 from persistence list
2016-12-14 14:03:04.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695384000 ms (execution: 0.000 s)
2016-12-14 14:03:04.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 41
2016-12-14 14:03:04.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[41] at createStream at LogStream.java:100 of time 1481695384000 ms
2016-12-14 14:03:04.008 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695382000 ms)
2016-12-14 14:03:04.008 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695382000 ms
2016-12-14 14:03:05.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695385000 ms
2016-12-14 14:03:05.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695385000 ms.0 from job set of time 1481695385000 ms
2016-12-14 14:03:05.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695385000 ms.0 from job set of time 1481695385000 ms
2016-12-14 14:03:05.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695385000 ms (execution: 0.000 s)
2016-12-14 14:03:05.007 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 42 from persistence list
2016-12-14 14:03:05.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 42
2016-12-14 14:03:05.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[42] at createStream at LogStream.java:100 of time 1481695385000 ms
2016-12-14 14:03:05.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695383000 ms)
2016-12-14 14:03:05.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695383000 ms
2016-12-14 14:03:06.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695386000 ms
2016-12-14 14:03:06.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695386000 ms.0 from job set of time 1481695386000 ms
2016-12-14 14:03:06.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695386000 ms.0 from job set of time 1481695386000 ms
2016-12-14 14:03:06.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 43 from persistence list
2016-12-14 14:03:06.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695386000 ms (execution: 0.000 s)
2016-12-14 14:03:06.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 43
2016-12-14 14:03:06.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[43] at createStream at LogStream.java:100 of time 1481695386000 ms
2016-12-14 14:03:06.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695384000 ms)
2016-12-14 14:03:06.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695384000 ms
2016-12-14 14:03:07.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695387000 ms
2016-12-14 14:03:07.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695387000 ms.0 from job set of time 1481695387000 ms
2016-12-14 14:03:07.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695387000 ms.0 from job set of time 1481695387000 ms
2016-12-14 14:03:07.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 44 from persistence list
2016-12-14 14:03:07.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695387000 ms (execution: 0.000 s)
2016-12-14 14:03:07.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 44
2016-12-14 14:03:07.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[44] at createStream at LogStream.java:100 of time 1481695387000 ms
2016-12-14 14:03:07.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695385000 ms)
2016-12-14 14:03:07.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695385000 ms
2016-12-14 14:03:08.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695388000 ms
2016-12-14 14:03:08.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695388000 ms.0 from job set of time 1481695388000 ms
2016-12-14 14:03:08.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695388000 ms.0 from job set of time 1481695388000 ms
2016-12-14 14:03:08.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 45 from persistence list
2016-12-14 14:03:08.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695388000 ms (execution: 0.000 s)
2016-12-14 14:03:08.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 45
2016-12-14 14:03:08.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[45] at createStream at LogStream.java:100 of time 1481695388000 ms
2016-12-14 14:03:08.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695386000 ms)
2016-12-14 14:03:08.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695386000 ms
2016-12-14 14:03:09.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695389000 ms
2016-12-14 14:03:09.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695389000 ms.0 from job set of time 1481695389000 ms
2016-12-14 14:03:09.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695389000 ms.0 from job set of time 1481695389000 ms
2016-12-14 14:03:09.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 46 from persistence list
2016-12-14 14:03:09.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 46
2016-12-14 14:03:09.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[46] at createStream at LogStream.java:100 of time 1481695389000 ms
2016-12-14 14:03:09.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695387000 ms)
2016-12-14 14:03:09.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695387000 ms
2016-12-14 14:03:09.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695389000 ms (execution: 0.001 s)
2016-12-14 14:03:10.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695390000 ms
2016-12-14 14:03:10.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695390000 ms.0 from job set of time 1481695390000 ms
2016-12-14 14:03:10.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695390000 ms.0 from job set of time 1481695390000 ms
2016-12-14 14:03:10.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 47 from persistence list
2016-12-14 14:03:10.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695390000 ms (execution: 0.000 s)
2016-12-14 14:03:10.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 47
2016-12-14 14:03:10.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[47] at createStream at LogStream.java:100 of time 1481695390000 ms
2016-12-14 14:03:10.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695388000 ms)
2016-12-14 14:03:10.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695388000 ms
2016-12-14 14:03:11.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695391000 ms
2016-12-14 14:03:11.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695391000 ms.0 from job set of time 1481695391000 ms
2016-12-14 14:03:11.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695391000 ms.0 from job set of time 1481695391000 ms
2016-12-14 14:03:11.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 48 from persistence list
2016-12-14 14:03:11.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695391000 ms (execution: 0.001 s)
2016-12-14 14:03:11.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 48
2016-12-14 14:03:11.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[48] at createStream at LogStream.java:100 of time 1481695391000 ms
2016-12-14 14:03:11.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695389000 ms)
2016-12-14 14:03:11.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695389000 ms
2016-12-14 14:03:12.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695392000 ms
2016-12-14 14:03:12.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695392000 ms.0 from job set of time 1481695392000 ms
2016-12-14 14:03:12.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695392000 ms.0 from job set of time 1481695392000 ms
2016-12-14 14:03:12.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 49 from persistence list
2016-12-14 14:03:12.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695392000 ms (execution: 0.000 s)
2016-12-14 14:03:12.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 49
2016-12-14 14:03:12.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[49] at createStream at LogStream.java:100 of time 1481695392000 ms
2016-12-14 14:03:12.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695390000 ms)
2016-12-14 14:03:12.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695390000 ms
2016-12-14 14:03:13.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695393000 ms
2016-12-14 14:03:13.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695393000 ms.0 from job set of time 1481695393000 ms
2016-12-14 14:03:13.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695393000 ms.0 from job set of time 1481695393000 ms
2016-12-14 14:03:13.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 50 from persistence list
2016-12-14 14:03:13.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695393000 ms (execution: 0.001 s)
2016-12-14 14:03:13.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 50
2016-12-14 14:03:13.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[50] at createStream at LogStream.java:100 of time 1481695393000 ms
2016-12-14 14:03:13.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695391000 ms)
2016-12-14 14:03:13.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695391000 ms
2016-12-14 14:03:14.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695394000 ms
2016-12-14 14:03:14.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695394000 ms.0 from job set of time 1481695394000 ms
2016-12-14 14:03:14.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695394000 ms.0 from job set of time 1481695394000 ms
2016-12-14 14:03:14.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 51 from persistence list
2016-12-14 14:03:14.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695394000 ms (execution: 0.001 s)
2016-12-14 14:03:14.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 51
2016-12-14 14:03:14.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[51] at createStream at LogStream.java:100 of time 1481695394000 ms
2016-12-14 14:03:14.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695392000 ms)
2016-12-14 14:03:14.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695392000 ms
2016-12-14 14:03:15.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695395000 ms
2016-12-14 14:03:15.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695395000 ms.0 from job set of time 1481695395000 ms
2016-12-14 14:03:15.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695395000 ms.0 from job set of time 1481695395000 ms
2016-12-14 14:03:15.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 52 from persistence list
2016-12-14 14:03:15.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695395000 ms (execution: 0.001 s)
2016-12-14 14:03:15.002 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 52
2016-12-14 14:03:15.002 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[52] at createStream at LogStream.java:100 of time 1481695395000 ms
2016-12-14 14:03:15.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695393000 ms)
2016-12-14 14:03:15.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695393000 ms
2016-12-14 14:03:16.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695396000 ms
2016-12-14 14:03:16.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695396000 ms.0 from job set of time 1481695396000 ms
2016-12-14 14:03:16.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695396000 ms.0 from job set of time 1481695396000 ms
2016-12-14 14:03:16.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 53 from persistence list
2016-12-14 14:03:16.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695396000 ms (execution: 0.000 s)
2016-12-14 14:03:16.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 53
2016-12-14 14:03:16.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[53] at createStream at LogStream.java:100 of time 1481695396000 ms
2016-12-14 14:03:16.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695394000 ms)
2016-12-14 14:03:16.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695394000 ms
2016-12-14 14:03:17.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695397000 ms
2016-12-14 14:03:17.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695397000 ms.0 from job set of time 1481695397000 ms
2016-12-14 14:03:17.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695397000 ms.0 from job set of time 1481695397000 ms
2016-12-14 14:03:17.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695397000 ms (execution: 0.001 s)
2016-12-14 14:03:17.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 54 from persistence list
2016-12-14 14:03:17.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 54
2016-12-14 14:03:17.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[54] at createStream at LogStream.java:100 of time 1481695397000 ms
2016-12-14 14:03:17.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695395000 ms)
2016-12-14 14:03:17.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695395000 ms
2016-12-14 14:03:18.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695398000 ms
2016-12-14 14:03:18.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695398000 ms.0 from job set of time 1481695398000 ms
2016-12-14 14:03:18.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695398000 ms.0 from job set of time 1481695398000 ms
2016-12-14 14:03:18.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695398000 ms (execution: 0.001 s)
2016-12-14 14:03:18.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 55 from persistence list
2016-12-14 14:03:18.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 55
2016-12-14 14:03:18.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[55] at createStream at LogStream.java:100 of time 1481695398000 ms
2016-12-14 14:03:18.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695396000 ms)
2016-12-14 14:03:18.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695396000 ms
2016-12-14 14:03:19.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695399000 ms
2016-12-14 14:03:19.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695399000 ms.0 from job set of time 1481695399000 ms
2016-12-14 14:03:19.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695399000 ms.0 from job set of time 1481695399000 ms
2016-12-14 14:03:19.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695399000 ms (execution: 0.000 s)
2016-12-14 14:03:19.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 56 from persistence list
2016-12-14 14:03:19.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 56
2016-12-14 14:03:19.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[56] at createStream at LogStream.java:100 of time 1481695399000 ms
2016-12-14 14:03:19.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695397000 ms)
2016-12-14 14:03:19.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695397000 ms
2016-12-14 14:03:20.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695400000 ms
2016-12-14 14:03:20.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695400000 ms.0 from job set of time 1481695400000 ms
2016-12-14 14:03:20.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695400000 ms.0 from job set of time 1481695400000 ms
2016-12-14 14:03:20.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 57 from persistence list
2016-12-14 14:03:20.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695400000 ms (execution: 0.001 s)
2016-12-14 14:03:20.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 57
2016-12-14 14:03:20.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[57] at createStream at LogStream.java:100 of time 1481695400000 ms
2016-12-14 14:03:20.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695398000 ms)
2016-12-14 14:03:20.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695398000 ms
2016-12-14 14:03:21.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695401000 ms
2016-12-14 14:03:21.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695401000 ms.0 from job set of time 1481695401000 ms
2016-12-14 14:03:21.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695401000 ms.0 from job set of time 1481695401000 ms
2016-12-14 14:03:21.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 58 from persistence list
2016-12-14 14:03:21.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695401000 ms (execution: 0.001 s)
2016-12-14 14:03:21.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 58
2016-12-14 14:03:21.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[58] at createStream at LogStream.java:100 of time 1481695401000 ms
2016-12-14 14:03:21.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695399000 ms)
2016-12-14 14:03:21.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695399000 ms
2016-12-14 14:03:22.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695402000 ms
2016-12-14 14:03:22.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695402000 ms.0 from job set of time 1481695402000 ms
2016-12-14 14:03:22.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695402000 ms.0 from job set of time 1481695402000 ms
2016-12-14 14:03:22.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 59 from persistence list
2016-12-14 14:03:22.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695402000 ms (execution: 0.001 s)
2016-12-14 14:03:22.002 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 59
2016-12-14 14:03:22.002 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[59] at createStream at LogStream.java:100 of time 1481695402000 ms
2016-12-14 14:03:22.002 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695400000 ms)
2016-12-14 14:03:22.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695400000 ms
2016-12-14 14:03:23.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695403000 ms
2016-12-14 14:03:23.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695403000 ms.0 from job set of time 1481695403000 ms
2016-12-14 14:03:23.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695403000 ms.0 from job set of time 1481695403000 ms
2016-12-14 14:03:23.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 60 from persistence list
2016-12-14 14:03:23.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695403000 ms (execution: 0.000 s)
2016-12-14 14:03:23.003 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 60
2016-12-14 14:03:23.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[60] at createStream at LogStream.java:100 of time 1481695403000 ms
2016-12-14 14:03:23.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695401000 ms)
2016-12-14 14:03:23.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695401000 ms
2016-12-14 14:03:24.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695404000 ms
2016-12-14 14:03:24.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695404000 ms.0 from job set of time 1481695404000 ms
2016-12-14 14:03:24.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695404000 ms.0 from job set of time 1481695404000 ms
2016-12-14 14:03:24.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 61 from persistence list
2016-12-14 14:03:24.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695404000 ms (execution: 0.001 s)
2016-12-14 14:03:24.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 61
2016-12-14 14:03:24.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[61] at createStream at LogStream.java:100 of time 1481695404000 ms
2016-12-14 14:03:24.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695402000 ms)
2016-12-14 14:03:24.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695402000 ms
2016-12-14 14:03:25.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695405000 ms
2016-12-14 14:03:25.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695405000 ms.0 from job set of time 1481695405000 ms
2016-12-14 14:03:25.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695405000 ms.0 from job set of time 1481695405000 ms
2016-12-14 14:03:25.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 62 from persistence list
2016-12-14 14:03:25.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695405000 ms (execution: 0.001 s)
2016-12-14 14:03:25.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 62
2016-12-14 14:03:25.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[62] at createStream at LogStream.java:100 of time 1481695405000 ms
2016-12-14 14:03:25.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695403000 ms)
2016-12-14 14:03:25.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695403000 ms
2016-12-14 14:03:26.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695406000 ms
2016-12-14 14:03:26.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695406000 ms.0 from job set of time 1481695406000 ms
2016-12-14 14:03:26.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695406000 ms.0 from job set of time 1481695406000 ms
2016-12-14 14:03:26.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695406000 ms (execution: 0.001 s)
2016-12-14 14:03:26.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 63 from persistence list
2016-12-14 14:03:26.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 63
2016-12-14 14:03:26.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[63] at createStream at LogStream.java:100 of time 1481695406000 ms
2016-12-14 14:03:26.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695404000 ms)
2016-12-14 14:03:26.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695404000 ms
2016-12-14 14:03:27.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695407000 ms
2016-12-14 14:03:27.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695407000 ms.0 from job set of time 1481695407000 ms
2016-12-14 14:03:27.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695407000 ms.0 from job set of time 1481695407000 ms
2016-12-14 14:03:27.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695407000 ms (execution: 0.001 s)
2016-12-14 14:03:27.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 64 from persistence list
2016-12-14 14:03:27.006 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 64
2016-12-14 14:03:27.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[64] at createStream at LogStream.java:100 of time 1481695407000 ms
2016-12-14 14:03:27.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695405000 ms)
2016-12-14 14:03:27.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695405000 ms
2016-12-14 14:03:28.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695408000 ms
2016-12-14 14:03:28.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695408000 ms.0 from job set of time 1481695408000 ms
2016-12-14 14:03:28.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695408000 ms.0 from job set of time 1481695408000 ms
2016-12-14 14:03:28.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 65 from persistence list
2016-12-14 14:03:28.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695408000 ms (execution: 0.001 s)
2016-12-14 14:03:28.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 65
2016-12-14 14:03:28.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[65] at createStream at LogStream.java:100 of time 1481695408000 ms
2016-12-14 14:03:28.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695406000 ms)
2016-12-14 14:03:28.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695406000 ms
2016-12-14 14:03:29.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695409000 ms
2016-12-14 14:03:29.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695409000 ms.0 from job set of time 1481695409000 ms
2016-12-14 14:03:29.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695409000 ms.0 from job set of time 1481695409000 ms
2016-12-14 14:03:29.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695409000 ms (execution: 0.000 s)
2016-12-14 14:03:29.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 66 from persistence list
2016-12-14 14:03:29.003 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 66
2016-12-14 14:03:29.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[66] at createStream at LogStream.java:100 of time 1481695409000 ms
2016-12-14 14:03:29.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695407000 ms)
2016-12-14 14:03:29.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695407000 ms
2016-12-14 14:03:30.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695410000 ms
2016-12-14 14:03:30.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695410000 ms.0 from job set of time 1481695410000 ms
2016-12-14 14:03:30.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695410000 ms.0 from job set of time 1481695410000 ms
2016-12-14 14:03:30.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 67 from persistence list
2016-12-14 14:03:30.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695410000 ms (execution: 0.001 s)
2016-12-14 14:03:30.007 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 67
2016-12-14 14:03:30.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[67] at createStream at LogStream.java:100 of time 1481695410000 ms
2016-12-14 14:03:30.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695408000 ms)
2016-12-14 14:03:30.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695408000 ms
2016-12-14 14:03:31.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695411000 ms
2016-12-14 14:03:31.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695411000 ms.0 from job set of time 1481695411000 ms
2016-12-14 14:03:31.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695411000 ms.0 from job set of time 1481695411000 ms
2016-12-14 14:03:31.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 68 from persistence list
2016-12-14 14:03:31.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695411000 ms (execution: 0.000 s)
2016-12-14 14:03:31.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 68
2016-12-14 14:03:31.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[68] at createStream at LogStream.java:100 of time 1481695411000 ms
2016-12-14 14:03:31.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695409000 ms)
2016-12-14 14:03:31.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695409000 ms
2016-12-14 14:03:32.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695412000 ms
2016-12-14 14:03:32.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695412000 ms.0 from job set of time 1481695412000 ms
2016-12-14 14:03:32.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695412000 ms.0 from job set of time 1481695412000 ms
2016-12-14 14:03:32.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 69 from persistence list
2016-12-14 14:03:32.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695412000 ms (execution: 0.001 s)
2016-12-14 14:03:32.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 69
2016-12-14 14:03:32.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[69] at createStream at LogStream.java:100 of time 1481695412000 ms
2016-12-14 14:03:32.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695410000 ms)
2016-12-14 14:03:32.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695410000 ms
2016-12-14 14:03:33.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695413000 ms
2016-12-14 14:03:33.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695413000 ms.0 from job set of time 1481695413000 ms
2016-12-14 14:03:33.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695413000 ms.0 from job set of time 1481695413000 ms
2016-12-14 14:03:33.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 70 from persistence list
2016-12-14 14:03:33.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695413000 ms (execution: 0.000 s)
2016-12-14 14:03:33.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 70
2016-12-14 14:03:33.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[70] at createStream at LogStream.java:100 of time 1481695413000 ms
2016-12-14 14:03:33.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695411000 ms)
2016-12-14 14:03:33.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695411000 ms
2016-12-14 14:03:34.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695414000 ms
2016-12-14 14:03:34.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695414000 ms.0 from job set of time 1481695414000 ms
2016-12-14 14:03:34.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695414000 ms.0 from job set of time 1481695414000 ms
2016-12-14 14:03:34.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 71 from persistence list
2016-12-14 14:03:34.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695414000 ms (execution: 0.001 s)
2016-12-14 14:03:34.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 71
2016-12-14 14:03:34.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[71] at createStream at LogStream.java:100 of time 1481695414000 ms
2016-12-14 14:03:34.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695412000 ms)
2016-12-14 14:03:34.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695412000 ms
2016-12-14 14:03:35.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695415000 ms
2016-12-14 14:03:35.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695415000 ms.0 from job set of time 1481695415000 ms
2016-12-14 14:03:35.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695415000 ms.0 from job set of time 1481695415000 ms
2016-12-14 14:03:35.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695415000 ms (execution: 0.001 s)
2016-12-14 14:03:35.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 72 from persistence list
2016-12-14 14:03:35.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 72
2016-12-14 14:03:35.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[72] at createStream at LogStream.java:100 of time 1481695415000 ms
2016-12-14 14:03:35.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695413000 ms)
2016-12-14 14:03:35.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695413000 ms
2016-12-14 14:03:36.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695416000 ms
2016-12-14 14:03:36.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695416000 ms.0 from job set of time 1481695416000 ms
2016-12-14 14:03:36.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695416000 ms.0 from job set of time 1481695416000 ms
2016-12-14 14:03:36.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695416000 ms (execution: 0.000 s)
2016-12-14 14:03:36.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 73 from persistence list
2016-12-14 14:03:36.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[73] at createStream at LogStream.java:100 of time 1481695416000 ms
2016-12-14 14:03:36.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 73
2016-12-14 14:03:36.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695414000 ms)
2016-12-14 14:03:36.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695414000 ms
2016-12-14 14:03:37.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695417000 ms
2016-12-14 14:03:37.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695417000 ms.0 from job set of time 1481695417000 ms
2016-12-14 14:03:37.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695417000 ms.0 from job set of time 1481695417000 ms
2016-12-14 14:03:37.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 74 from persistence list
2016-12-14 14:03:37.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695417000 ms (execution: 0.001 s)
2016-12-14 14:03:37.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 74
2016-12-14 14:03:37.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[74] at createStream at LogStream.java:100 of time 1481695417000 ms
2016-12-14 14:03:37.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695415000 ms)
2016-12-14 14:03:37.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695415000 ms
2016-12-14 14:03:38.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695418000 ms
2016-12-14 14:03:38.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695418000 ms.0 from job set of time 1481695418000 ms
2016-12-14 14:03:38.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695418000 ms.0 from job set of time 1481695418000 ms
2016-12-14 14:03:38.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 75 from persistence list
2016-12-14 14:03:38.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695418000 ms (execution: 0.000 s)
2016-12-14 14:03:38.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 75
2016-12-14 14:03:38.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[75] at createStream at LogStream.java:100 of time 1481695418000 ms
2016-12-14 14:03:38.006 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695416000 ms)
2016-12-14 14:03:38.006 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695416000 ms
2016-12-14 14:03:39.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695419000 ms
2016-12-14 14:03:39.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695419000 ms.0 from job set of time 1481695419000 ms
2016-12-14 14:03:39.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695419000 ms.0 from job set of time 1481695419000 ms
2016-12-14 14:03:39.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 76 from persistence list
2016-12-14 14:03:39.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.001 s for time 1481695419000 ms (execution: 0.000 s)
2016-12-14 14:03:39.002 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 76
2016-12-14 14:03:39.002 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[76] at createStream at LogStream.java:100 of time 1481695419000 ms
2016-12-14 14:03:39.002 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695417000 ms)
2016-12-14 14:03:39.002 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695417000 ms
2016-12-14 14:03:40.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695420000 ms
2016-12-14 14:03:40.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695420000 ms.0 from job set of time 1481695420000 ms
2016-12-14 14:03:40.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695420000 ms.0 from job set of time 1481695420000 ms
2016-12-14 14:03:40.002 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 77 from persistence list
2016-12-14 14:03:40.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.001 s for time 1481695420000 ms (execution: 0.000 s)
2016-12-14 14:03:40.002 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 77
2016-12-14 14:03:40.002 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[77] at createStream at LogStream.java:100 of time 1481695420000 ms
2016-12-14 14:03:40.002 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695418000 ms)
2016-12-14 14:03:40.002 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695418000 ms
2016-12-14 14:03:41.001 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695421000 ms
2016-12-14 14:03:41.001 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695421000 ms.0 from job set of time 1481695421000 ms
2016-12-14 14:03:41.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695421000 ms.0 from job set of time 1481695421000 ms
2016-12-14 14:03:41.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 78 from persistence list
2016-12-14 14:03:41.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.002 s for time 1481695421000 ms (execution: 0.001 s)
2016-12-14 14:03:41.003 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 78
2016-12-14 14:03:41.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[78] at createStream at LogStream.java:100 of time 1481695421000 ms
2016-12-14 14:03:41.003 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695419000 ms)
2016-12-14 14:03:41.003 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695419000 ms
2016-12-14 14:03:42.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695422000 ms
2016-12-14 14:03:42.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695422000 ms.0 from job set of time 1481695422000 ms
2016-12-14 14:03:42.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695422000 ms.0 from job set of time 1481695422000 ms
2016-12-14 14:03:42.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 79 from persistence list
2016-12-14 14:03:42.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695422000 ms (execution: 0.001 s)
2016-12-14 14:03:42.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 79
2016-12-14 14:03:42.006 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[79] at createStream at LogStream.java:100 of time 1481695422000 ms
2016-12-14 14:03:42.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695420000 ms)
2016-12-14 14:03:42.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695420000 ms
2016-12-14 14:03:43.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695423000 ms
2016-12-14 14:03:43.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695423000 ms.0 from job set of time 1481695423000 ms
2016-12-14 14:03:43.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695423000 ms.0 from job set of time 1481695423000 ms
2016-12-14 14:03:43.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 80 from persistence list
2016-12-14 14:03:43.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695423000 ms (execution: 0.000 s)
2016-12-14 14:03:43.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 80
2016-12-14 14:03:43.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[80] at createStream at LogStream.java:100 of time 1481695423000 ms
2016-12-14 14:03:43.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695421000 ms)
2016-12-14 14:03:43.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695421000 ms
2016-12-14 14:03:44.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695424000 ms
2016-12-14 14:03:44.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695424000 ms.0 from job set of time 1481695424000 ms
2016-12-14 14:03:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695424000 ms.0 from job set of time 1481695424000 ms
2016-12-14 14:03:44.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 81 from persistence list
2016-12-14 14:03:44.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695424000 ms (execution: 0.001 s)
2016-12-14 14:03:44.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 81
2016-12-14 14:03:44.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[81] at createStream at LogStream.java:100 of time 1481695424000 ms
2016-12-14 14:03:44.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695422000 ms)
2016-12-14 14:03:44.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695422000 ms
2016-12-14 14:03:45.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695425000 ms
2016-12-14 14:03:45.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695425000 ms.0 from job set of time 1481695425000 ms
2016-12-14 14:03:45.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695425000 ms.0 from job set of time 1481695425000 ms
2016-12-14 14:03:45.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695425000 ms (execution: 0.001 s)
2016-12-14 14:03:45.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 82 from persistence list
2016-12-14 14:03:45.009 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[82] at createStream at LogStream.java:100 of time 1481695425000 ms
2016-12-14 14:03:45.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695423000 ms)
2016-12-14 14:03:45.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695423000 ms
2016-12-14 14:03:45.009 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 82
2016-12-14 14:03:46.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695426000 ms
2016-12-14 14:03:46.002 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695426000 ms.0 from job set of time 1481695426000 ms
2016-12-14 14:03:46.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695426000 ms.0 from job set of time 1481695426000 ms
2016-12-14 14:03:46.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 83 from persistence list
2016-12-14 14:03:46.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695426000 ms (execution: 0.001 s)
2016-12-14 14:03:46.003 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 83
2016-12-14 14:03:46.003 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[83] at createStream at LogStream.java:100 of time 1481695426000 ms
2016-12-14 14:03:46.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695424000 ms)
2016-12-14 14:03:46.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695424000 ms
2016-12-14 14:03:47.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695427000 ms
2016-12-14 14:03:47.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695427000 ms.0 from job set of time 1481695427000 ms
2016-12-14 14:03:47.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695427000 ms.0 from job set of time 1481695427000 ms
2016-12-14 14:03:47.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 84 from persistence list
2016-12-14 14:03:47.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695427000 ms (execution: 0.000 s)
2016-12-14 14:03:47.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 84
2016-12-14 14:03:47.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[84] at createStream at LogStream.java:100 of time 1481695427000 ms
2016-12-14 14:03:47.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695425000 ms)
2016-12-14 14:03:47.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695425000 ms
2016-12-14 14:03:48.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695428000 ms
2016-12-14 14:03:48.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695428000 ms.0 from job set of time 1481695428000 ms
2016-12-14 14:03:48.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695428000 ms.0 from job set of time 1481695428000 ms
2016-12-14 14:03:48.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 85 from persistence list
2016-12-14 14:03:48.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695428000 ms (execution: 0.001 s)
2016-12-14 14:03:48.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 85
2016-12-14 14:03:48.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[85] at createStream at LogStream.java:100 of time 1481695428000 ms
2016-12-14 14:03:48.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695426000 ms)
2016-12-14 14:03:48.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695426000 ms
2016-12-14 14:03:49.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695429000 ms
2016-12-14 14:03:49.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695429000 ms.0 from job set of time 1481695429000 ms
2016-12-14 14:03:49.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695429000 ms.0 from job set of time 1481695429000 ms
2016-12-14 14:03:49.005 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 86 from persistence list
2016-12-14 14:03:49.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695429000 ms (execution: 0.001 s)
2016-12-14 14:03:49.005 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 86
2016-12-14 14:03:49.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[86] at createStream at LogStream.java:100 of time 1481695429000 ms
2016-12-14 14:03:49.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695427000 ms)
2016-12-14 14:03:49.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695427000 ms
2016-12-14 14:03:50.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695430000 ms
2016-12-14 14:03:50.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695430000 ms.0 from job set of time 1481695430000 ms
2016-12-14 14:03:50.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695430000 ms.0 from job set of time 1481695430000 ms
2016-12-14 14:03:50.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 87 from persistence list
2016-12-14 14:03:50.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.004 s for time 1481695430000 ms (execution: 0.000 s)
2016-12-14 14:03:50.005 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 87
2016-12-14 14:03:50.005 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[87] at createStream at LogStream.java:100 of time 1481695430000 ms
2016-12-14 14:03:50.005 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695428000 ms)
2016-12-14 14:03:50.005 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695428000 ms
2016-12-14 14:03:51.003 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695431000 ms
2016-12-14 14:03:51.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695431000 ms.0 from job set of time 1481695431000 ms
2016-12-14 14:03:51.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695431000 ms.0 from job set of time 1481695431000 ms
2016-12-14 14:03:51.004 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 88 from persistence list
2016-12-14 14:03:51.004 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695431000 ms (execution: 0.000 s)
2016-12-14 14:03:51.004 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 88
2016-12-14 14:03:51.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[88] at createStream at LogStream.java:100 of time 1481695431000 ms
2016-12-14 14:03:51.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695429000 ms)
2016-12-14 14:03:51.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695429000 ms
2016-12-14 14:03:52.002 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695432000 ms
2016-12-14 14:03:52.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695432000 ms.0 from job set of time 1481695432000 ms
2016-12-14 14:03:52.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695432000 ms.0 from job set of time 1481695432000 ms
2016-12-14 14:03:52.003 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.003 s for time 1481695432000 ms (execution: 0.000 s)
2016-12-14 14:03:52.003 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 89 from persistence list
2016-12-14 14:03:52.004 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 89
2016-12-14 14:03:52.004 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[89] at createStream at LogStream.java:100 of time 1481695432000 ms
2016-12-14 14:03:52.004 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695430000 ms)
2016-12-14 14:03:52.004 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695430000 ms
2016-12-14 14:03:52.355 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 14:03:52.361 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 14:03:52.361 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 14:03:52.363 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 14:03:52.393 [dispatcher-event-loop-0] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05ab closed
2016-12-14 14:03:52.393 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 14:03:52.394 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 14:03:52.395 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 14:03:52.397 [dispatcher-event-loop-2] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 14:03:52.397 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 14:03:52.398 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 14:03:52.603 [dispatcher-event-loop-0] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695432600
2016-12-14 14:03:52.603 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 14:03:52.613 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 14:03:52.613 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 14:03:52.614 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 14:03:52.615 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 14:03:52.620 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 14:03:52.625 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 89651 ms on localhost (1/1)
2016-12-14 14:03:52.627 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:03:52.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 89.669 s
2016-12-14 14:03:52.639 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 14:03:52.640 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 14:03:52.641 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 14:03:52.642 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695432000
2016-12-14 14:03:52.643 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 14:03:52.646 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 14:03:52.650 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 14:03:52.652 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 14:03:52.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 14:03:52.655 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 14:03:52.656 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 14:03:52.673 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 14:03:52.673 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 14:03:52.674 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:03:52.674 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:03:52.674 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:03:52.674 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:03:52.675 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:03:52.675 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:03:52.675 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:03:52.676 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:03:52.676 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:03:52.676 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:03:52.677 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:03:52.677 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:03:52.677 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:03:52.678 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:03:52.679 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:03:52.680 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:03:52.680 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:03:52.733 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 14:03:52.743 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:03:52.755 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 14:03:52.755 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 14:03:52.756 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 14:03:52.758 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 14:03:52.760 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 14:03:52.761 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:03:52.762 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-2c497462-40cd-411b-8145-d6560ceb930c
2016-12-14 14:03:52.771 [sparkDriverActorSystem-akka.actor.default-dispatcher-15] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 14:03:52.772 [sparkDriverActorSystem-akka.actor.default-dispatcher-15] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:04:01.425 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:04:02.054 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:04:02.098 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:04:02.707 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:04:03.025 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:04:03.033 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:04:03.034 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:04:03.035 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:04:03.036 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:04:03.064 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:04:03.086 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:04:03.098 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05ac, negotiated timeout = 40000
2016-12-14 14:04:03.187 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:04:04.511 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:04:04.522 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:04:04.529 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:04:04.534 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:04:04.536 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:04:04.537 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:04:04.537 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:04:04.550 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:04:04.550 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:04:05.062 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:04:05.449 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:04:05.511 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:04:05.512 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:04:05.513 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:04:06.117 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60321.
2016-12-14 14:04:06.638 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:04:06.692 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 14:04:06.867 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60322]
2016-12-14 14:04:06.878 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60322.
2016-12-14 14:04:06.895 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:04:06.923 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:04:06.941 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-0859445d-8eca-401b-a08e-0ac1f5bf41fe
2016-12-14 14:04:06.952 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:04:07.014 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:04:07.232 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:04:07.282 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:04:07.282 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:04:07.285 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:04:07.392 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:04:07.430 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60323.
2016-12-14 14:04:07.431 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60323
2016-12-14 14:04:07.432 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:04:07.435 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60323 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60323)
2016-12-14 14:04:07.446 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:04:08.311 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 14:04:08.315 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 14:04:08.322 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:04:08.323 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:04:08.324 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:04:08.325 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:04:08.325 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:04:08.326 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@7ec8afff
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:04:08.327 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4b0d7169
2016-12-14 14:04:08.408 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695449000
2016-12-14 14:04:08.410 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695449000 ms
2016-12-14 14:04:08.411 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 14:04:08.419 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 14:04:08.428 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 14:04:08.441 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 14:04:08.442 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 14:04:08.443 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:04:08.445 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:04:08.457 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 14:04:08.634 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 14:04:08.644 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 14:04:08.646 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60323 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 14:04:08.650 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:04:08.653 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 14:04:08.655 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 14:04:08.698 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 14:04:08.713 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:04:08.810 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695449000
2016-12-14 14:04:08.811 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 14:04:08.811 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 14:04:08.820 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60321
2016-12-14 14:04:08.821 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 14:04:08.822 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 14:04:08.824 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 14:04:08.915 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@51aa6c0c
2016-12-14 14:04:08.916 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:04:08.918 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:04:08.922 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05ad, negotiated timeout = 6000
2016-12-14 14:04:08.952 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 14:04:09.031 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695449000 ms
2016-12-14 14:04:09.033 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695449000 ms.0 from job set of time 1481695449000 ms
2016-12-14 14:04:09.038 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695449000 ms.0 from job set of time 1481695449000 ms
2016-12-14 14:04:09.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.037 s for time 1481695449000 ms (execution: 0.005 s)
2016-12-14 14:04:09.048 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:04:09.051 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:04:09.339 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:04:09.345 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:04:09.346 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:04:09.347 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 14:04:09.348 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 14:04:10.068 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695450000 ms
2016-12-14 14:04:10.069 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695450000 ms.0 from job set of time 1481695450000 ms
2016-12-14 14:04:10.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695450000 ms.0 from job set of time 1481695450000 ms
2016-12-14 14:04:10.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.070 s for time 1481695450000 ms (execution: 0.001 s)
2016-12-14 14:04:10.071 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 14:04:10.079 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695450000 ms
2016-12-14 14:04:10.080 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:04:10.081 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:04:10.082 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 14:04:11.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695451000 ms
2016-12-14 14:04:11.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695451000 ms.0 from job set of time 1481695451000 ms
2016-12-14 14:04:11.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695451000 ms.0 from job set of time 1481695451000 ms
2016-12-14 14:04:11.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 2 from persistence list
2016-12-14 14:04:11.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.006 s for time 1481695451000 ms (execution: 0.001 s)
2016-12-14 14:04:11.007 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 14:04:11.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[2] at createStream at LogStream.java:100 of time 1481695451000 ms
2016-12-14 14:04:11.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695449000 ms)
2016-12-14 14:04:11.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695449000 ms
2016-12-14 14:04:12.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695452000 ms
2016-12-14 14:04:12.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695452000 ms.0 from job set of time 1481695452000 ms
2016-12-14 14:04:12.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695452000 ms.0 from job set of time 1481695452000 ms
2016-12-14 14:04:12.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695452000 ms (execution: 0.001 s)
2016-12-14 14:04:12.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 3 from persistence list
2016-12-14 14:04:12.008 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 14:04:12.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[3] at createStream at LogStream.java:100 of time 1481695452000 ms
2016-12-14 14:04:12.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695450000 ms)
2016-12-14 14:04:12.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695450000 ms
2016-12-14 14:04:13.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695453000 ms
2016-12-14 14:04:13.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695453000 ms.0 from job set of time 1481695453000 ms
2016-12-14 14:04:13.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695453000 ms.0 from job set of time 1481695453000 ms
2016-12-14 14:04:13.008 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 4 from persistence list
2016-12-14 14:04:13.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.007 s for time 1481695453000 ms (execution: 0.001 s)
2016-12-14 14:04:13.008 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 14:04:13.008 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[4] at createStream at LogStream.java:100 of time 1481695453000 ms
2016-12-14 14:04:13.009 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695451000 ms)
2016-12-14 14:04:13.009 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695451000 ms
2016-12-14 14:04:14.004 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695454000 ms
2016-12-14 14:04:14.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695454000 ms.0 from job set of time 1481695454000 ms
2016-12-14 14:04:14.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695454000 ms.0 from job set of time 1481695454000 ms
2016-12-14 14:04:14.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.005 s for time 1481695454000 ms (execution: 0.000 s)
2016-12-14 14:04:14.006 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 5 from persistence list
2016-12-14 14:04:14.006 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 5
2016-12-14 14:04:14.007 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[5] at createStream at LogStream.java:100 of time 1481695454000 ms
2016-12-14 14:04:14.007 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695452000 ms)
2016-12-14 14:04:14.007 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695452000 ms
2016-12-14 14:04:15.006 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695455000 ms
2016-12-14 14:04:15.006 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695455000 ms.0 from job set of time 1481695455000 ms
2016-12-14 14:04:15.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695455000 ms.0 from job set of time 1481695455000 ms
2016-12-14 14:04:15.009 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 6 from persistence list
2016-12-14 14:04:15.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.009 s for time 1481695455000 ms (execution: 0.003 s)
2016-12-14 14:04:15.010 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 14:04:15.010 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[6] at createStream at LogStream.java:100 of time 1481695455000 ms
2016-12-14 14:04:15.010 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695453000 ms)
2016-12-14 14:04:15.010 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695453000 ms
2016-12-14 14:04:15.121 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 14:04:15.125 [dispatcher-event-loop-0] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 14:04:15.125 [dispatcher-event-loop-1] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 14:04:15.127 [dispatcher-event-loop-1] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 14:04:15.149 [dispatcher-event-loop-1] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05ad closed
2016-12-14 14:04:15.149 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 14:04:15.151 [dispatcher-event-loop-1] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 14:04:15.152 [dispatcher-event-loop-1] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 14:04:15.154 [dispatcher-event-loop-3] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 14:04:15.155 [dispatcher-event-loop-1] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 14:04:15.156 [dispatcher-event-loop-1] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 14:04:15.401 [dispatcher-event-loop-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695455400
2016-12-14 14:04:15.402 [dispatcher-event-loop-1] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 14:04:15.411 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 14:04:15.411 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 14:04:15.412 [dispatcher-event-loop-1] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 14:04:15.413 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 14:04:15.422 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 14:04:15.444 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 6766 ms on localhost (1/1)
2016-12-14 14:04:15.447 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:04:15.448 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 6.783 s
2016-12-14 14:04:15.458 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 14:04:15.459 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 14:04:15.459 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 14:04:15.460 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695455000
2016-12-14 14:04:15.463 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 14:04:15.466 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 14:04:15.470 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 14:04:15.472 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 14:04:15.473 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 14:04:15.475 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 14:04:15.475 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 14:04:15.490 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 14:04:15.491 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 14:04:15.491 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:04:15.491 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:04:15.492 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:04:15.492 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:04:15.493 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:04:15.493 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:04:15.493 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:04:15.494 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:04:15.494 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:04:15.495 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:04:15.495 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:04:15.496 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:04:15.496 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:04:15.497 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:04:15.498 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:04:15.499 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:04:15.499 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:04:15.499 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:04:15.551 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 14:04:15.563 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:04:15.570 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 14:04:15.571 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 14:04:15.573 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 14:04:15.576 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 14:04:15.584 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 14:04:15.586 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:04:15.587 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 14:04:15.587 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-bfc541b9-bcf5-40f1-a403-86380201a922
2016-12-14 14:04:15.590 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:05:58.034 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:05:58.569 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:05:58.660 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:05:59.307 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:05:59.597 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:05:59.604 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:05:59.604 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:05:59.604 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:05:59.604 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:05:59.604 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:05:59.605 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:05:59.606 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:05:59.606 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:05:59.606 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:05:59.607 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:05:59.632 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:05:59.654 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:05:59.665 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05ae, negotiated timeout = 40000
2016-12-14 14:05:59.763 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:06:01.023 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:06:01.038 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:06:01.046 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:06:01.052 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:06:01.055 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:06:01.055 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:06:01.055 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:06:01.068 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:06:01.068 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:06:01.513 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:06:01.885 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:06:01.982 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:06:01.983 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:06:01.984 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:06:02.714 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60388.
2016-12-14 14:06:03.247 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:06:03.310 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2016-12-14 14:06:03.509 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60389]
2016-12-14 14:06:03.518 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60389.
2016-12-14 14:06:03.533 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:06:03.556 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:06:03.574 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-50e8ec7e-851b-425d-8d7c-82542efdbea7
2016-12-14 14:06:03.584 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:06:03.644 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:06:03.896 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:06:03.945 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:06:03.946 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:06:03.948 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:06:04.093 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:06:04.131 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60390.
2016-12-14 14:06:04.131 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60390
2016-12-14 14:06:04.133 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:06:04.137 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60390 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60390)
2016-12-14 14:06:04.143 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:06:05.033 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 14:06:05.037 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 14:06:05.049 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.051 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.052 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:06:05.053 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.053 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:06:05.054 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.055 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@341e4f77
2016-12-14 14:06:05.055 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4c75e8e3
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.056 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.057 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.057 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.057 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@341e4f77
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:06:05.058 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@18255c66
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Slide time = 1000 ms
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Checkpoint interval = null
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Initialized and validated org.apache.spark.streaming.dstream.FilteredDStream@b2e786c
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.059 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@4d0dfb89
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Slide time = 1000 ms
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Checkpoint interval = null
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@2edc203b
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Slide time = 1000 ms
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Checkpoint interval = null
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@1ca88fea
2016-12-14 14:06:05.060 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:06:05.061 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.063 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:06:05.063 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@64bd690b
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@46ce07a6
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:06:05.064 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@9dc3abc
2016-12-14 14:06:05.129 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695566000
2016-12-14 14:06:05.129 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695566000 ms
2016-12-14 14:06:05.130 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 14:06:05.140 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 14:06:05.142 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 14:06:05.146 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 14:06:05.147 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 14:06:05.147 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:06:05.150 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:06:05.163 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 14:06:05.366 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 14:06:05.383 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 14:06:05.385 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60390 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 14:06:05.388 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:05.393 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 14:06:05.395 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 14:06:05.445 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 14:06:05.459 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:06:05.532 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695565600
2016-12-14 14:06:05.534 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 14:06:05.535 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 14:06:05.546 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60388
2016-12-14 14:06:05.547 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 14:06:05.549 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 14:06:05.550 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 14:06:05.630 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@337a9db3
2016-12-14 14:06:05.631 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:06:05.632 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:06:05.640 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05af, negotiated timeout = 6000
2016-12-14 14:06:05.657 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 14:06:06.029 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:06:06.029 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:06:06.029 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:06:06.029 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 14:06:06.030 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 14:06:06.077 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695566000 ms
2016-12-14 14:06:06.080 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695566000 ms.0 from job set of time 1481695566000 ms
2016-12-14 14:06:06.083 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695566000 ms.0 from job set of time 1481695566000 ms
2016-12-14 14:06:06.083 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695566000 ms.1 from job set of time 1481695566000 ms
2016-12-14 14:06:06.243 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:06.265 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 6 (union at DStream.scala:617)
2016-12-14 14:06:06.270 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:06.270 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (take at LogStream.java:127)
2016-12-14 14:06:06.270 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2016-12-14 14:06:06.270 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2016-12-14 14:06:06.272 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (UnionRDD[6] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:06.287 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 106.3 KB)
2016-12-14 14:06:06.291 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 108.7 KB)
2016-12-14 14:06:06.292 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:06.292 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:06.295 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (UnionRDD[6] at union at DStream.scala:617)
2016-12-14 14:06:06.295 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2016-12-14 14:06:06.299 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:06.301 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:06:06.369 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1159 bytes result sent to driver
2016-12-14 14:06:06.378 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 80 ms on localhost (1/1)
2016-12-14 14:06:06.379 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:06:06.382 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (union at DStream.scala:617) finished in 0.085 s
2016-12-14 14:06:06.385 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:06.386 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:06.387 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2016-12-14 14:06:06.388 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:06.389 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:06.394 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 112.4 KB)
2016-12-14 14:06:06.396 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 114.5 KB)
2016-12-14 14:06:06.397 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:06.398 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:06.398 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at count at LogStream.java:120)
2016-12-14 14:06:06.399 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2016-12-14 14:06:06.403 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:06.403 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 14:06:06.419 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:06.421 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 4 ms
2016-12-14 14:06:06.445 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1241 bytes result sent to driver
2016-12-14 14:06:06.447 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 46 ms on localhost (1/1)
2016-12-14 14:06:06.447 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (take at LogStream.java:127) finished in 0.046 s
2016-12-14 14:06:06.447 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:06:06.454 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: take at LogStream.java:127, took 0.210638 s
2016-12-14 14:06:06.940 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695566000 ms.1 from job set of time 1481695566000 ms
2016-12-14 14:06:06.941 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.940 s for time 1481695566000 ms (execution: 0.862 s)
2016-12-14 14:06:06.945 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:06:06.947 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:06:07.020 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695567000 ms
2016-12-14 14:06:07.021 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695567000 ms.0 from job set of time 1481695567000 ms
2016-12-14 14:06:07.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695567000 ms.0 from job set of time 1481695567000 ms
2016-12-14 14:06:07.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695567000 ms.1 from job set of time 1481695567000 ms
2016-12-14 14:06:07.032 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:07.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 15 (union at DStream.scala:617)
2016-12-14 14:06:07.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:07.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (take at LogStream.java:127)
2016-12-14 14:06:07.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 3)
2016-12-14 14:06:07.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 3)
2016-12-14 14:06:07.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 3 (UnionRDD[15] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:07.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 118.7 KB)
2016-12-14 14:06:07.040 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 121.2 KB)
2016-12-14 14:06:07.040 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:07.041 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:07.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (UnionRDD[15] at union at DStream.scala:617)
2016-12-14 14:06:07.042 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2016-12-14 14:06:07.043 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:07.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2016-12-14 14:06:07.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1159 bytes result sent to driver
2016-12-14 14:06:07.053 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (1/1)
2016-12-14 14:06:07.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 3 (union at DStream.scala:617) finished in 0.011 s
2016-12-14 14:06:07.053 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:06:07.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:07.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:07.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 4)
2016-12-14 14:06:07.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:07.054 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[18] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:07.057 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 124.9 KB)
2016-12-14 14:06:07.058 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 127.0 KB)
2016-12-14 14:06:07.059 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:07.060 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:07.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at count at LogStream.java:120)
2016-12-14 14:06:07.060 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks
2016-12-14 14:06:07.062 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:07.062 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2016-12-14 14:06:07.066 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:07.066 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:07.069 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1241 bytes result sent to driver
2016-12-14 14:06:07.070 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (1/1)
2016-12-14 14:06:07.070 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (take at LogStream.java:127) finished in 0.009 s
2016-12-14 14:06:07.071 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:06:07.071 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: take at LogStream.java:127, took 0.038697 s
2016-12-14 14:06:07.101 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695567000 ms.1 from job set of time 1481695567000 ms
2016-12-14 14:06:07.102 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.101 s for time 1481695567000 ms (execution: 0.081 s)
2016-12-14 14:06:07.102 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 14:06:07.108 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695567000 ms
2016-12-14 14:06:07.109 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 9 from persistence list
2016-12-14 14:06:07.109 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 14:06:07.110 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 8 from persistence list
2016-12-14 14:06:07.110 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 7 from persistence list
2016-12-14 14:06:07.111 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 9
2016-12-14 14:06:07.111 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 6 from persistence list
2016-12-14 14:06:07.111 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 8
2016-12-14 14:06:07.112 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 7
2016-12-14 14:06:07.112 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 4 from persistence list
2016-12-14 14:06:07.112 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 14:06:07.113 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 3 from persistence list
2016-12-14 14:06:07.114 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 2 from persistence list
2016-12-14 14:06:07.115 [block-manager-slave-async-thread-pool-11] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 14:06:07.115 [block-manager-slave-async-thread-pool-12] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 14:06:07.116 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:06:07.116 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:06:07.116 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 14:06:08.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695568000 ms
2016-12-14 14:06:08.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695568000 ms.0 from job set of time 1481695568000 ms
2016-12-14 14:06:08.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695568000 ms.0 from job set of time 1481695568000 ms
2016-12-14 14:06:08.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695568000 ms.1 from job set of time 1481695568000 ms
2016-12-14 14:06:08.021 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:08.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 24 (union at DStream.scala:617)
2016-12-14 14:06:08.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:08.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (take at LogStream.java:127)
2016-12-14 14:06:08.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 5)
2016-12-14 14:06:08.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 5)
2016-12-14 14:06:08.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 5 (UnionRDD[24] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:08.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 4.2 KB, free 131.2 KB)
2016-12-14 14:06:08.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 133.6 KB)
2016-12-14 14:06:08.031 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:08.032 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:08.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 5 (UnionRDD[24] at union at DStream.scala:617)
2016-12-14 14:06:08.032 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks
2016-12-14 14:06:08.033 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:08.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2016-12-14 14:06:08.042 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1159 bytes result sent to driver
2016-12-14 14:06:08.043 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (1/1)
2016-12-14 14:06:08.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 5 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:06:08.043 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:06:08.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:08.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:08.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 6)
2016-12-14 14:06:08.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:08.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[27] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:08.046 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 137.3 KB)
2016-12-14 14:06:08.047 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 139.4 KB)
2016-12-14 14:06:08.048 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:08.049 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:08.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at count at LogStream.java:120)
2016-12-14 14:06:08.049 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks
2016-12-14 14:06:08.050 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:08.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2016-12-14 14:06:08.054 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:08.054 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:08.056 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1241 bytes result sent to driver
2016-12-14 14:06:08.057 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (1/1)
2016-12-14 14:06:08.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:06:08.058 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:06:08.058 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: take at LogStream.java:127, took 0.036840 s
2016-12-14 14:06:08.092 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695568000 ms.1 from job set of time 1481695568000 ms
2016-12-14 14:06:08.092 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 10 from persistence list
2016-12-14 14:06:08.092 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.092 s for time 1481695568000 ms (execution: 0.078 s)
2016-12-14 14:06:08.093 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 10
2016-12-14 14:06:08.093 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[10] at createStream at LogStream.java:100 of time 1481695568000 ms
2016-12-14 14:06:08.093 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 18 from persistence list
2016-12-14 14:06:08.093 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 18
2016-12-14 14:06:08.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 17 from persistence list
2016-12-14 14:06:08.094 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 17
2016-12-14 14:06:08.094 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 16 from persistence list
2016-12-14 14:06:08.095 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 16
2016-12-14 14:06:08.095 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 15 from persistence list
2016-12-14 14:06:08.095 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 15
2016-12-14 14:06:08.095 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 13 from persistence list
2016-12-14 14:06:08.095 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 13
2016-12-14 14:06:08.096 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 12 from persistence list
2016-12-14 14:06:08.096 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 12
2016-12-14 14:06:08.096 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 11 from persistence list
2016-12-14 14:06:08.097 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 11
2016-12-14 14:06:08.097 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695566000 ms)
2016-12-14 14:06:08.097 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695566000 ms
2016-12-14 14:06:09.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695569000 ms.0 from job set of time 1481695569000 ms
2016-12-14 14:06:09.018 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695569000 ms
2016-12-14 14:06:09.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695569000 ms.0 from job set of time 1481695569000 ms
2016-12-14 14:06:09.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695569000 ms.1 from job set of time 1481695569000 ms
2016-12-14 14:06:09.024 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:09.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 33 (union at DStream.scala:617)
2016-12-14 14:06:09.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:09.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (take at LogStream.java:127)
2016-12-14 14:06:09.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
2016-12-14 14:06:09.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 7)
2016-12-14 14:06:09.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 7 (UnionRDD[33] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:09.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 143.6 KB)
2016-12-14 14:06:09.031 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 146.1 KB)
2016-12-14 14:06:09.032 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:09.032 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:09.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (UnionRDD[33] at union at DStream.scala:617)
2016-12-14 14:06:09.033 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2016-12-14 14:06:09.034 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:09.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2016-12-14 14:06:09.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 1159 bytes result sent to driver
2016-12-14 14:06:09.042 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
2016-12-14 14:06:09.042 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:06:09.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 7 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:06:09.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:09.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:09.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2016-12-14 14:06:09.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:09.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[36] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:09.046 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 149.8 KB)
2016-12-14 14:06:09.047 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 151.9 KB)
2016-12-14 14:06:09.048 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:09.049 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:09.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[36] at count at LogStream.java:120)
2016-12-14 14:06:09.050 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks
2016-12-14 14:06:09.053 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:09.056 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2016-12-14 14:06:09.059 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:09.059 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:09.062 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1241 bytes result sent to driver
2016-12-14 14:06:09.063 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 11 ms on localhost (1/1)
2016-12-14 14:06:09.064 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:06:09.067 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (take at LogStream.java:127) finished in 0.014 s
2016-12-14 14:06:09.068 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: take at LogStream.java:127, took 0.043542 s
2016-12-14 14:06:09.146 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695569000 ms.1 from job set of time 1481695569000 ms
2016-12-14 14:06:09.147 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 19 from persistence list
2016-12-14 14:06:09.147 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.146 s for time 1481695569000 ms (execution: 0.128 s)
2016-12-14 14:06:09.148 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 19
2016-12-14 14:06:09.148 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[19] at createStream at LogStream.java:100 of time 1481695569000 ms
2016-12-14 14:06:09.149 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 27 from persistence list
2016-12-14 14:06:09.149 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 27
2016-12-14 14:06:09.149 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 26 from persistence list
2016-12-14 14:06:09.150 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 26
2016-12-14 14:06:09.150 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 25 from persistence list
2016-12-14 14:06:09.151 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 25
2016-12-14 14:06:09.151 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 24 from persistence list
2016-12-14 14:06:09.151 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 24
2016-12-14 14:06:09.151 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 22 from persistence list
2016-12-14 14:06:09.152 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 22
2016-12-14 14:06:09.152 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 21 from persistence list
2016-12-14 14:06:09.152 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 21
2016-12-14 14:06:09.152 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 20 from persistence list
2016-12-14 14:06:09.153 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 20
2016-12-14 14:06:09.154 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695567000 ms)
2016-12-14 14:06:09.154 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695567000 ms
2016-12-14 14:06:10.017 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695570000 ms
2016-12-14 14:06:10.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695570000 ms.0 from job set of time 1481695570000 ms
2016-12-14 14:06:10.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695570000 ms.0 from job set of time 1481695570000 ms
2016-12-14 14:06:10.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695570000 ms.1 from job set of time 1481695570000 ms
2016-12-14 14:06:10.023 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:10.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 42 (union at DStream.scala:617)
2016-12-14 14:06:10.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:10.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (take at LogStream.java:127)
2016-12-14 14:06:10.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 9)
2016-12-14 14:06:10.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 9)
2016-12-14 14:06:10.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (UnionRDD[42] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:10.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 4.2 KB, free 156.1 KB)
2016-12-14 14:06:10.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 158.5 KB)
2016-12-14 14:06:10.033 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:10.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:10.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 9 (UnionRDD[42] at union at DStream.scala:617)
2016-12-14 14:06:10.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks
2016-12-14 14:06:10.036 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:10.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2016-12-14 14:06:10.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1159 bytes result sent to driver
2016-12-14 14:06:10.044 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 9 ms on localhost (1/1)
2016-12-14 14:06:10.044 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 10)
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:10.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[45] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:10.049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 3.7 KB, free 162.2 KB)
2016-12-14 14:06:10.051 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.1 KB, free 164.3 KB)
2016-12-14 14:06:10.052 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:10.053 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:10.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at count at LogStream.java:120)
2016-12-14 14:06:10.054 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks
2016-12-14 14:06:10.056 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:10.056 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2016-12-14 14:06:10.058 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:10.059 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:10.061 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 1241 bytes result sent to driver
2016-12-14 14:06:10.062 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on localhost (1/1)
2016-12-14 14:06:10.062 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:06:10.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:06:10.063 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: take at LogStream.java:127, took 0.039410 s
2016-12-14 14:06:10.088 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695570000 ms.1 from job set of time 1481695570000 ms
2016-12-14 14:06:10.088 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 28 from persistence list
2016-12-14 14:06:10.088 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.088 s for time 1481695570000 ms (execution: 0.071 s)
2016-12-14 14:06:10.088 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 28
2016-12-14 14:06:10.089 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[28] at createStream at LogStream.java:100 of time 1481695570000 ms
2016-12-14 14:06:10.089 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 36 from persistence list
2016-12-14 14:06:10.089 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 36
2016-12-14 14:06:10.090 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 35 from persistence list
2016-12-14 14:06:10.090 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 35
2016-12-14 14:06:10.090 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 34 from persistence list
2016-12-14 14:06:10.091 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 34
2016-12-14 14:06:10.092 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 33 from persistence list
2016-12-14 14:06:10.093 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 33
2016-12-14 14:06:10.093 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 31 from persistence list
2016-12-14 14:06:10.093 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 31
2016-12-14 14:06:10.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 30 from persistence list
2016-12-14 14:06:10.094 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 30
2016-12-14 14:06:10.095 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 29 from persistence list
2016-12-14 14:06:10.095 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 29
2016-12-14 14:06:10.096 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695568000 ms)
2016-12-14 14:06:10.096 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695568000 ms
2016-12-14 14:06:11.020 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695571000 ms
2016-12-14 14:06:11.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695571000 ms.0 from job set of time 1481695571000 ms
2016-12-14 14:06:11.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695571000 ms.0 from job set of time 1481695571000 ms
2016-12-14 14:06:11.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695571000 ms.1 from job set of time 1481695571000 ms
2016-12-14 14:06:11.027 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:11.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 51 (union at DStream.scala:617)
2016-12-14 14:06:11.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:11.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (take at LogStream.java:127)
2016-12-14 14:06:11.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 11)
2016-12-14 14:06:11.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 11)
2016-12-14 14:06:11.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 11 (UnionRDD[51] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:11.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 4.2 KB, free 168.5 KB)
2016-12-14 14:06:11.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 171.0 KB)
2016-12-14 14:06:11.035 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:11.036 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:11.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 11 (UnionRDD[51] at union at DStream.scala:617)
2016-12-14 14:06:11.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks
2016-12-14 14:06:11.037 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:11.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2016-12-14 14:06:11.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1159 bytes result sent to driver
2016-12-14 14:06:11.045 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 8 ms on localhost (1/1)
2016-12-14 14:06:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 11 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:06:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:11.045 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:06:11.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:11.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 12)
2016-12-14 14:06:11.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:11.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[54] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:11.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 3.7 KB, free 174.7 KB)
2016-12-14 14:06:11.050 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.1 KB, free 176.8 KB)
2016-12-14 14:06:11.050 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:11.051 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:11.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at count at LogStream.java:120)
2016-12-14 14:06:11.052 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks
2016-12-14 14:06:11.053 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:11.054 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2016-12-14 14:06:11.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:11.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:11.059 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1241 bytes result sent to driver
2016-12-14 14:06:11.060 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (1/1)
2016-12-14 14:06:11.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:06:11.060 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:06:11.060 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: take at LogStream.java:127, took 0.032908 s
2016-12-14 14:06:11.163 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695571000 ms.1 from job set of time 1481695571000 ms
2016-12-14 14:06:11.163 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.163 s for time 1481695571000 ms (execution: 0.141 s)
2016-12-14 14:06:11.163 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 37 from persistence list
2016-12-14 14:06:11.164 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 37
2016-12-14 14:06:11.164 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[37] at createStream at LogStream.java:100 of time 1481695571000 ms
2016-12-14 14:06:11.164 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 45 from persistence list
2016-12-14 14:06:11.165 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 45
2016-12-14 14:06:11.165 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 44 from persistence list
2016-12-14 14:06:11.165 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 44
2016-12-14 14:06:11.165 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 43 from persistence list
2016-12-14 14:06:11.166 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 43
2016-12-14 14:06:11.166 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 42 from persistence list
2016-12-14 14:06:11.166 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 42
2016-12-14 14:06:11.167 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 40 from persistence list
2016-12-14 14:06:11.167 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 40
2016-12-14 14:06:11.167 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 39 from persistence list
2016-12-14 14:06:11.167 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 39
2016-12-14 14:06:11.168 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 38 from persistence list
2016-12-14 14:06:11.168 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 38
2016-12-14 14:06:11.168 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695569000 ms)
2016-12-14 14:06:11.168 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695569000 ms
2016-12-14 14:06:12.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695572000 ms
2016-12-14 14:06:12.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695572000 ms.0 from job set of time 1481695572000 ms
2016-12-14 14:06:12.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695572000 ms.0 from job set of time 1481695572000 ms
2016-12-14 14:06:12.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695572000 ms.1 from job set of time 1481695572000 ms
2016-12-14 14:06:12.023 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:12.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 60 (union at DStream.scala:617)
2016-12-14 14:06:12.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:12.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (take at LogStream.java:127)
2016-12-14 14:06:12.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 13)
2016-12-14 14:06:12.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 13)
2016-12-14 14:06:12.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 13 (UnionRDD[60] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:12.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 4.2 KB, free 181.0 KB)
2016-12-14 14:06:12.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 183.4 KB)
2016-12-14 14:06:12.029 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:12.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:12.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 13 (UnionRDD[60] at union at DStream.scala:617)
2016-12-14 14:06:12.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks
2016-12-14 14:06:12.031 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:12.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2016-12-14 14:06:12.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 1159 bytes result sent to driver
2016-12-14 14:06:12.037 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on localhost (1/1)
2016-12-14 14:06:12.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 13 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:12.037 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:06:12.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:12.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:12.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 14)
2016-12-14 14:06:12.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:12.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[63] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:12.040 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 3.7 KB, free 187.1 KB)
2016-12-14 14:06:12.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.1 KB, free 189.2 KB)
2016-12-14 14:06:12.044 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:12.044 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:12.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[63] at count at LogStream.java:120)
2016-12-14 14:06:12.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks
2016-12-14 14:06:12.046 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:12.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2016-12-14 14:06:12.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:12.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:12.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1241 bytes result sent to driver
2016-12-14 14:06:12.052 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (1/1)
2016-12-14 14:06:12.052 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:06:12.054 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:06:12.055 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: take at LogStream.java:127, took 0.031947 s
2016-12-14 14:06:12.063 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695572000 ms.1 from job set of time 1481695572000 ms
2016-12-14 14:06:12.064 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 46 from persistence list
2016-12-14 14:06:12.064 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.063 s for time 1481695572000 ms (execution: 0.046 s)
2016-12-14 14:06:12.064 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 46
2016-12-14 14:06:12.064 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[46] at createStream at LogStream.java:100 of time 1481695572000 ms
2016-12-14 14:06:12.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 54 from persistence list
2016-12-14 14:06:12.065 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 54
2016-12-14 14:06:12.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 53 from persistence list
2016-12-14 14:06:12.065 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 53
2016-12-14 14:06:12.065 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 52 from persistence list
2016-12-14 14:06:12.065 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 52
2016-12-14 14:06:12.065 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 51 from persistence list
2016-12-14 14:06:12.066 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 51
2016-12-14 14:06:12.066 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 49 from persistence list
2016-12-14 14:06:12.066 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 49
2016-12-14 14:06:12.066 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 48 from persistence list
2016-12-14 14:06:12.066 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 48
2016-12-14 14:06:12.067 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 47 from persistence list
2016-12-14 14:06:12.067 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 47
2016-12-14 14:06:12.068 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695570000 ms)
2016-12-14 14:06:12.068 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695570000 ms
2016-12-14 14:06:13.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695573000 ms
2016-12-14 14:06:13.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695573000 ms.0 from job set of time 1481695573000 ms
2016-12-14 14:06:13.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695573000 ms.0 from job set of time 1481695573000 ms
2016-12-14 14:06:13.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695573000 ms.1 from job set of time 1481695573000 ms
2016-12-14 14:06:13.022 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:13.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 69 (union at DStream.scala:617)
2016-12-14 14:06:13.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:13.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (take at LogStream.java:127)
2016-12-14 14:06:13.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 15)
2016-12-14 14:06:13.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 15)
2016-12-14 14:06:13.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 15 (UnionRDD[69] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:13.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 4.2 KB, free 193.4 KB)
2016-12-14 14:06:13.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 195.9 KB)
2016-12-14 14:06:13.029 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:13.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:13.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 15 (UnionRDD[69] at union at DStream.scala:617)
2016-12-14 14:06:13.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks
2016-12-14 14:06:13.031 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:13.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2016-12-14 14:06:13.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 1159 bytes result sent to driver
2016-12-14 14:06:13.039 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 9 ms on localhost (1/1)
2016-12-14 14:06:13.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 15 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:06:13.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:13.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:13.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 16)
2016-12-14 14:06:13.039 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:06:13.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:13.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[72] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:13.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 3.7 KB, free 199.6 KB)
2016-12-14 14:06:13.045 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.1 KB, free 201.7 KB)
2016-12-14 14:06:13.046 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:13.046 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:13.047 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[72] at count at LogStream.java:120)
2016-12-14 14:06:13.047 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks
2016-12-14 14:06:13.048 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:13.048 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2016-12-14 14:06:13.050 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:13.050 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:13.052 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1241 bytes result sent to driver
2016-12-14 14:06:13.054 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 7 ms on localhost (1/1)
2016-12-14 14:06:13.055 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:06:13.055 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:06:13.056 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: take at LogStream.java:127, took 0.033292 s
2016-12-14 14:06:13.062 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695573000 ms.1 from job set of time 1481695573000 ms
2016-12-14 14:06:13.062 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 55 from persistence list
2016-12-14 14:06:13.062 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.062 s for time 1481695573000 ms (execution: 0.046 s)
2016-12-14 14:06:13.063 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 55
2016-12-14 14:06:13.063 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[55] at createStream at LogStream.java:100 of time 1481695573000 ms
2016-12-14 14:06:13.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 63 from persistence list
2016-12-14 14:06:13.064 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 63
2016-12-14 14:06:13.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 62 from persistence list
2016-12-14 14:06:13.065 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 62
2016-12-14 14:06:13.065 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 61 from persistence list
2016-12-14 14:06:13.067 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 61
2016-12-14 14:06:13.067 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 60 from persistence list
2016-12-14 14:06:13.067 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 60
2016-12-14 14:06:13.068 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 58 from persistence list
2016-12-14 14:06:13.068 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 58
2016-12-14 14:06:13.068 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 57 from persistence list
2016-12-14 14:06:13.068 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 57
2016-12-14 14:06:13.069 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 56 from persistence list
2016-12-14 14:06:13.069 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 56
2016-12-14 14:06:13.069 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695571000 ms)
2016-12-14 14:06:13.069 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695571000 ms
2016-12-14 14:06:14.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695574000 ms.0 from job set of time 1481695574000 ms
2016-12-14 14:06:14.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695574000 ms
2016-12-14 14:06:14.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695574000 ms.0 from job set of time 1481695574000 ms
2016-12-14 14:06:14.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695574000 ms.1 from job set of time 1481695574000 ms
2016-12-14 14:06:14.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:14.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 78 (union at DStream.scala:617)
2016-12-14 14:06:14.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:14.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 18 (take at LogStream.java:127)
2016-12-14 14:06:14.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 17)
2016-12-14 14:06:14.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 17)
2016-12-14 14:06:14.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 17 (UnionRDD[78] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:14.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 4.2 KB, free 205.9 KB)
2016-12-14 14:06:14.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.4 KB, free 208.3 KB)
2016-12-14 14:06:14.026 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:14.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:14.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 17 (UnionRDD[78] at union at DStream.scala:617)
2016-12-14 14:06:14.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 1 tasks
2016-12-14 14:06:14.027 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:14.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2016-12-14 14:06:14.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 1159 bytes result sent to driver
2016-12-14 14:06:14.033 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 6 ms on localhost (1/1)
2016-12-14 14:06:14.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 17 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:06:14.033 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:06:14.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:14.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:14.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 18)
2016-12-14 14:06:14.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:14.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 18 (MapPartitionsRDD[81] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:14.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 3.7 KB, free 212.0 KB)
2016-12-14 14:06:14.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 214.1 KB)
2016-12-14 14:06:14.039 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:14.040 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:14.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[81] at count at LogStream.java:120)
2016-12-14 14:06:14.041 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 18.0 with 1 tasks
2016-12-14 14:06:14.042 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:14.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 18.0 (TID 18)
2016-12-14 14:06:14.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:14.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:14.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 18.0 (TID 18). 1241 bytes result sent to driver
2016-12-14 14:06:14.047 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 18.0 (TID 18) in 5 ms on localhost (1/1)
2016-12-14 14:06:14.047 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:06:14.047 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 18 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:06:14.048 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: take at LogStream.java:127, took 0.028414 s
2016-12-14 14:06:14.053 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695574000 ms.1 from job set of time 1481695574000 ms
2016-12-14 14:06:14.054 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.053 s for time 1481695574000 ms (execution: 0.040 s)
2016-12-14 14:06:14.055 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 64 from persistence list
2016-12-14 14:06:14.055 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 64
2016-12-14 14:06:14.055 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[64] at createStream at LogStream.java:100 of time 1481695574000 ms
2016-12-14 14:06:14.056 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 72 from persistence list
2016-12-14 14:06:14.056 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 72
2016-12-14 14:06:14.056 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 71 from persistence list
2016-12-14 14:06:14.057 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 71
2016-12-14 14:06:14.057 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 70 from persistence list
2016-12-14 14:06:14.057 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 70
2016-12-14 14:06:14.057 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 69 from persistence list
2016-12-14 14:06:14.058 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 69
2016-12-14 14:06:14.058 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 67 from persistence list
2016-12-14 14:06:14.058 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 67
2016-12-14 14:06:14.058 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 66 from persistence list
2016-12-14 14:06:14.059 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 66
2016-12-14 14:06:14.059 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 65 from persistence list
2016-12-14 14:06:14.059 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 65
2016-12-14 14:06:14.059 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695572000 ms)
2016-12-14 14:06:14.060 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695572000 ms
2016-12-14 14:06:15.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695575000 ms
2016-12-14 14:06:15.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695575000 ms.0 from job set of time 1481695575000 ms
2016-12-14 14:06:15.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695575000 ms.0 from job set of time 1481695575000 ms
2016-12-14 14:06:15.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695575000 ms.1 from job set of time 1481695575000 ms
2016-12-14 14:06:15.021 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:15.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 87 (union at DStream.scala:617)
2016-12-14 14:06:15.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:15.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (take at LogStream.java:127)
2016-12-14 14:06:15.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 19)
2016-12-14 14:06:15.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 19)
2016-12-14 14:06:15.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 19 (UnionRDD[87] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:15.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 4.2 KB, free 218.3 KB)
2016-12-14 14:06:15.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 220.8 KB)
2016-12-14 14:06:15.028 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:15.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:15.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 19 (UnionRDD[87] at union at DStream.scala:617)
2016-12-14 14:06:15.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks
2016-12-14 14:06:15.030 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:15.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2016-12-14 14:06:15.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 1159 bytes result sent to driver
2016-12-14 14:06:15.038 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 9 ms on localhost (1/1)
2016-12-14 14:06:15.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 19 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:06:15.038 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:06:15.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:15.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:15.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 20)
2016-12-14 14:06:15.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:15.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[90] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:15.041 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 3.7 KB, free 224.5 KB)
2016-12-14 14:06:15.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 226.6 KB)
2016-12-14 14:06:15.043 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:15.044 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:15.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[90] at count at LogStream.java:120)
2016-12-14 14:06:15.044 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks
2016-12-14 14:06:15.045 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:15.045 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2016-12-14 14:06:15.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:15.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:15.049 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1241 bytes result sent to driver
2016-12-14 14:06:15.050 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 5 ms on localhost (1/1)
2016-12-14 14:06:15.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:06:15.050 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:06:15.051 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: take at LogStream.java:127, took 0.029173 s
2016-12-14 14:06:15.056 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695575000 ms.1 from job set of time 1481695575000 ms
2016-12-14 14:06:15.057 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 73 from persistence list
2016-12-14 14:06:15.057 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.056 s for time 1481695575000 ms (execution: 0.040 s)
2016-12-14 14:06:15.057 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 73
2016-12-14 14:06:15.057 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[73] at createStream at LogStream.java:100 of time 1481695575000 ms
2016-12-14 14:06:15.058 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 81 from persistence list
2016-12-14 14:06:15.058 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 81
2016-12-14 14:06:15.059 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 80 from persistence list
2016-12-14 14:06:15.060 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 80
2016-12-14 14:06:15.060 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 79 from persistence list
2016-12-14 14:06:15.060 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 79
2016-12-14 14:06:15.060 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 78 from persistence list
2016-12-14 14:06:15.060 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 78
2016-12-14 14:06:15.060 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 76 from persistence list
2016-12-14 14:06:15.061 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 76
2016-12-14 14:06:15.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 75 from persistence list
2016-12-14 14:06:15.061 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 75
2016-12-14 14:06:15.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 74 from persistence list
2016-12-14 14:06:15.061 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 74
2016-12-14 14:06:15.061 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695573000 ms)
2016-12-14 14:06:15.062 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695573000 ms
2016-12-14 14:06:16.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695576000 ms
2016-12-14 14:06:16.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695576000 ms.0 from job set of time 1481695576000 ms
2016-12-14 14:06:16.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695576000 ms.0 from job set of time 1481695576000 ms
2016-12-14 14:06:16.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695576000 ms.1 from job set of time 1481695576000 ms
2016-12-14 14:06:16.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:16.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 96 (union at DStream.scala:617)
2016-12-14 14:06:16.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:16.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 22 (take at LogStream.java:127)
2016-12-14 14:06:16.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 21)
2016-12-14 14:06:16.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 21)
2016-12-14 14:06:16.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 21 (UnionRDD[96] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:16.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 4.2 KB, free 230.8 KB)
2016-12-14 14:06:16.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.4 KB, free 233.2 KB)
2016-12-14 14:06:16.020 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:16.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:16.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 21 (UnionRDD[96] at union at DStream.scala:617)
2016-12-14 14:06:16.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 21.0 with 1 tasks
2016-12-14 14:06:16.022 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 21.0 (TID 21, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:16.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 21)
2016-12-14 14:06:16.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 21). 1159 bytes result sent to driver
2016-12-14 14:06:16.028 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 21.0 (TID 21) in 6 ms on localhost (1/1)
2016-12-14 14:06:16.028 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 21 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 22)
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 22 (MapPartitionsRDD[99] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:16.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 3.7 KB, free 236.9 KB)
2016-12-14 14:06:16.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.1 KB, free 239.0 KB)
2016-12-14 14:06:16.034 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:16.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:16.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[99] at count at LogStream.java:120)
2016-12-14 14:06:16.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 22.0 with 1 tasks
2016-12-14 14:06:16.035 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 22.0 (TID 22, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:16.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 22.0 (TID 22)
2016-12-14 14:06:16.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:16.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:16.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 22.0 (TID 22). 1241 bytes result sent to driver
2016-12-14 14:06:16.039 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (1/1)
2016-12-14 14:06:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 22 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:16.039 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:06:16.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: take at LogStream.java:127, took 0.024573 s
2016-12-14 14:06:16.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695576000 ms.1 from job set of time 1481695576000 ms
2016-12-14 14:06:16.048 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 82 from persistence list
2016-12-14 14:06:16.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.048 s for time 1481695576000 ms (execution: 0.037 s)
2016-12-14 14:06:16.049 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 82
2016-12-14 14:06:16.049 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[82] at createStream at LogStream.java:100 of time 1481695576000 ms
2016-12-14 14:06:16.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 90 from persistence list
2016-12-14 14:06:16.049 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 90
2016-12-14 14:06:16.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 89 from persistence list
2016-12-14 14:06:16.050 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 89
2016-12-14 14:06:16.050 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 88 from persistence list
2016-12-14 14:06:16.050 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 88
2016-12-14 14:06:16.051 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 87 from persistence list
2016-12-14 14:06:16.051 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 87
2016-12-14 14:06:16.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 85 from persistence list
2016-12-14 14:06:16.052 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 85
2016-12-14 14:06:16.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 84 from persistence list
2016-12-14 14:06:16.052 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 84
2016-12-14 14:06:16.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 83 from persistence list
2016-12-14 14:06:16.054 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 83
2016-12-14 14:06:16.055 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695574000 ms)
2016-12-14 14:06:16.055 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695574000 ms
2016-12-14 14:06:17.015 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695577000 ms
2016-12-14 14:06:17.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695577000 ms.0 from job set of time 1481695577000 ms
2016-12-14 14:06:17.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695577000 ms.0 from job set of time 1481695577000 ms
2016-12-14 14:06:17.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695577000 ms.1 from job set of time 1481695577000 ms
2016-12-14 14:06:17.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:17.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 105 (union at DStream.scala:617)
2016-12-14 14:06:17.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:17.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 24 (take at LogStream.java:127)
2016-12-14 14:06:17.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 23)
2016-12-14 14:06:17.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 23)
2016-12-14 14:06:17.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 23 (UnionRDD[105] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:17.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 4.2 KB, free 243.2 KB)
2016-12-14 14:06:17.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.4 KB, free 245.7 KB)
2016-12-14 14:06:17.026 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_23_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:17.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:17.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 23 (UnionRDD[105] at union at DStream.scala:617)
2016-12-14 14:06:17.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 23.0 with 1 tasks
2016-12-14 14:06:17.028 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 23.0 (TID 23, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:17.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 23.0 (TID 23)
2016-12-14 14:06:17.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 23.0 (TID 23). 1159 bytes result sent to driver
2016-12-14 14:06:17.035 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 23.0 (TID 23) in 7 ms on localhost (1/1)
2016-12-14 14:06:17.035 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 23 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 24)
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:17.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 24 (MapPartitionsRDD[108] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:17.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 249.4 KB)
2016-12-14 14:06:17.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.1 KB, free 251.5 KB)
2016-12-14 14:06:17.044 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_24_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:17.045 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:17.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[108] at count at LogStream.java:120)
2016-12-14 14:06:17.046 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 24.0 with 1 tasks
2016-12-14 14:06:17.047 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 24.0 (TID 24, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:17.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 24.0 (TID 24)
2016-12-14 14:06:17.049 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:17.049 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:17.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 24.0 (TID 24). 1241 bytes result sent to driver
2016-12-14 14:06:17.050 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 24.0 (TID 24) in 4 ms on localhost (1/1)
2016-12-14 14:06:17.051 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:06:17.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 24 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:17.052 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: take at LogStream.java:127, took 0.032186 s
2016-12-14 14:06:17.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695577000 ms.1 from job set of time 1481695577000 ms
2016-12-14 14:06:17.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.061 s for time 1481695577000 ms (execution: 0.046 s)
2016-12-14 14:06:17.061 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 91 from persistence list
2016-12-14 14:06:17.061 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 91
2016-12-14 14:06:17.062 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[91] at createStream at LogStream.java:100 of time 1481695577000 ms
2016-12-14 14:06:17.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 99 from persistence list
2016-12-14 14:06:17.062 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 99
2016-12-14 14:06:17.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 98 from persistence list
2016-12-14 14:06:17.063 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 98
2016-12-14 14:06:17.063 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 97 from persistence list
2016-12-14 14:06:17.063 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 97
2016-12-14 14:06:17.063 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 96 from persistence list
2016-12-14 14:06:17.064 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 96
2016-12-14 14:06:17.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 94 from persistence list
2016-12-14 14:06:17.064 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 94
2016-12-14 14:06:17.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 93 from persistence list
2016-12-14 14:06:17.065 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 93
2016-12-14 14:06:17.066 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 92 from persistence list
2016-12-14 14:06:17.067 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695575000 ms)
2016-12-14 14:06:17.067 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695575000 ms
2016-12-14 14:06:17.068 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 92
2016-12-14 14:06:18.015 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695578000 ms
2016-12-14 14:06:18.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695578000 ms.0 from job set of time 1481695578000 ms
2016-12-14 14:06:18.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695578000 ms.0 from job set of time 1481695578000 ms
2016-12-14 14:06:18.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695578000 ms.1 from job set of time 1481695578000 ms
2016-12-14 14:06:18.022 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:18.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 114 (union at DStream.scala:617)
2016-12-14 14:06:18.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:18.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 26 (take at LogStream.java:127)
2016-12-14 14:06:18.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 25)
2016-12-14 14:06:18.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 25)
2016-12-14 14:06:18.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 25 (UnionRDD[114] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:18.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 4.2 KB, free 255.7 KB)
2016-12-14 14:06:18.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.4 KB, free 258.1 KB)
2016-12-14 14:06:18.030 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_25_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:18.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:18.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 25 (UnionRDD[114] at union at DStream.scala:617)
2016-12-14 14:06:18.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 25.0 with 1 tasks
2016-12-14 14:06:18.033 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 25.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:18.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 25.0 (TID 25)
2016-12-14 14:06:18.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 25.0 (TID 25). 1159 bytes result sent to driver
2016-12-14 14:06:18.039 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 25.0 (TID 25) in 6 ms on localhost (1/1)
2016-12-14 14:06:18.039 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:06:18.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 25 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:18.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:18.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:18.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 26)
2016-12-14 14:06:18.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:18.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 26 (MapPartitionsRDD[117] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:18.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 261.8 KB)
2016-12-14 14:06:18.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.1 KB, free 263.9 KB)
2016-12-14 14:06:18.049 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_26_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:18.050 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:18.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[117] at count at LogStream.java:120)
2016-12-14 14:06:18.050 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 26.0 with 1 tasks
2016-12-14 14:06:18.057 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 26.0 (TID 26, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:18.060 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 26.0 (TID 26)
2016-12-14 14:06:18.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:18.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:18.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 26.0 (TID 26). 1241 bytes result sent to driver
2016-12-14 14:06:18.065 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 26.0 (TID 26) in 8 ms on localhost (1/1)
2016-12-14 14:06:18.065 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:06:18.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 26 (take at LogStream.java:127) finished in 0.014 s
2016-12-14 14:06:18.067 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: take at LogStream.java:127, took 0.044166 s
2016-12-14 14:06:18.074 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695578000 ms.1 from job set of time 1481695578000 ms
2016-12-14 14:06:18.074 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 100 from persistence list
2016-12-14 14:06:18.074 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.074 s for time 1481695578000 ms (execution: 0.059 s)
2016-12-14 14:06:18.074 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 100
2016-12-14 14:06:18.075 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[100] at createStream at LogStream.java:100 of time 1481695578000 ms
2016-12-14 14:06:18.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 108 from persistence list
2016-12-14 14:06:18.076 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 108
2016-12-14 14:06:18.076 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 107 from persistence list
2016-12-14 14:06:18.076 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 107
2016-12-14 14:06:18.077 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 106 from persistence list
2016-12-14 14:06:18.077 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 106
2016-12-14 14:06:18.077 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 105 from persistence list
2016-12-14 14:06:18.078 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 105
2016-12-14 14:06:18.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 103 from persistence list
2016-12-14 14:06:18.079 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 103
2016-12-14 14:06:18.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 102 from persistence list
2016-12-14 14:06:18.079 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 102
2016-12-14 14:06:18.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 101 from persistence list
2016-12-14 14:06:18.080 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 101
2016-12-14 14:06:18.080 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695576000 ms)
2016-12-14 14:06:18.080 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695576000 ms
2016-12-14 14:06:19.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695579000 ms
2016-12-14 14:06:19.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695579000 ms.0 from job set of time 1481695579000 ms
2016-12-14 14:06:19.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695579000 ms.0 from job set of time 1481695579000 ms
2016-12-14 14:06:19.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695579000 ms.1 from job set of time 1481695579000 ms
2016-12-14 14:06:19.022 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 123 (union at DStream.scala:617)
2016-12-14 14:06:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 28 (take at LogStream.java:127)
2016-12-14 14:06:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 27)
2016-12-14 14:06:19.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 27)
2016-12-14 14:06:19.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 27 (UnionRDD[123] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:19.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 4.2 KB, free 268.1 KB)
2016-12-14 14:06:19.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.4 KB, free 270.6 KB)
2016-12-14 14:06:19.030 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_27_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:19.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:19.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 27 (UnionRDD[123] at union at DStream.scala:617)
2016-12-14 14:06:19.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 27.0 with 1 tasks
2016-12-14 14:06:19.032 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 27.0 (TID 27, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:19.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 27.0 (TID 27)
2016-12-14 14:06:19.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 27.0 (TID 27). 1159 bytes result sent to driver
2016-12-14 14:06:19.037 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 27.0 (TID 27) in 5 ms on localhost (1/1)
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 27 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:19.037 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 28)
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:19.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 28 (MapPartitionsRDD[126] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:19.039 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 3.7 KB, free 274.3 KB)
2016-12-14 14:06:19.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.1 KB, free 276.4 KB)
2016-12-14 14:06:19.044 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_28_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:19.045 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:19.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[126] at count at LogStream.java:120)
2016-12-14 14:06:19.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 28.0 with 1 tasks
2016-12-14 14:06:19.046 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 28.0 (TID 28, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:19.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 28.0 (TID 28)
2016-12-14 14:06:19.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:19.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:19.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 28.0 (TID 28). 1241 bytes result sent to driver
2016-12-14 14:06:19.051 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 28.0 (TID 28) in 5 ms on localhost (1/1)
2016-12-14 14:06:19.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 28 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:06:19.052 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:06:19.052 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: take at LogStream.java:127, took 0.030005 s
2016-12-14 14:06:19.079 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695579000 ms.1 from job set of time 1481695579000 ms
2016-12-14 14:06:19.079 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 109 from persistence list
2016-12-14 14:06:19.079 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.079 s for time 1481695579000 ms (execution: 0.063 s)
2016-12-14 14:06:19.080 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 109
2016-12-14 14:06:19.080 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[109] at createStream at LogStream.java:100 of time 1481695579000 ms
2016-12-14 14:06:19.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 117 from persistence list
2016-12-14 14:06:19.080 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 117
2016-12-14 14:06:19.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 116 from persistence list
2016-12-14 14:06:19.081 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 116
2016-12-14 14:06:19.081 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 115 from persistence list
2016-12-14 14:06:19.082 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 115
2016-12-14 14:06:19.082 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 114 from persistence list
2016-12-14 14:06:19.083 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 114
2016-12-14 14:06:19.083 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 112 from persistence list
2016-12-14 14:06:19.083 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 112
2016-12-14 14:06:19.083 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 111 from persistence list
2016-12-14 14:06:19.084 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 111
2016-12-14 14:06:19.084 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 110 from persistence list
2016-12-14 14:06:19.085 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 110
2016-12-14 14:06:19.085 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695577000 ms)
2016-12-14 14:06:19.085 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695577000 ms
2016-12-14 14:06:20.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695580000 ms
2016-12-14 14:06:20.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695580000 ms.0 from job set of time 1481695580000 ms
2016-12-14 14:06:20.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695580000 ms.0 from job set of time 1481695580000 ms
2016-12-14 14:06:20.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695580000 ms.1 from job set of time 1481695580000 ms
2016-12-14 14:06:20.020 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 132 (union at DStream.scala:617)
2016-12-14 14:06:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 30 (take at LogStream.java:127)
2016-12-14 14:06:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 29)
2016-12-14 14:06:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 29)
2016-12-14 14:06:20.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 29 (UnionRDD[132] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:20.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 4.2 KB, free 280.6 KB)
2016-12-14 14:06:20.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 KB, free 283.0 KB)
2016-12-14 14:06:20.029 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_29_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:20.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:20.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 29 (UnionRDD[132] at union at DStream.scala:617)
2016-12-14 14:06:20.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 29.0 with 1 tasks
2016-12-14 14:06:20.032 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 29.0 (TID 29, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:20.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 29.0 (TID 29)
2016-12-14 14:06:20.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 29.0 (TID 29). 1159 bytes result sent to driver
2016-12-14 14:06:20.038 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 29.0 (TID 29) in 6 ms on localhost (1/1)
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 29 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:06:20.038 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 30)
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:20.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 30 (MapPartitionsRDD[135] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:20.039 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_30 stored as values in memory (estimated size 3.7 KB, free 286.7 KB)
2016-12-14 14:06:20.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.1 KB, free 288.8 KB)
2016-12-14 14:06:20.043 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_30_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:20.044 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:20.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[135] at count at LogStream.java:120)
2016-12-14 14:06:20.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 30.0 with 1 tasks
2016-12-14 14:06:20.045 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 30.0 (TID 30, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:20.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 30.0 (TID 30)
2016-12-14 14:06:20.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:20.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:20.049 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 30.0 (TID 30). 1241 bytes result sent to driver
2016-12-14 14:06:20.049 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 30.0 (TID 30) in 4 ms on localhost (1/1)
2016-12-14 14:06:20.049 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:06:20.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 30 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:20.050 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: take at LogStream.java:127, took 0.029320 s
2016-12-14 14:06:20.056 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695580000 ms.1 from job set of time 1481695580000 ms
2016-12-14 14:06:20.056 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.056 s for time 1481695580000 ms (execution: 0.042 s)
2016-12-14 14:06:20.056 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 118 from persistence list
2016-12-14 14:06:20.057 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 118
2016-12-14 14:06:20.057 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[118] at createStream at LogStream.java:100 of time 1481695580000 ms
2016-12-14 14:06:20.057 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 126 from persistence list
2016-12-14 14:06:20.058 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 126
2016-12-14 14:06:20.058 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 125 from persistence list
2016-12-14 14:06:20.058 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 124 from persistence list
2016-12-14 14:06:20.058 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 125
2016-12-14 14:06:20.059 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 124
2016-12-14 14:06:20.059 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 123 from persistence list
2016-12-14 14:06:20.061 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 123
2016-12-14 14:06:20.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 121 from persistence list
2016-12-14 14:06:20.062 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 121
2016-12-14 14:06:20.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 120 from persistence list
2016-12-14 14:06:20.062 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 120
2016-12-14 14:06:20.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 119 from persistence list
2016-12-14 14:06:20.063 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 119
2016-12-14 14:06:20.063 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695578000 ms)
2016-12-14 14:06:20.063 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695578000 ms
2016-12-14 14:06:21.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695581000 ms
2016-12-14 14:06:21.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695581000 ms.0 from job set of time 1481695581000 ms
2016-12-14 14:06:21.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695581000 ms.0 from job set of time 1481695581000 ms
2016-12-14 14:06:21.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695581000 ms.1 from job set of time 1481695581000 ms
2016-12-14 14:06:21.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 141 (union at DStream.scala:617)
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 32 (take at LogStream.java:127)
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 31)
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 31)
2016-12-14 14:06:21.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 31 (UnionRDD[141] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:21.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_31 stored as values in memory (estimated size 4.2 KB, free 293.0 KB)
2016-12-14 14:06:21.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.4 KB, free 295.5 KB)
2016-12-14 14:06:21.028 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_31_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:21.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:21.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 31 (UnionRDD[141] at union at DStream.scala:617)
2016-12-14 14:06:21.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 31.0 with 1 tasks
2016-12-14 14:06:21.035 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 31.0 (TID 31, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:21.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 31.0 (TID 31)
2016-12-14 14:06:21.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 31.0 (TID 31). 1159 bytes result sent to driver
2016-12-14 14:06:21.046 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 31.0 (TID 31) in 12 ms on localhost (1/1)
2016-12-14 14:06:21.046 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:06:21.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 31 (union at DStream.scala:617) finished in 0.016 s
2016-12-14 14:06:21.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:21.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:21.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 32)
2016-12-14 14:06:21.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:21.047 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 32 (MapPartitionsRDD[144] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:21.049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_32 stored as values in memory (estimated size 3.7 KB, free 299.2 KB)
2016-12-14 14:06:21.057 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.1 KB, free 301.3 KB)
2016-12-14 14:06:21.060 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_32_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:21.061 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:21.061 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[144] at count at LogStream.java:120)
2016-12-14 14:06:21.061 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 32.0 with 1 tasks
2016-12-14 14:06:21.062 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 32.0 (TID 32, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:21.063 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 32.0 (TID 32)
2016-12-14 14:06:21.066 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:21.066 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:21.067 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 32.0 (TID 32). 1241 bytes result sent to driver
2016-12-14 14:06:21.071 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 32.0 (TID 32) in 9 ms on localhost (1/1)
2016-12-14 14:06:21.071 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:06:21.072 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 32 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:06:21.074 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: take at LogStream.java:127, took 0.055708 s
2016-12-14 14:06:21.081 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695581000 ms.1 from job set of time 1481695581000 ms
2016-12-14 14:06:21.082 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.081 s for time 1481695581000 ms (execution: 0.068 s)
2016-12-14 14:06:21.082 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 127 from persistence list
2016-12-14 14:06:21.082 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 127
2016-12-14 14:06:21.082 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[127] at createStream at LogStream.java:100 of time 1481695581000 ms
2016-12-14 14:06:21.082 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 135 from persistence list
2016-12-14 14:06:21.083 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 134 from persistence list
2016-12-14 14:06:21.083 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 135
2016-12-14 14:06:21.084 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 133 from persistence list
2016-12-14 14:06:21.084 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 134
2016-12-14 14:06:21.084 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 133
2016-12-14 14:06:21.084 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 132 from persistence list
2016-12-14 14:06:21.085 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 130 from persistence list
2016-12-14 14:06:21.085 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 132
2016-12-14 14:06:21.086 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 129 from persistence list
2016-12-14 14:06:21.086 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 130
2016-12-14 14:06:21.087 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 128 from persistence list
2016-12-14 14:06:21.087 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 129
2016-12-14 14:06:21.093 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695579000 ms)
2016-12-14 14:06:21.093 [block-manager-slave-async-thread-pool-9] INFO  o.apache.spark.storage.BlockManager - Removing RDD 128
2016-12-14 14:06:21.093 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695579000 ms
2016-12-14 14:06:22.031 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695582000 ms
2016-12-14 14:06:22.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695582000 ms.0 from job set of time 1481695582000 ms
2016-12-14 14:06:22.033 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695582000 ms.0 from job set of time 1481695582000 ms
2016-12-14 14:06:22.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695582000 ms.1 from job set of time 1481695582000 ms
2016-12-14 14:06:22.039 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:22.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 150 (union at DStream.scala:617)
2016-12-14 14:06:22.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 17 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:22.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 34 (take at LogStream.java:127)
2016-12-14 14:06:22.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 33)
2016-12-14 14:06:22.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 33)
2016-12-14 14:06:22.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 33 (UnionRDD[150] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:22.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_33 stored as values in memory (estimated size 4.2 KB, free 303.0 KB)
2016-12-14 14:06:22.048 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_27_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.4 KB, free 305.5 KB)
2016-12-14 14:06:22.052 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_33_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.055 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:22.055 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 33 (UnionRDD[150] at union at DStream.scala:617)
2016-12-14 14:06:22.055 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 33.0 with 1 tasks
2016-12-14 14:06:22.057 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 33.0 (TID 33, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:22.058 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 33.0 (TID 33)
2016-12-14 14:06:22.062 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 33.0 (TID 33). 1159 bytes result sent to driver
2016-12-14 14:06:22.063 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 33.0 (TID 33) in 6 ms on localhost (1/1)
2016-12-14 14:06:22.063 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:06:22.063 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 33 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:22.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:22.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:22.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 34)
2016-12-14 14:06:22.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:22.064 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 34 (MapPartitionsRDD[153] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:22.066 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_34 stored as values in memory (estimated size 3.7 KB, free 302.5 KB)
2016-12-14 14:06:22.068 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.1 KB, free 300.4 KB)
2016-12-14 14:06:22.069 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_34_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 10
2016-12-14 14:06:22.070 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:22.070 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[153] at count at LogStream.java:120)
2016-12-14 14:06:22.070 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 34.0 with 1 tasks
2016-12-14 14:06:22.072 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 34.0 (TID 34, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:22.072 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 34.0 (TID 34)
2016-12-14 14:06:22.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 4
2016-12-14 14:06:22.074 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:22.074 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:22.075 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.075 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 34.0 (TID 34). 1241 bytes result sent to driver
2016-12-14 14:06:22.078 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 34.0 (TID 34) in 7 ms on localhost (1/1)
2016-12-14 14:06:22.078 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:06:22.079 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 34 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:06:22.080 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 finished: take at LogStream.java:127, took 0.040053 s
2016-12-14 14:06:22.080 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 9
2016-12-14 14:06:22.083 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 8
2016-12-14 14:06:22.084 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 3
2016-12-14 14:06:22.086 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.086 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 7
2016-12-14 14:06:22.089 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.091 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695582000 ms.1 from job set of time 1481695582000 ms
2016-12-14 14:06:22.092 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.091 s for time 1481695582000 ms (execution: 0.059 s)
2016-12-14 14:06:22.092 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 136 from persistence list
2016-12-14 14:06:22.093 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 6
2016-12-14 14:06:22.093 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[136] at createStream at LogStream.java:100 of time 1481695582000 ms
2016-12-14 14:06:22.093 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 144 from persistence list
2016-12-14 14:06:22.094 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 2
2016-12-14 14:06:22.094 [block-manager-slave-async-thread-pool-9] INFO  o.apache.spark.storage.BlockManager - Removing RDD 136
2016-12-14 14:06:22.095 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 143 from persistence list
2016-12-14 14:06:22.095 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 144
2016-12-14 14:06:22.096 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.096 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 142 from persistence list
2016-12-14 14:06:22.096 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 143
2016-12-14 14:06:22.097 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 141 from persistence list
2016-12-14 14:06:22.097 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 142
2016-12-14 14:06:22.098 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 139 from persistence list
2016-12-14 14:06:22.098 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 141
2016-12-14 14:06:22.098 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 5
2016-12-14 14:06:22.098 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 139
2016-12-14 14:06:22.099 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 138 from persistence list
2016-12-14 14:06:22.099 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.100 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 137 from persistence list
2016-12-14 14:06:22.100 [block-manager-slave-async-thread-pool-9] INFO  o.apache.spark.storage.BlockManager - Removing RDD 138
2016-12-14 14:06:22.100 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 137
2016-12-14 14:06:22.100 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 4
2016-12-14 14:06:22.101 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695580000 ms)
2016-12-14 14:06:22.101 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695580000 ms
2016-12-14 14:06:22.101 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 1
2016-12-14 14:06:22.103 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.105 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 3
2016-12-14 14:06:22.106 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.106 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 2
2016-12-14 14:06:22.107 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_20_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.107 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 21
2016-12-14 14:06:22.108 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_19_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.108 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 20
2016-12-14 14:06:22.109 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 9
2016-12-14 14:06:22.110 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_18_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.110 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 19
2016-12-14 14:06:22.111 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.111 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 18
2016-12-14 14:06:22.112 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 8
2016-12-14 14:06:22.114 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.115 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 17
2016-12-14 14:06:22.116 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.116 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 16
2016-12-14 14:06:22.117 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 7
2016-12-14 14:06:22.118 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.119 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 15
2016-12-14 14:06:22.120 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.120 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 14
2016-12-14 14:06:22.120 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 6
2016-12-14 14:06:22.121 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.121 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 13
2016-12-14 14:06:22.122 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.123 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 12
2016-12-14 14:06:22.123 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 5
2016-12-14 14:06:22.124 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.124 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 11
2016-12-14 14:06:22.124 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 33
2016-12-14 14:06:22.125 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_31_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.125 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 32
2016-12-14 14:06:22.127 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_30_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.128 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 31
2016-12-14 14:06:22.128 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_29_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.129 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 30
2016-12-14 14:06:22.129 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 14
2016-12-14 14:06:22.130 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_28_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.131 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 29
2016-12-14 14:06:22.131 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 28
2016-12-14 14:06:22.133 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 13
2016-12-14 14:06:22.134 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_26_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.134 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 27
2016-12-14 14:06:22.135 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_25_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.136 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 26
2016-12-14 14:06:22.137 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 12
2016-12-14 14:06:22.138 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_24_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.140 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 25
2016-12-14 14:06:22.140 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_23_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.141 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 24
2016-12-14 14:06:22.141 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 11
2016-12-14 14:06:22.142 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_22_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:22.143 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 23
2016-12-14 14:06:22.143 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_21_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:22.144 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 22
2016-12-14 14:06:22.144 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 10
2016-12-14 14:06:22.145 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_32_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:23.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695583000 ms
2016-12-14 14:06:23.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695583000 ms.0 from job set of time 1481695583000 ms
2016-12-14 14:06:23.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695583000 ms.0 from job set of time 1481695583000 ms
2016-12-14 14:06:23.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695583000 ms.1 from job set of time 1481695583000 ms
2016-12-14 14:06:23.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:23.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 159 (union at DStream.scala:617)
2016-12-14 14:06:23.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:23.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 36 (take at LogStream.java:127)
2016-12-14 14:06:23.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 35)
2016-12-14 14:06:23.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 35)
2016-12-14 14:06:23.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 35 (UnionRDD[159] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:23.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 4.2 KB, free 118.7 KB)
2016-12-14 14:06:23.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.4 KB, free 121.2 KB)
2016-12-14 14:06:23.019 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_35_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:23.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:23.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 35 (UnionRDD[159] at union at DStream.scala:617)
2016-12-14 14:06:23.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 35.0 with 1 tasks
2016-12-14 14:06:23.021 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 35.0 (TID 35, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:23.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 35.0 (TID 35)
2016-12-14 14:06:23.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 35.0 (TID 35). 1159 bytes result sent to driver
2016-12-14 14:06:23.025 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 35.0 (TID 35) in 4 ms on localhost (1/1)
2016-12-14 14:06:23.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 35 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:23.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:06:23.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:23.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:23.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 36)
2016-12-14 14:06:23.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:23.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 36 (MapPartitionsRDD[162] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:23.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_36 stored as values in memory (estimated size 3.7 KB, free 124.9 KB)
2016-12-14 14:06:23.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 127.0 KB)
2016-12-14 14:06:23.029 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_36_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:23.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 36 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:23.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[162] at count at LogStream.java:120)
2016-12-14 14:06:23.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 36.0 with 1 tasks
2016-12-14 14:06:23.030 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 36.0 (TID 36, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:23.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 36.0 (TID 36)
2016-12-14 14:06:23.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:23.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:23.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 36.0 (TID 36). 1241 bytes result sent to driver
2016-12-14 14:06:23.034 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 36.0 (TID 36) in 4 ms on localhost (1/1)
2016-12-14 14:06:23.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 36 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:23.034 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:06:23.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: take at LogStream.java:127, took 0.019706 s
2016-12-14 14:06:23.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695583000 ms.1 from job set of time 1481695583000 ms
2016-12-14 14:06:23.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 145 from persistence list
2016-12-14 14:06:23.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.043 s for time 1481695583000 ms (execution: 0.032 s)
2016-12-14 14:06:23.043 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 145
2016-12-14 14:06:23.043 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[145] at createStream at LogStream.java:100 of time 1481695583000 ms
2016-12-14 14:06:23.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 153 from persistence list
2016-12-14 14:06:23.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 153
2016-12-14 14:06:23.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 152 from persistence list
2016-12-14 14:06:23.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 152
2016-12-14 14:06:23.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 151 from persistence list
2016-12-14 14:06:23.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 151
2016-12-14 14:06:23.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 150 from persistence list
2016-12-14 14:06:23.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 150
2016-12-14 14:06:23.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 148 from persistence list
2016-12-14 14:06:23.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 148
2016-12-14 14:06:23.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 147 from persistence list
2016-12-14 14:06:23.045 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 147
2016-12-14 14:06:23.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 146 from persistence list
2016-12-14 14:06:23.045 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 146
2016-12-14 14:06:23.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695581000 ms)
2016-12-14 14:06:23.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695581000 ms
2016-12-14 14:06:24.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695584000 ms
2016-12-14 14:06:24.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695584000 ms.0 from job set of time 1481695584000 ms
2016-12-14 14:06:24.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695584000 ms.0 from job set of time 1481695584000 ms
2016-12-14 14:06:24.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695584000 ms.1 from job set of time 1481695584000 ms
2016-12-14 14:06:24.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 168 (union at DStream.scala:617)
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 38 (take at LogStream.java:127)
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 37)
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 37)
2016-12-14 14:06:24.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 37 (UnionRDD[168] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:24.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_37 stored as values in memory (estimated size 4.2 KB, free 131.2 KB)
2016-12-14 14:06:24.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.4 KB, free 133.6 KB)
2016-12-14 14:06:24.017 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_37_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:24.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 37 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:24.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 37 (UnionRDD[168] at union at DStream.scala:617)
2016-12-14 14:06:24.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 37.0 with 1 tasks
2016-12-14 14:06:24.019 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 37.0 (TID 37, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:24.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 37.0 (TID 37)
2016-12-14 14:06:24.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 37.0 (TID 37). 1159 bytes result sent to driver
2016-12-14 14:06:24.023 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 37.0 (TID 37) in 5 ms on localhost (1/1)
2016-12-14 14:06:24.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 37 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:24.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:24.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:06:24.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:24.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 38)
2016-12-14 14:06:24.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:24.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 38 (MapPartitionsRDD[171] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:24.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_38 stored as values in memory (estimated size 3.7 KB, free 137.3 KB)
2016-12-14 14:06:24.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.1 KB, free 139.4 KB)
2016-12-14 14:06:24.027 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_38_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:24.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 38 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:24.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[171] at count at LogStream.java:120)
2016-12-14 14:06:24.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 38.0 with 1 tasks
2016-12-14 14:06:24.029 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 38.0 (TID 38, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:24.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 38.0 (TID 38)
2016-12-14 14:06:24.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:24.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:24.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 38.0 (TID 38). 1241 bytes result sent to driver
2016-12-14 14:06:24.033 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 38.0 (TID 38) in 4 ms on localhost (1/1)
2016-12-14 14:06:24.033 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:06:24.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 38 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:06:24.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: take at LogStream.java:127, took 0.020960 s
2016-12-14 14:06:24.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695584000 ms.1 from job set of time 1481695584000 ms
2016-12-14 14:06:24.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.041 s for time 1481695584000 ms (execution: 0.032 s)
2016-12-14 14:06:24.041 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 154 from persistence list
2016-12-14 14:06:24.042 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 154
2016-12-14 14:06:24.042 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[154] at createStream at LogStream.java:100 of time 1481695584000 ms
2016-12-14 14:06:24.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 162 from persistence list
2016-12-14 14:06:24.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 162
2016-12-14 14:06:24.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 161 from persistence list
2016-12-14 14:06:24.043 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 161
2016-12-14 14:06:24.043 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 160 from persistence list
2016-12-14 14:06:24.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 160
2016-12-14 14:06:24.043 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 159 from persistence list
2016-12-14 14:06:24.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 159
2016-12-14 14:06:24.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 157 from persistence list
2016-12-14 14:06:24.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 157
2016-12-14 14:06:24.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 156 from persistence list
2016-12-14 14:06:24.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 156
2016-12-14 14:06:24.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 155 from persistence list
2016-12-14 14:06:24.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 155
2016-12-14 14:06:24.044 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695582000 ms)
2016-12-14 14:06:24.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695582000 ms
2016-12-14 14:06:25.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695585000 ms
2016-12-14 14:06:25.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695585000 ms.0 from job set of time 1481695585000 ms
2016-12-14 14:06:25.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695585000 ms.0 from job set of time 1481695585000 ms
2016-12-14 14:06:25.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695585000 ms.1 from job set of time 1481695585000 ms
2016-12-14 14:06:25.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:25.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 177 (union at DStream.scala:617)
2016-12-14 14:06:25.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 20 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:25.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 40 (take at LogStream.java:127)
2016-12-14 14:06:25.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 39)
2016-12-14 14:06:25.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 39)
2016-12-14 14:06:25.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 39 (UnionRDD[177] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:25.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_39 stored as values in memory (estimated size 4.2 KB, free 143.6 KB)
2016-12-14 14:06:25.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.4 KB, free 146.1 KB)
2016-12-14 14:06:25.025 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_39_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:25.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 39 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:25.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 39 (UnionRDD[177] at union at DStream.scala:617)
2016-12-14 14:06:25.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 39.0 with 1 tasks
2016-12-14 14:06:25.027 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 39.0 (TID 39, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:25.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 39.0 (TID 39)
2016-12-14 14:06:25.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 39.0 (TID 39). 1159 bytes result sent to driver
2016-12-14 14:06:25.033 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 39.0 (TID 39) in 7 ms on localhost (1/1)
2016-12-14 14:06:25.033 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 39 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 40)
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:25.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 40 (MapPartitionsRDD[180] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:25.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_40 stored as values in memory (estimated size 3.7 KB, free 149.8 KB)
2016-12-14 14:06:25.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_40_piece0 stored as bytes in memory (estimated size 2.1 KB, free 151.9 KB)
2016-12-14 14:06:25.037 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_40_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:25.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 40 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:25.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[180] at count at LogStream.java:120)
2016-12-14 14:06:25.039 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 40.0 with 1 tasks
2016-12-14 14:06:25.040 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 40.0 (TID 40, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:25.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 40.0 (TID 40)
2016-12-14 14:06:25.042 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:25.042 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:25.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 40.0 (TID 40). 1241 bytes result sent to driver
2016-12-14 14:06:25.044 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 40.0 (TID 40) in 4 ms on localhost (1/1)
2016-12-14 14:06:25.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 40 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:25.044 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:06:25.044 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 finished: take at LogStream.java:127, took 0.025856 s
2016-12-14 14:06:25.104 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695585000 ms.1 from job set of time 1481695585000 ms
2016-12-14 14:06:25.104 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.104 s for time 1481695585000 ms (execution: 0.092 s)
2016-12-14 14:06:25.105 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 163 from persistence list
2016-12-14 14:06:25.105 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 163
2016-12-14 14:06:25.105 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[163] at createStream at LogStream.java:100 of time 1481695585000 ms
2016-12-14 14:06:25.105 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 171 from persistence list
2016-12-14 14:06:25.105 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 171
2016-12-14 14:06:25.106 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 170 from persistence list
2016-12-14 14:06:25.106 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 170
2016-12-14 14:06:25.107 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 169 from persistence list
2016-12-14 14:06:25.107 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 169
2016-12-14 14:06:25.107 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 168 from persistence list
2016-12-14 14:06:25.107 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 168
2016-12-14 14:06:25.108 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 166 from persistence list
2016-12-14 14:06:25.108 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 166
2016-12-14 14:06:25.108 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 165 from persistence list
2016-12-14 14:06:25.108 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 165
2016-12-14 14:06:25.108 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 164 from persistence list
2016-12-14 14:06:25.108 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 164
2016-12-14 14:06:25.109 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695583000 ms)
2016-12-14 14:06:25.109 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695583000 ms
2016-12-14 14:06:26.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695586000 ms
2016-12-14 14:06:26.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695586000 ms.0 from job set of time 1481695586000 ms
2016-12-14 14:06:26.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695586000 ms.0 from job set of time 1481695586000 ms
2016-12-14 14:06:26.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695586000 ms.1 from job set of time 1481695586000 ms
2016-12-14 14:06:26.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 186 (union at DStream.scala:617)
2016-12-14 14:06:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 21 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 42 (take at LogStream.java:127)
2016-12-14 14:06:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 41)
2016-12-14 14:06:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 41)
2016-12-14 14:06:26.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 41 (UnionRDD[186] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:26.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_41 stored as values in memory (estimated size 4.2 KB, free 156.1 KB)
2016-12-14 14:06:26.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.4 KB, free 158.5 KB)
2016-12-14 14:06:26.025 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_41_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:26.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 41 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:26.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 41 (UnionRDD[186] at union at DStream.scala:617)
2016-12-14 14:06:26.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 41.0 with 1 tasks
2016-12-14 14:06:26.027 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 41.0 (TID 41, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:26.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 41.0 (TID 41)
2016-12-14 14:06:26.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 41.0 (TID 41). 1159 bytes result sent to driver
2016-12-14 14:06:26.035 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 41.0 (TID 41) in 8 ms on localhost (1/1)
2016-12-14 14:06:26.036 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:06:26.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 41 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:06:26.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:26.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:26.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 42)
2016-12-14 14:06:26.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:26.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 42 (MapPartitionsRDD[189] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:26.039 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_42 stored as values in memory (estimated size 3.7 KB, free 162.2 KB)
2016-12-14 14:06:26.041 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.1 KB, free 164.3 KB)
2016-12-14 14:06:26.042 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_42_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:26.042 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 42 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:26.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[189] at count at LogStream.java:120)
2016-12-14 14:06:26.043 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 42.0 with 1 tasks
2016-12-14 14:06:26.043 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 42.0 (TID 42, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:26.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 42.0 (TID 42)
2016-12-14 14:06:26.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:26.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:26.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 42.0 (TID 42). 1241 bytes result sent to driver
2016-12-14 14:06:26.051 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 42.0 (TID 42) in 8 ms on localhost (1/1)
2016-12-14 14:06:26.051 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:06:26.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 42 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:06:26.052 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 21 finished: take at LogStream.java:127, took 0.032079 s
2016-12-14 14:06:26.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695586000 ms.1 from job set of time 1481695586000 ms
2016-12-14 14:06:26.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.060 s for time 1481695586000 ms (execution: 0.045 s)
2016-12-14 14:06:26.060 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 172 from persistence list
2016-12-14 14:06:26.063 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 172
2016-12-14 14:06:26.063 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[172] at createStream at LogStream.java:100 of time 1481695586000 ms
2016-12-14 14:06:26.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 180 from persistence list
2016-12-14 14:06:26.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 179 from persistence list
2016-12-14 14:06:26.064 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 180
2016-12-14 14:06:26.066 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 178 from persistence list
2016-12-14 14:06:26.067 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 179
2016-12-14 14:06:26.068 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 177 from persistence list
2016-12-14 14:06:26.068 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 178
2016-12-14 14:06:26.068 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 175 from persistence list
2016-12-14 14:06:26.068 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 177
2016-12-14 14:06:26.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 174 from persistence list
2016-12-14 14:06:26.071 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 175
2016-12-14 14:06:26.072 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 174
2016-12-14 14:06:26.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 173 from persistence list
2016-12-14 14:06:26.072 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 173
2016-12-14 14:06:26.072 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695584000 ms)
2016-12-14 14:06:26.072 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695584000 ms
2016-12-14 14:06:27.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695587000 ms
2016-12-14 14:06:27.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695587000 ms.0 from job set of time 1481695587000 ms
2016-12-14 14:06:27.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695587000 ms.0 from job set of time 1481695587000 ms
2016-12-14 14:06:27.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695587000 ms.1 from job set of time 1481695587000 ms
2016-12-14 14:06:27.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 195 (union at DStream.scala:617)
2016-12-14 14:06:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 22 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 44 (take at LogStream.java:127)
2016-12-14 14:06:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 43)
2016-12-14 14:06:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 43)
2016-12-14 14:06:27.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 43 (UnionRDD[195] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:27.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_43 stored as values in memory (estimated size 4.2 KB, free 168.5 KB)
2016-12-14 14:06:27.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.4 KB, free 171.0 KB)
2016-12-14 14:06:27.023 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_43_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:27.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 43 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:27.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 43 (UnionRDD[195] at union at DStream.scala:617)
2016-12-14 14:06:27.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 43.0 with 1 tasks
2016-12-14 14:06:27.025 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 43.0 (TID 43, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:27.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 43.0 (TID 43)
2016-12-14 14:06:27.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 43.0 (TID 43). 1159 bytes result sent to driver
2016-12-14 14:06:27.031 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 43.0 (TID 43) in 6 ms on localhost (1/1)
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 43 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:27.031 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 44)
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 44 (MapPartitionsRDD[198] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:27.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_44 stored as values in memory (estimated size 3.7 KB, free 174.7 KB)
2016-12-14 14:06:27.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.1 KB, free 176.8 KB)
2016-12-14 14:06:27.033 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_44_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:27.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 44 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:27.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[198] at count at LogStream.java:120)
2016-12-14 14:06:27.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 44.0 with 1 tasks
2016-12-14 14:06:27.035 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 44.0 (TID 44, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:27.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 44.0 (TID 44)
2016-12-14 14:06:27.036 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:27.036 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:27.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 44.0 (TID 44). 1241 bytes result sent to driver
2016-12-14 14:06:27.040 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 44.0 (TID 44) in 5 ms on localhost (1/1)
2016-12-14 14:06:27.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 44 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:06:27.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:06:27.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 22 finished: take at LogStream.java:127, took 0.021082 s
2016-12-14 14:06:27.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695587000 ms.1 from job set of time 1481695587000 ms
2016-12-14 14:06:27.046 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 181 from persistence list
2016-12-14 14:06:27.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.046 s for time 1481695587000 ms (execution: 0.031 s)
2016-12-14 14:06:27.047 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 181
2016-12-14 14:06:27.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[181] at createStream at LogStream.java:100 of time 1481695587000 ms
2016-12-14 14:06:27.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 189 from persistence list
2016-12-14 14:06:27.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 188 from persistence list
2016-12-14 14:06:27.048 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 189
2016-12-14 14:06:27.048 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 188
2016-12-14 14:06:27.048 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 187 from persistence list
2016-12-14 14:06:27.048 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 187
2016-12-14 14:06:27.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 186 from persistence list
2016-12-14 14:06:27.049 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 186
2016-12-14 14:06:27.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 184 from persistence list
2016-12-14 14:06:27.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 183 from persistence list
2016-12-14 14:06:27.050 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 184
2016-12-14 14:06:27.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 183
2016-12-14 14:06:27.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 182 from persistence list
2016-12-14 14:06:27.052 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 182
2016-12-14 14:06:27.052 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695585000 ms)
2016-12-14 14:06:27.052 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695585000 ms
2016-12-14 14:06:28.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695588000 ms
2016-12-14 14:06:28.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695588000 ms.0 from job set of time 1481695588000 ms
2016-12-14 14:06:28.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695588000 ms.0 from job set of time 1481695588000 ms
2016-12-14 14:06:28.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695588000 ms.1 from job set of time 1481695588000 ms
2016-12-14 14:06:28.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 204 (union at DStream.scala:617)
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 23 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 46 (take at LogStream.java:127)
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 45)
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 45)
2016-12-14 14:06:28.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 45 (UnionRDD[204] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:28.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_45 stored as values in memory (estimated size 4.2 KB, free 181.0 KB)
2016-12-14 14:06:28.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.4 KB, free 183.4 KB)
2016-12-14 14:06:28.020 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_45_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:28.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 45 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:28.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 45 (UnionRDD[204] at union at DStream.scala:617)
2016-12-14 14:06:28.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 45.0 with 1 tasks
2016-12-14 14:06:28.022 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 45.0 (TID 45, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:28.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 45.0 (TID 45)
2016-12-14 14:06:28.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 45.0 (TID 45). 1159 bytes result sent to driver
2016-12-14 14:06:28.025 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 45.0 (TID 45) in 4 ms on localhost (1/1)
2016-12-14 14:06:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 45 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:28.025 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:06:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 46)
2016-12-14 14:06:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:28.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 46 (MapPartitionsRDD[207] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:28.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_46 stored as values in memory (estimated size 3.7 KB, free 187.1 KB)
2016-12-14 14:06:28.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_46_piece0 stored as bytes in memory (estimated size 2.1 KB, free 189.2 KB)
2016-12-14 14:06:28.028 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_46_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:28.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 46 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:28.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[207] at count at LogStream.java:120)
2016-12-14 14:06:28.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 46.0 with 1 tasks
2016-12-14 14:06:28.029 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 46.0 (TID 46, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:28.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 46.0 (TID 46)
2016-12-14 14:06:28.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:28.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:28.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 46.0 (TID 46). 1241 bytes result sent to driver
2016-12-14 14:06:28.033 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 46.0 (TID 46) in 4 ms on localhost (1/1)
2016-12-14 14:06:28.034 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:06:28.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 46 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:06:28.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 23 finished: take at LogStream.java:127, took 0.018347 s
2016-12-14 14:06:28.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695588000 ms.1 from job set of time 1481695588000 ms
2016-12-14 14:06:28.042 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 190 from persistence list
2016-12-14 14:06:28.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.042 s for time 1481695588000 ms (execution: 0.030 s)
2016-12-14 14:06:28.042 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 190
2016-12-14 14:06:28.042 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[190] at createStream at LogStream.java:100 of time 1481695588000 ms
2016-12-14 14:06:28.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 198 from persistence list
2016-12-14 14:06:28.043 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 198
2016-12-14 14:06:28.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 197 from persistence list
2016-12-14 14:06:28.044 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 197
2016-12-14 14:06:28.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 196 from persistence list
2016-12-14 14:06:28.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 196
2016-12-14 14:06:28.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 195 from persistence list
2016-12-14 14:06:28.044 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 195
2016-12-14 14:06:28.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 193 from persistence list
2016-12-14 14:06:28.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 193
2016-12-14 14:06:28.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 192 from persistence list
2016-12-14 14:06:28.045 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 192
2016-12-14 14:06:28.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 191 from persistence list
2016-12-14 14:06:28.045 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 191
2016-12-14 14:06:28.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695586000 ms)
2016-12-14 14:06:28.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695586000 ms
2016-12-14 14:06:29.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695589000 ms
2016-12-14 14:06:29.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695589000 ms.0 from job set of time 1481695589000 ms
2016-12-14 14:06:29.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695589000 ms.0 from job set of time 1481695589000 ms
2016-12-14 14:06:29.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695589000 ms.1 from job set of time 1481695589000 ms
2016-12-14 14:06:29.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 213 (union at DStream.scala:617)
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 24 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 48 (take at LogStream.java:127)
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 47)
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 47)
2016-12-14 14:06:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 47 (UnionRDD[213] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:29.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_47 stored as values in memory (estimated size 4.2 KB, free 193.4 KB)
2016-12-14 14:06:29.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KB, free 195.9 KB)
2016-12-14 14:06:29.019 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_47_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:29.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 47 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:29.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 47 (UnionRDD[213] at union at DStream.scala:617)
2016-12-14 14:06:29.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 47.0 with 1 tasks
2016-12-14 14:06:29.020 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 47.0 (TID 47, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:29.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 47.0 (TID 47)
2016-12-14 14:06:29.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 47.0 (TID 47). 1159 bytes result sent to driver
2016-12-14 14:06:29.024 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 47.0 (TID 47) in 4 ms on localhost (1/1)
2016-12-14 14:06:29.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 47 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 48)
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:29.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 48 (MapPartitionsRDD[216] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:29.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_48 stored as values in memory (estimated size 3.7 KB, free 199.6 KB)
2016-12-14 14:06:29.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 201.7 KB)
2016-12-14 14:06:29.028 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_48_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:29.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 48 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:29.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[216] at count at LogStream.java:120)
2016-12-14 14:06:29.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 48.0 with 1 tasks
2016-12-14 14:06:29.029 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 48.0 (TID 48, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:29.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 48.0 (TID 48)
2016-12-14 14:06:29.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:29.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:29.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 48.0 (TID 48). 1241 bytes result sent to driver
2016-12-14 14:06:29.033 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 48.0 (TID 48) in 4 ms on localhost (1/1)
2016-12-14 14:06:29.033 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:06:29.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 48 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:29.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 24 finished: take at LogStream.java:127, took 0.019150 s
2016-12-14 14:06:29.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695589000 ms.1 from job set of time 1481695589000 ms
2016-12-14 14:06:29.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.041 s for time 1481695589000 ms (execution: 0.029 s)
2016-12-14 14:06:29.041 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 199 from persistence list
2016-12-14 14:06:29.042 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 199
2016-12-14 14:06:29.042 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[199] at createStream at LogStream.java:100 of time 1481695589000 ms
2016-12-14 14:06:29.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 207 from persistence list
2016-12-14 14:06:29.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 207
2016-12-14 14:06:29.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 206 from persistence list
2016-12-14 14:06:29.043 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 206
2016-12-14 14:06:29.043 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 205 from persistence list
2016-12-14 14:06:29.043 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 205
2016-12-14 14:06:29.043 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 204 from persistence list
2016-12-14 14:06:29.043 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 204
2016-12-14 14:06:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 202 from persistence list
2016-12-14 14:06:29.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 202
2016-12-14 14:06:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 201 from persistence list
2016-12-14 14:06:29.044 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 201
2016-12-14 14:06:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 200 from persistence list
2016-12-14 14:06:29.045 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 200
2016-12-14 14:06:29.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695587000 ms)
2016-12-14 14:06:29.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695587000 ms
2016-12-14 14:06:30.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695590000 ms
2016-12-14 14:06:30.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695590000 ms.0 from job set of time 1481695590000 ms
2016-12-14 14:06:30.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695590000 ms.0 from job set of time 1481695590000 ms
2016-12-14 14:06:30.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695590000 ms.1 from job set of time 1481695590000 ms
2016-12-14 14:06:30.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:30.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 222 (union at DStream.scala:617)
2016-12-14 14:06:30.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 25 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:30.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 50 (take at LogStream.java:127)
2016-12-14 14:06:30.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 49)
2016-12-14 14:06:30.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 49)
2016-12-14 14:06:30.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 49 (UnionRDD[222] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:30.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_49 stored as values in memory (estimated size 4.2 KB, free 205.9 KB)
2016-12-14 14:06:30.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.4 KB, free 208.3 KB)
2016-12-14 14:06:30.017 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_49_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:30.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 49 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:30.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 49 (UnionRDD[222] at union at DStream.scala:617)
2016-12-14 14:06:30.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 49.0 with 1 tasks
2016-12-14 14:06:30.018 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 49.0 (TID 49, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:30.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 49.0 (TID 49)
2016-12-14 14:06:30.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 49.0 (TID 49). 1159 bytes result sent to driver
2016-12-14 14:06:30.021 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 49.0 (TID 49) in 3 ms on localhost (1/1)
2016-12-14 14:06:30.021 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:06:30.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 49 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:06:30.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:30.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:30.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 50)
2016-12-14 14:06:30.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:30.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 50 (MapPartitionsRDD[225] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:30.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_50 stored as values in memory (estimated size 3.7 KB, free 212.0 KB)
2016-12-14 14:06:30.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 214.1 KB)
2016-12-14 14:06:30.025 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_50_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:30.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 50 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:30.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[225] at count at LogStream.java:120)
2016-12-14 14:06:30.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 50.0 with 1 tasks
2016-12-14 14:06:30.026 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 50.0 (TID 50, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:30.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 50.0 (TID 50)
2016-12-14 14:06:30.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:30.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:30.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 50.0 (TID 50). 1241 bytes result sent to driver
2016-12-14 14:06:30.029 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 50.0 (TID 50) in 3 ms on localhost (1/1)
2016-12-14 14:06:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 50 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:06:30.029 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:06:30.029 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 25 finished: take at LogStream.java:127, took 0.015908 s
2016-12-14 14:06:30.038 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695590000 ms.1 from job set of time 1481695590000 ms
2016-12-14 14:06:30.038 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.038 s for time 1481695590000 ms (execution: 0.027 s)
2016-12-14 14:06:30.039 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 208 from persistence list
2016-12-14 14:06:30.039 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 208
2016-12-14 14:06:30.039 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[208] at createStream at LogStream.java:100 of time 1481695590000 ms
2016-12-14 14:06:30.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 216 from persistence list
2016-12-14 14:06:30.039 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 216
2016-12-14 14:06:30.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 215 from persistence list
2016-12-14 14:06:30.039 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 215
2016-12-14 14:06:30.039 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 214 from persistence list
2016-12-14 14:06:30.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 214
2016-12-14 14:06:30.040 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 213 from persistence list
2016-12-14 14:06:30.040 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 213
2016-12-14 14:06:30.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 211 from persistence list
2016-12-14 14:06:30.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 211
2016-12-14 14:06:30.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 210 from persistence list
2016-12-14 14:06:30.040 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 210
2016-12-14 14:06:30.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 209 from persistence list
2016-12-14 14:06:30.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 209
2016-12-14 14:06:30.041 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695588000 ms)
2016-12-14 14:06:30.041 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695588000 ms
2016-12-14 14:06:31.022 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695591000 ms
2016-12-14 14:06:31.023 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695591000 ms.0 from job set of time 1481695591000 ms
2016-12-14 14:06:31.025 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695591000 ms.0 from job set of time 1481695591000 ms
2016-12-14 14:06:31.025 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695591000 ms.1 from job set of time 1481695591000 ms
2016-12-14 14:06:31.030 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:31.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 231 (union at DStream.scala:617)
2016-12-14 14:06:31.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 26 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:31.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 52 (take at LogStream.java:127)
2016-12-14 14:06:31.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 51)
2016-12-14 14:06:31.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 51)
2016-12-14 14:06:31.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 51 (UnionRDD[231] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:31.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_51 stored as values in memory (estimated size 4.2 KB, free 218.3 KB)
2016-12-14 14:06:31.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.4 KB, free 220.8 KB)
2016-12-14 14:06:31.038 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_51_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:31.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 51 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:31.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 51 (UnionRDD[231] at union at DStream.scala:617)
2016-12-14 14:06:31.039 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 51.0 with 1 tasks
2016-12-14 14:06:31.041 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 51.0 (TID 51, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:31.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 51.0 (TID 51)
2016-12-14 14:06:31.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 51.0 (TID 51). 1159 bytes result sent to driver
2016-12-14 14:06:31.045 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 51.0 (TID 51) in 4 ms on localhost (1/1)
2016-12-14 14:06:31.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 51 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:31.045 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 14:06:31.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:31.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:31.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 52)
2016-12-14 14:06:31.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:31.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 52 (MapPartitionsRDD[234] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:31.047 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_52 stored as values in memory (estimated size 3.7 KB, free 224.5 KB)
2016-12-14 14:06:31.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.1 KB, free 226.6 KB)
2016-12-14 14:06:31.049 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_52_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:31.049 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 52 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:31.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[234] at count at LogStream.java:120)
2016-12-14 14:06:31.049 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 52.0 with 1 tasks
2016-12-14 14:06:31.050 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 52.0 (TID 52, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:31.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 52.0 (TID 52)
2016-12-14 14:06:31.051 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:31.052 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:31.053 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 52.0 (TID 52). 1241 bytes result sent to driver
2016-12-14 14:06:31.055 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 52 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:06:31.055 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 52.0 (TID 52) in 4 ms on localhost (1/1)
2016-12-14 14:06:31.055 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 14:06:31.055 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 26 finished: take at LogStream.java:127, took 0.025332 s
2016-12-14 14:06:31.063 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695591000 ms.1 from job set of time 1481695591000 ms
2016-12-14 14:06:31.063 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.063 s for time 1481695591000 ms (execution: 0.040 s)
2016-12-14 14:06:31.063 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 217 from persistence list
2016-12-14 14:06:31.065 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[217] at createStream at LogStream.java:100 of time 1481695591000 ms
2016-12-14 14:06:31.065 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 217
2016-12-14 14:06:31.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 225 from persistence list
2016-12-14 14:06:31.065 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 225
2016-12-14 14:06:31.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 224 from persistence list
2016-12-14 14:06:31.066 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 223 from persistence list
2016-12-14 14:06:31.066 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 224
2016-12-14 14:06:31.066 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 223
2016-12-14 14:06:31.066 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 222 from persistence list
2016-12-14 14:06:31.067 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 222
2016-12-14 14:06:31.067 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 220 from persistence list
2016-12-14 14:06:31.067 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 220
2016-12-14 14:06:31.067 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 219 from persistence list
2016-12-14 14:06:31.067 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 219
2016-12-14 14:06:31.067 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 218 from persistence list
2016-12-14 14:06:31.067 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 218
2016-12-14 14:06:31.068 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695589000 ms)
2016-12-14 14:06:31.068 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695589000 ms
2016-12-14 14:06:32.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695592000 ms
2016-12-14 14:06:32.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695592000 ms.0 from job set of time 1481695592000 ms
2016-12-14 14:06:32.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695592000 ms.0 from job set of time 1481695592000 ms
2016-12-14 14:06:32.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695592000 ms.1 from job set of time 1481695592000 ms
2016-12-14 14:06:32.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 240 (union at DStream.scala:617)
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 27 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 54 (take at LogStream.java:127)
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 53)
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 53)
2016-12-14 14:06:32.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 53 (UnionRDD[240] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:32.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_53 stored as values in memory (estimated size 4.2 KB, free 230.8 KB)
2016-12-14 14:06:32.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.4 KB, free 233.2 KB)
2016-12-14 14:06:32.019 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_53_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:32.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 53 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 53 (UnionRDD[240] at union at DStream.scala:617)
2016-12-14 14:06:32.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 53.0 with 1 tasks
2016-12-14 14:06:32.020 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 53.0 (TID 53, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:32.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 53.0 (TID 53)
2016-12-14 14:06:32.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 53.0 (TID 53). 1159 bytes result sent to driver
2016-12-14 14:06:32.024 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 53.0 (TID 53) in 4 ms on localhost (1/1)
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 53 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:32.024 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 54)
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:32.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 54 (MapPartitionsRDD[243] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:32.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_54 stored as values in memory (estimated size 3.7 KB, free 236.9 KB)
2016-12-14 14:06:32.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.1 KB, free 239.0 KB)
2016-12-14 14:06:32.027 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_54_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:32.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 54 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:32.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[243] at count at LogStream.java:120)
2016-12-14 14:06:32.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 54.0 with 1 tasks
2016-12-14 14:06:32.028 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 54.0 (TID 54, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:32.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 54.0 (TID 54)
2016-12-14 14:06:32.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:32.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:32.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 54.0 (TID 54). 1241 bytes result sent to driver
2016-12-14 14:06:32.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 54 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:32.032 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 54.0 (TID 54) in 4 ms on localhost (1/1)
2016-12-14 14:06:32.032 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2016-12-14 14:06:32.032 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 27 finished: take at LogStream.java:127, took 0.017067 s
2016-12-14 14:06:32.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695592000 ms.1 from job set of time 1481695592000 ms
2016-12-14 14:06:32.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.040 s for time 1481695592000 ms (execution: 0.028 s)
2016-12-14 14:06:32.040 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 226 from persistence list
2016-12-14 14:06:32.040 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 226
2016-12-14 14:06:32.040 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[226] at createStream at LogStream.java:100 of time 1481695592000 ms
2016-12-14 14:06:32.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 234 from persistence list
2016-12-14 14:06:32.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 234
2016-12-14 14:06:32.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 233 from persistence list
2016-12-14 14:06:32.041 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 233
2016-12-14 14:06:32.041 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 232 from persistence list
2016-12-14 14:06:32.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 232
2016-12-14 14:06:32.041 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 231 from persistence list
2016-12-14 14:06:32.041 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 231
2016-12-14 14:06:32.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 229 from persistence list
2016-12-14 14:06:32.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 229
2016-12-14 14:06:32.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 228 from persistence list
2016-12-14 14:06:32.042 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 228
2016-12-14 14:06:32.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 227 from persistence list
2016-12-14 14:06:32.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 227
2016-12-14 14:06:32.042 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695590000 ms)
2016-12-14 14:06:32.042 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695590000 ms
2016-12-14 14:06:33.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695593000 ms
2016-12-14 14:06:33.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695593000 ms.0 from job set of time 1481695593000 ms
2016-12-14 14:06:33.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695593000 ms.0 from job set of time 1481695593000 ms
2016-12-14 14:06:33.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695593000 ms.1 from job set of time 1481695593000 ms
2016-12-14 14:06:33.017 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 249 (union at DStream.scala:617)
2016-12-14 14:06:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 28 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 56 (take at LogStream.java:127)
2016-12-14 14:06:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 55)
2016-12-14 14:06:33.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 55)
2016-12-14 14:06:33.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 55 (UnionRDD[249] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:33.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_55 stored as values in memory (estimated size 4.2 KB, free 243.2 KB)
2016-12-14 14:06:33.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.4 KB, free 245.7 KB)
2016-12-14 14:06:33.022 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_55_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:33.022 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 55 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:33.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 55 (UnionRDD[249] at union at DStream.scala:617)
2016-12-14 14:06:33.022 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 55.0 with 1 tasks
2016-12-14 14:06:33.023 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 55.0 (TID 55, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:33.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 55.0 (TID 55)
2016-12-14 14:06:33.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 55.0 (TID 55). 1159 bytes result sent to driver
2016-12-14 14:06:33.027 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 55.0 (TID 55) in 4 ms on localhost (1/1)
2016-12-14 14:06:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 55 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:33.027 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2016-12-14 14:06:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 56)
2016-12-14 14:06:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:33.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 56 (MapPartitionsRDD[252] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:33.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_56 stored as values in memory (estimated size 3.7 KB, free 249.4 KB)
2016-12-14 14:06:33.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.1 KB, free 251.5 KB)
2016-12-14 14:06:33.030 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_56_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:33.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 56 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:33.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[252] at count at LogStream.java:120)
2016-12-14 14:06:33.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 56.0 with 1 tasks
2016-12-14 14:06:33.032 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 56.0 (TID 56, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:33.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 56.0 (TID 56)
2016-12-14 14:06:33.034 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:33.034 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:33.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 56.0 (TID 56). 1241 bytes result sent to driver
2016-12-14 14:06:33.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 56 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:33.035 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 56.0 (TID 56) in 3 ms on localhost (1/1)
2016-12-14 14:06:33.036 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2016-12-14 14:06:33.036 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 28 finished: take at LogStream.java:127, took 0.018657 s
2016-12-14 14:06:33.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695593000 ms.1 from job set of time 1481695593000 ms
2016-12-14 14:06:33.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.042 s for time 1481695593000 ms (execution: 0.029 s)
2016-12-14 14:06:33.042 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 235 from persistence list
2016-12-14 14:06:33.043 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[235] at createStream at LogStream.java:100 of time 1481695593000 ms
2016-12-14 14:06:33.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 235
2016-12-14 14:06:33.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 243 from persistence list
2016-12-14 14:06:33.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 243
2016-12-14 14:06:33.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 242 from persistence list
2016-12-14 14:06:33.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 242
2016-12-14 14:06:33.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 241 from persistence list
2016-12-14 14:06:33.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 241
2016-12-14 14:06:33.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 240 from persistence list
2016-12-14 14:06:33.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 240
2016-12-14 14:06:33.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 238 from persistence list
2016-12-14 14:06:33.045 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 238
2016-12-14 14:06:33.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 237 from persistence list
2016-12-14 14:06:33.045 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 237
2016-12-14 14:06:33.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 236 from persistence list
2016-12-14 14:06:33.046 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 236
2016-12-14 14:06:33.046 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695591000 ms)
2016-12-14 14:06:33.046 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695591000 ms
2016-12-14 14:06:34.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695594000 ms
2016-12-14 14:06:34.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695594000 ms.0 from job set of time 1481695594000 ms
2016-12-14 14:06:34.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695594000 ms.0 from job set of time 1481695594000 ms
2016-12-14 14:06:34.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695594000 ms.1 from job set of time 1481695594000 ms
2016-12-14 14:06:34.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:34.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 258 (union at DStream.scala:617)
2016-12-14 14:06:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 29 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 58 (take at LogStream.java:127)
2016-12-14 14:06:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 57)
2016-12-14 14:06:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 57)
2016-12-14 14:06:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 57 (UnionRDD[258] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:34.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_57 stored as values in memory (estimated size 4.2 KB, free 255.7 KB)
2016-12-14 14:06:34.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.4 KB, free 258.1 KB)
2016-12-14 14:06:34.018 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_57_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:34.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 57 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:34.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 57 (UnionRDD[258] at union at DStream.scala:617)
2016-12-14 14:06:34.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 57.0 with 1 tasks
2016-12-14 14:06:34.020 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 57.0 (TID 57, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:34.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 57.0 (TID 57)
2016-12-14 14:06:34.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 57.0 (TID 57). 1159 bytes result sent to driver
2016-12-14 14:06:34.023 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 57.0 (TID 57) in 3 ms on localhost (1/1)
2016-12-14 14:06:34.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 57 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:34.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2016-12-14 14:06:34.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:34.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:34.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 58)
2016-12-14 14:06:34.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:34.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 58 (MapPartitionsRDD[261] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:34.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_58 stored as values in memory (estimated size 3.7 KB, free 261.8 KB)
2016-12-14 14:06:34.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.1 KB, free 263.9 KB)
2016-12-14 14:06:34.026 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_58_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:34.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 58 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:34.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[261] at count at LogStream.java:120)
2016-12-14 14:06:34.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 58.0 with 1 tasks
2016-12-14 14:06:34.027 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 58.0 (TID 58, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:34.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 58.0 (TID 58)
2016-12-14 14:06:34.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:34.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:34.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 58.0 (TID 58). 1241 bytes result sent to driver
2016-12-14 14:06:34.029 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 58.0 (TID 58) in 2 ms on localhost (1/1)
2016-12-14 14:06:34.030 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2016-12-14 14:06:34.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 58 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:06:34.030 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 29 finished: take at LogStream.java:127, took 0.014848 s
2016-12-14 14:06:34.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695594000 ms.1 from job set of time 1481695594000 ms
2016-12-14 14:06:34.037 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 244 from persistence list
2016-12-14 14:06:34.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.037 s for time 1481695594000 ms (execution: 0.025 s)
2016-12-14 14:06:34.037 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 244
2016-12-14 14:06:34.037 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[244] at createStream at LogStream.java:100 of time 1481695594000 ms
2016-12-14 14:06:34.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 252 from persistence list
2016-12-14 14:06:34.037 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 252
2016-12-14 14:06:34.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 251 from persistence list
2016-12-14 14:06:34.037 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 251
2016-12-14 14:06:34.038 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 250 from persistence list
2016-12-14 14:06:34.038 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 250
2016-12-14 14:06:34.038 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 249 from persistence list
2016-12-14 14:06:34.038 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 249
2016-12-14 14:06:34.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 247 from persistence list
2016-12-14 14:06:34.038 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 247
2016-12-14 14:06:34.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 246 from persistence list
2016-12-14 14:06:34.038 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 246
2016-12-14 14:06:34.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 245 from persistence list
2016-12-14 14:06:34.038 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 245
2016-12-14 14:06:34.039 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695592000 ms)
2016-12-14 14:06:34.039 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695592000 ms
2016-12-14 14:06:35.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695595000 ms
2016-12-14 14:06:35.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695595000 ms.0 from job set of time 1481695595000 ms
2016-12-14 14:06:35.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695595000 ms.0 from job set of time 1481695595000 ms
2016-12-14 14:06:35.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695595000 ms.1 from job set of time 1481695595000 ms
2016-12-14 14:06:35.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:35.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 267 (union at DStream.scala:617)
2016-12-14 14:06:35.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 30 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:35.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 60 (take at LogStream.java:127)
2016-12-14 14:06:35.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 59)
2016-12-14 14:06:35.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 59)
2016-12-14 14:06:35.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 59 (UnionRDD[267] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:35.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_59 stored as values in memory (estimated size 4.2 KB, free 268.1 KB)
2016-12-14 14:06:35.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.4 KB, free 270.6 KB)
2016-12-14 14:06:35.016 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_59_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:35.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 59 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:35.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 59 (UnionRDD[267] at union at DStream.scala:617)
2016-12-14 14:06:35.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 59.0 with 1 tasks
2016-12-14 14:06:35.018 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 59.0 (TID 59, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:35.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 59.0 (TID 59)
2016-12-14 14:06:35.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 59.0 (TID 59). 1159 bytes result sent to driver
2016-12-14 14:06:35.021 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 59.0 (TID 59) in 4 ms on localhost (1/1)
2016-12-14 14:06:35.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 59 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:35.021 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2016-12-14 14:06:35.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:35.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:35.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 60)
2016-12-14 14:06:35.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:35.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 60 (MapPartitionsRDD[270] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:35.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_60 stored as values in memory (estimated size 3.7 KB, free 274.3 KB)
2016-12-14 14:06:35.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.1 KB, free 276.4 KB)
2016-12-14 14:06:35.024 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_60_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:35.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 60 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:35.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[270] at count at LogStream.java:120)
2016-12-14 14:06:35.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 60.0 with 1 tasks
2016-12-14 14:06:35.026 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 60.0 (TID 60, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:35.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 60.0 (TID 60)
2016-12-14 14:06:35.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:35.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:35.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 60.0 (TID 60). 1241 bytes result sent to driver
2016-12-14 14:06:35.031 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 60.0 (TID 60) in 4 ms on localhost (1/1)
2016-12-14 14:06:35.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 60 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:06:35.031 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2016-12-14 14:06:35.031 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 30 finished: take at LogStream.java:127, took 0.018467 s
2016-12-14 14:06:35.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695595000 ms.1 from job set of time 1481695595000 ms
2016-12-14 14:06:35.041 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 253 from persistence list
2016-12-14 14:06:35.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.040 s for time 1481695595000 ms (execution: 0.031 s)
2016-12-14 14:06:35.042 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 253
2016-12-14 14:06:35.042 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[253] at createStream at LogStream.java:100 of time 1481695595000 ms
2016-12-14 14:06:35.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 261 from persistence list
2016-12-14 14:06:35.045 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 261
2016-12-14 14:06:35.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 260 from persistence list
2016-12-14 14:06:35.045 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 259 from persistence list
2016-12-14 14:06:35.051 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 260
2016-12-14 14:06:35.052 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 259
2016-12-14 14:06:35.052 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 258 from persistence list
2016-12-14 14:06:35.052 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 258
2016-12-14 14:06:35.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 256 from persistence list
2016-12-14 14:06:35.053 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 256
2016-12-14 14:06:35.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 255 from persistence list
2016-12-14 14:06:35.053 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 255
2016-12-14 14:06:35.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 254 from persistence list
2016-12-14 14:06:35.053 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 254
2016-12-14 14:06:35.053 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695593000 ms)
2016-12-14 14:06:35.053 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695593000 ms
2016-12-14 14:06:36.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695596000 ms
2016-12-14 14:06:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695596000 ms.0 from job set of time 1481695596000 ms
2016-12-14 14:06:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695596000 ms.0 from job set of time 1481695596000 ms
2016-12-14 14:06:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695596000 ms.1 from job set of time 1481695596000 ms
2016-12-14 14:06:36.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:36.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 276 (union at DStream.scala:617)
2016-12-14 14:06:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 31 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 62 (take at LogStream.java:127)
2016-12-14 14:06:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 61)
2016-12-14 14:06:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 61)
2016-12-14 14:06:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 61 (UnionRDD[276] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:36.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_61 stored as values in memory (estimated size 4.2 KB, free 280.6 KB)
2016-12-14 14:06:36.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.4 KB, free 283.0 KB)
2016-12-14 14:06:36.016 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_61_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:36.016 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 61 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:36.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 61 (UnionRDD[276] at union at DStream.scala:617)
2016-12-14 14:06:36.016 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 61.0 with 1 tasks
2016-12-14 14:06:36.017 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 61.0 (TID 61, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:36.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 61.0 (TID 61)
2016-12-14 14:06:36.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 61.0 (TID 61). 1159 bytes result sent to driver
2016-12-14 14:06:36.020 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 61.0 (TID 61) in 3 ms on localhost (1/1)
2016-12-14 14:06:36.021 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 61 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 62)
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 62 (MapPartitionsRDD[279] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:36.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_62 stored as values in memory (estimated size 3.7 KB, free 286.7 KB)
2016-12-14 14:06:36.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.1 KB, free 288.8 KB)
2016-12-14 14:06:36.023 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_62_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:36.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 62 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:36.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[279] at count at LogStream.java:120)
2016-12-14 14:06:36.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 62.0 with 1 tasks
2016-12-14 14:06:36.024 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 62.0 (TID 62, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:36.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 62.0 (TID 62)
2016-12-14 14:06:36.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:36.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:36.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 62.0 (TID 62). 1241 bytes result sent to driver
2016-12-14 14:06:36.027 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 62.0 (TID 62) in 3 ms on localhost (1/1)
2016-12-14 14:06:36.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 62 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:06:36.027 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2016-12-14 14:06:36.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 31 finished: take at LogStream.java:127, took 0.014540 s
2016-12-14 14:06:36.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695596000 ms.1 from job set of time 1481695596000 ms
2016-12-14 14:06:36.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.035 s for time 1481695596000 ms (execution: 0.025 s)
2016-12-14 14:06:36.035 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 262 from persistence list
2016-12-14 14:06:36.035 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 262
2016-12-14 14:06:36.035 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[262] at createStream at LogStream.java:100 of time 1481695596000 ms
2016-12-14 14:06:36.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 270 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 270
2016-12-14 14:06:36.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 269 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 269
2016-12-14 14:06:36.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 268 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 268
2016-12-14 14:06:36.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 267 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 267
2016-12-14 14:06:36.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 265 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 265
2016-12-14 14:06:36.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 264 from persistence list
2016-12-14 14:06:36.036 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 264
2016-12-14 14:06:36.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 263 from persistence list
2016-12-14 14:06:36.037 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 263
2016-12-14 14:06:36.037 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695594000 ms)
2016-12-14 14:06:36.037 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695594000 ms
2016-12-14 14:06:37.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695597000 ms
2016-12-14 14:06:37.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695597000 ms.0 from job set of time 1481695597000 ms
2016-12-14 14:06:37.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695597000 ms.0 from job set of time 1481695597000 ms
2016-12-14 14:06:37.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695597000 ms.1 from job set of time 1481695597000 ms
2016-12-14 14:06:37.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:37.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 285 (union at DStream.scala:617)
2016-12-14 14:06:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 32 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 64 (take at LogStream.java:127)
2016-12-14 14:06:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 63)
2016-12-14 14:06:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 63)
2016-12-14 14:06:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 63 (UnionRDD[285] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:37.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_63 stored as values in memory (estimated size 4.2 KB, free 293.0 KB)
2016-12-14 14:06:37.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.4 KB, free 295.5 KB)
2016-12-14 14:06:37.019 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_63_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:37.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 63 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:37.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 63 (UnionRDD[285] at union at DStream.scala:617)
2016-12-14 14:06:37.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 63.0 with 1 tasks
2016-12-14 14:06:37.020 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 63.0 (TID 63, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:37.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 63.0 (TID 63)
2016-12-14 14:06:37.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 63.0 (TID 63). 1159 bytes result sent to driver
2016-12-14 14:06:37.024 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 63.0 (TID 63) in 4 ms on localhost (1/1)
2016-12-14 14:06:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 63 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:37.024 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2016-12-14 14:06:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 64)
2016-12-14 14:06:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 64 (MapPartitionsRDD[288] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:37.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_64 stored as values in memory (estimated size 3.7 KB, free 299.2 KB)
2016-12-14 14:06:37.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.1 KB, free 301.3 KB)
2016-12-14 14:06:37.028 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_64_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:37.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 64 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:37.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[288] at count at LogStream.java:120)
2016-12-14 14:06:37.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 64.0 with 1 tasks
2016-12-14 14:06:37.029 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 64.0 (TID 64, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:37.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 64.0 (TID 64)
2016-12-14 14:06:37.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:37.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:37.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 64.0 (TID 64). 1241 bytes result sent to driver
2016-12-14 14:06:37.032 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 64.0 (TID 64) in 3 ms on localhost (1/1)
2016-12-14 14:06:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 64 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:37.032 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2016-12-14 14:06:37.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 32 finished: take at LogStream.java:127, took 0.019108 s
2016-12-14 14:06:37.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695597000 ms.1 from job set of time 1481695597000 ms
2016-12-14 14:06:37.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.041 s for time 1481695597000 ms (execution: 0.029 s)
2016-12-14 14:06:37.041 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 271 from persistence list
2016-12-14 14:06:37.041 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 271
2016-12-14 14:06:37.041 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[271] at createStream at LogStream.java:100 of time 1481695597000 ms
2016-12-14 14:06:37.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 279 from persistence list
2016-12-14 14:06:37.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 279
2016-12-14 14:06:37.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 278 from persistence list
2016-12-14 14:06:37.042 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 278
2016-12-14 14:06:37.042 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 277 from persistence list
2016-12-14 14:06:37.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 277
2016-12-14 14:06:37.042 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 276 from persistence list
2016-12-14 14:06:37.042 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 276
2016-12-14 14:06:37.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 274 from persistence list
2016-12-14 14:06:37.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 274
2016-12-14 14:06:37.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 273 from persistence list
2016-12-14 14:06:37.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 273
2016-12-14 14:06:37.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 272 from persistence list
2016-12-14 14:06:37.043 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 272
2016-12-14 14:06:37.043 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695595000 ms)
2016-12-14 14:06:37.043 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695595000 ms
2016-12-14 14:06:38.029 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695598000 ms
2016-12-14 14:06:38.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695598000 ms.0 from job set of time 1481695598000 ms
2016-12-14 14:06:38.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695598000 ms.0 from job set of time 1481695598000 ms
2016-12-14 14:06:38.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695598000 ms.1 from job set of time 1481695598000 ms
2016-12-14 14:06:38.038 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 294 (union at DStream.scala:617)
2016-12-14 14:06:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 33 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 66 (take at LogStream.java:127)
2016-12-14 14:06:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 65)
2016-12-14 14:06:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 65)
2016-12-14 14:06:38.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 65 (UnionRDD[294] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:38.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_65 stored as values in memory (estimated size 4.2 KB, free 305.5 KB)
2016-12-14 14:06:38.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.4 KB, free 307.9 KB)
2016-12-14 14:06:38.044 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_65_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:38.045 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 65 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:38.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 65 (UnionRDD[294] at union at DStream.scala:617)
2016-12-14 14:06:38.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 65.0 with 1 tasks
2016-12-14 14:06:38.046 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 65.0 (TID 65, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:38.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 65.0 (TID 65)
2016-12-14 14:06:38.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 65.0 (TID 65). 1159 bytes result sent to driver
2016-12-14 14:06:38.051 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 65.0 (TID 65) in 5 ms on localhost (1/1)
2016-12-14 14:06:38.051 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2016-12-14 14:06:38.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 65 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:06:38.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:38.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:38.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 66)
2016-12-14 14:06:38.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:38.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 66 (MapPartitionsRDD[297] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:38.054 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_66 stored as values in memory (estimated size 3.7 KB, free 311.6 KB)
2016-12-14 14:06:38.055 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.1 KB, free 313.7 KB)
2016-12-14 14:06:38.056 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_66_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:38.056 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 66 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:38.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[297] at count at LogStream.java:120)
2016-12-14 14:06:38.056 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 66.0 with 1 tasks
2016-12-14 14:06:38.057 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 66.0 (TID 66, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:38.057 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 66.0 (TID 66)
2016-12-14 14:06:38.058 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:38.059 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:38.060 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 66.0 (TID 66). 1241 bytes result sent to driver
2016-12-14 14:06:38.061 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 66.0 (TID 66) in 4 ms on localhost (1/1)
2016-12-14 14:06:38.061 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 66 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:38.061 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2016-12-14 14:06:38.061 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 33 finished: take at LogStream.java:127, took 0.022909 s
2016-12-14 14:06:38.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695598000 ms.1 from job set of time 1481695598000 ms
2016-12-14 14:06:38.070 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 280 from persistence list
2016-12-14 14:06:38.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.070 s for time 1481695598000 ms (execution: 0.035 s)
2016-12-14 14:06:38.071 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 280
2016-12-14 14:06:38.071 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[280] at createStream at LogStream.java:100 of time 1481695598000 ms
2016-12-14 14:06:38.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 288 from persistence list
2016-12-14 14:06:38.071 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 288
2016-12-14 14:06:38.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 287 from persistence list
2016-12-14 14:06:38.078 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 286 from persistence list
2016-12-14 14:06:38.078 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 287
2016-12-14 14:06:38.080 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 285 from persistence list
2016-12-14 14:06:38.080 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 286
2016-12-14 14:06:38.081 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 285
2016-12-14 14:06:38.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 283 from persistence list
2016-12-14 14:06:38.081 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 283
2016-12-14 14:06:38.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 282 from persistence list
2016-12-14 14:06:38.082 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 282
2016-12-14 14:06:38.082 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 281 from persistence list
2016-12-14 14:06:38.082 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 281
2016-12-14 14:06:38.082 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695596000 ms)
2016-12-14 14:06:38.082 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695596000 ms
2016-12-14 14:06:39.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695599000 ms.0 from job set of time 1481695599000 ms
2016-12-14 14:06:39.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695599000 ms.0 from job set of time 1481695599000 ms
2016-12-14 14:06:39.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695599000 ms.1 from job set of time 1481695599000 ms
2016-12-14 14:06:39.018 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695599000 ms
2016-12-14 14:06:39.020 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:39.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 303 (union at DStream.scala:617)
2016-12-14 14:06:39.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 34 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:39.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 68 (take at LogStream.java:127)
2016-12-14 14:06:39.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 67)
2016-12-14 14:06:39.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 67)
2016-12-14 14:06:39.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 67 (UnionRDD[303] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:39.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_67 stored as values in memory (estimated size 4.2 KB, free 318.0 KB)
2016-12-14 14:06:39.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_67_piece0 stored as bytes in memory (estimated size 2.4 KB, free 320.4 KB)
2016-12-14 14:06:39.025 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_67_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:39.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 67 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 67 (UnionRDD[303] at union at DStream.scala:617)
2016-12-14 14:06:39.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 67.0 with 1 tasks
2016-12-14 14:06:39.027 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 67.0 (TID 67, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:39.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 67.0 (TID 67)
2016-12-14 14:06:39.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 67.0 (TID 67). 1159 bytes result sent to driver
2016-12-14 14:06:39.030 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 67.0 (TID 67) in 4 ms on localhost (1/1)
2016-12-14 14:06:39.030 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2016-12-14 14:06:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 67 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 68)
2016-12-14 14:06:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:39.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 68 (MapPartitionsRDD[306] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:39.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_68 stored as values in memory (estimated size 3.7 KB, free 324.1 KB)
2016-12-14 14:06:39.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.1 KB, free 326.2 KB)
2016-12-14 14:06:39.033 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_68_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:39.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 68 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:39.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[306] at count at LogStream.java:120)
2016-12-14 14:06:39.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 68.0 with 1 tasks
2016-12-14 14:06:39.035 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 68.0 (TID 68, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:39.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 68.0 (TID 68)
2016-12-14 14:06:39.036 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:39.036 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:39.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 68.0 (TID 68). 1241 bytes result sent to driver
2016-12-14 14:06:39.038 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 68.0 (TID 68) in 3 ms on localhost (1/1)
2016-12-14 14:06:39.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 68 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:39.038 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2016-12-14 14:06:39.038 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 34 finished: take at LogStream.java:127, took 0.017670 s
2016-12-14 14:06:39.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695599000 ms.1 from job set of time 1481695599000 ms
2016-12-14 14:06:39.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.042 s for time 1481695599000 ms (execution: 0.026 s)
2016-12-14 14:06:39.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 289 from persistence list
2016-12-14 14:06:39.043 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 289
2016-12-14 14:06:39.043 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[289] at createStream at LogStream.java:100 of time 1481695599000 ms
2016-12-14 14:06:39.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 297 from persistence list
2016-12-14 14:06:39.043 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 297
2016-12-14 14:06:39.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 296 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 296
2016-12-14 14:06:39.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 295 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 295
2016-12-14 14:06:39.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 294 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 294
2016-12-14 14:06:39.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 292 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 292
2016-12-14 14:06:39.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 291 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 291
2016-12-14 14:06:39.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 290 from persistence list
2016-12-14 14:06:39.044 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 290
2016-12-14 14:06:39.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695597000 ms)
2016-12-14 14:06:39.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695597000 ms
2016-12-14 14:06:40.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695600000 ms
2016-12-14 14:06:40.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695600000 ms.0 from job set of time 1481695600000 ms
2016-12-14 14:06:40.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695600000 ms.0 from job set of time 1481695600000 ms
2016-12-14 14:06:40.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695600000 ms.1 from job set of time 1481695600000 ms
2016-12-14 14:06:40.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 312 (union at DStream.scala:617)
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 35 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 70 (take at LogStream.java:127)
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 69)
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 69)
2016-12-14 14:06:40.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 69 (UnionRDD[312] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:40.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_69 stored as values in memory (estimated size 4.2 KB, free 330.4 KB)
2016-12-14 14:06:40.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.4 KB, free 332.8 KB)
2016-12-14 14:06:40.019 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_69_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:40.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 69 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:40.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 69 (UnionRDD[312] at union at DStream.scala:617)
2016-12-14 14:06:40.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 69.0 with 1 tasks
2016-12-14 14:06:40.020 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 69.0 (TID 69, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:40.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 69.0 (TID 69)
2016-12-14 14:06:40.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 69.0 (TID 69). 1159 bytes result sent to driver
2016-12-14 14:06:40.023 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 69.0 (TID 69) in 3 ms on localhost (1/1)
2016-12-14 14:06:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 69 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:06:40.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2016-12-14 14:06:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 70)
2016-12-14 14:06:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:40.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 70 (MapPartitionsRDD[315] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:40.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_70 stored as values in memory (estimated size 3.7 KB, free 336.5 KB)
2016-12-14 14:06:40.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.1 KB, free 338.6 KB)
2016-12-14 14:06:40.026 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_70_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:40.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 70 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:40.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[315] at count at LogStream.java:120)
2016-12-14 14:06:40.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 70.0 with 1 tasks
2016-12-14 14:06:40.027 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 70.0 (TID 70, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:40.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 70.0 (TID 70)
2016-12-14 14:06:40.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:40.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:40.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 70.0 (TID 70). 1241 bytes result sent to driver
2016-12-14 14:06:40.029 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 70.0 (TID 70) in 2 ms on localhost (1/1)
2016-12-14 14:06:40.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 70 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:06:40.029 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2016-12-14 14:06:40.029 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 35 finished: take at LogStream.java:127, took 0.014023 s
2016-12-14 14:06:40.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695600000 ms.1 from job set of time 1481695600000 ms
2016-12-14 14:06:40.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.035 s for time 1481695600000 ms (execution: 0.024 s)
2016-12-14 14:06:40.035 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 298 from persistence list
2016-12-14 14:06:40.035 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 298
2016-12-14 14:06:40.035 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[298] at createStream at LogStream.java:100 of time 1481695600000 ms
2016-12-14 14:06:40.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 306 from persistence list
2016-12-14 14:06:40.036 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 306
2016-12-14 14:06:40.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 305 from persistence list
2016-12-14 14:06:40.036 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 305
2016-12-14 14:06:40.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 304 from persistence list
2016-12-14 14:06:40.036 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 304
2016-12-14 14:06:40.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 303 from persistence list
2016-12-14 14:06:40.037 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 303
2016-12-14 14:06:40.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 301 from persistence list
2016-12-14 14:06:40.037 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 301
2016-12-14 14:06:40.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 300 from persistence list
2016-12-14 14:06:40.037 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 300
2016-12-14 14:06:40.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 299 from persistence list
2016-12-14 14:06:40.037 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 299
2016-12-14 14:06:40.037 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695598000 ms)
2016-12-14 14:06:40.037 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695598000 ms
2016-12-14 14:06:41.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695601000 ms
2016-12-14 14:06:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695601000 ms.0 from job set of time 1481695601000 ms
2016-12-14 14:06:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695601000 ms.0 from job set of time 1481695601000 ms
2016-12-14 14:06:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695601000 ms.1 from job set of time 1481695601000 ms
2016-12-14 14:06:41.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:41.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 321 (union at DStream.scala:617)
2016-12-14 14:06:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 36 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 72 (take at LogStream.java:127)
2016-12-14 14:06:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 71)
2016-12-14 14:06:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 71)
2016-12-14 14:06:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 71 (UnionRDD[321] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:41.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_71 stored as values in memory (estimated size 4.2 KB, free 342.9 KB)
2016-12-14 14:06:41.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.4 KB, free 345.3 KB)
2016-12-14 14:06:41.017 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_71_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:41.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 71 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 71 (UnionRDD[321] at union at DStream.scala:617)
2016-12-14 14:06:41.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 71.0 with 1 tasks
2016-12-14 14:06:41.018 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 71.0 (TID 71, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:41.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 71.0 (TID 71)
2016-12-14 14:06:41.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 71.0 (TID 71). 1159 bytes result sent to driver
2016-12-14 14:06:41.022 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 71.0 (TID 71) in 4 ms on localhost (1/1)
2016-12-14 14:06:41.022 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 71 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 72)
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:41.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 72 (MapPartitionsRDD[324] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:41.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_72 stored as values in memory (estimated size 3.7 KB, free 349.0 KB)
2016-12-14 14:06:41.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.1 KB, free 351.1 KB)
2016-12-14 14:06:41.028 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_72_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:41.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 72 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:41.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[324] at count at LogStream.java:120)
2016-12-14 14:06:41.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 72.0 with 1 tasks
2016-12-14 14:06:41.029 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 72.0 (TID 72, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:41.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 72.0 (TID 72)
2016-12-14 14:06:41.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:41.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:41.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 72.0 (TID 72). 1241 bytes result sent to driver
2016-12-14 14:06:41.033 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 72.0 (TID 72) in 4 ms on localhost (1/1)
2016-12-14 14:06:41.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 72 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:41.033 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2016-12-14 14:06:41.034 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 36 finished: take at LogStream.java:127, took 0.020956 s
2016-12-14 14:06:41.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695601000 ms.1 from job set of time 1481695601000 ms
2016-12-14 14:06:41.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.040 s for time 1481695601000 ms (execution: 0.030 s)
2016-12-14 14:06:41.040 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 307 from persistence list
2016-12-14 14:06:41.040 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 307
2016-12-14 14:06:41.040 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[307] at createStream at LogStream.java:100 of time 1481695601000 ms
2016-12-14 14:06:41.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 315 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 315
2016-12-14 14:06:41.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 314 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 314
2016-12-14 14:06:41.041 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 313 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 313
2016-12-14 14:06:41.041 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 312 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 312
2016-12-14 14:06:41.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 310 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 310
2016-12-14 14:06:41.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 309 from persistence list
2016-12-14 14:06:41.041 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 309
2016-12-14 14:06:41.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 308 from persistence list
2016-12-14 14:06:41.042 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 308
2016-12-14 14:06:41.042 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695599000 ms)
2016-12-14 14:06:41.042 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695599000 ms
2016-12-14 14:06:42.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695602000 ms
2016-12-14 14:06:42.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695602000 ms.0 from job set of time 1481695602000 ms
2016-12-14 14:06:42.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695602000 ms.0 from job set of time 1481695602000 ms
2016-12-14 14:06:42.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695602000 ms.1 from job set of time 1481695602000 ms
2016-12-14 14:06:42.017 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:42.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 330 (union at DStream.scala:617)
2016-12-14 14:06:42.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 37 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:42.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 74 (take at LogStream.java:127)
2016-12-14 14:06:42.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 73)
2016-12-14 14:06:42.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 73)
2016-12-14 14:06:42.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 73 (UnionRDD[330] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:42.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_73 stored as values in memory (estimated size 4.2 KB, free 355.3 KB)
2016-12-14 14:06:42.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_73_piece0 stored as bytes in memory (estimated size 2.4 KB, free 357.7 KB)
2016-12-14 14:06:42.022 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_73_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:42.022 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 73 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:42.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 73 (UnionRDD[330] at union at DStream.scala:617)
2016-12-14 14:06:42.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 73.0 with 1 tasks
2016-12-14 14:06:42.023 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 73.0 (TID 73, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:42.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 73.0 (TID 73)
2016-12-14 14:06:42.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 73.0 (TID 73). 1159 bytes result sent to driver
2016-12-14 14:06:42.027 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 73.0 (TID 73) in 4 ms on localhost (1/1)
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 73 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:42.028 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 74)
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 74 (MapPartitionsRDD[333] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:42.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_74 stored as values in memory (estimated size 3.7 KB, free 361.4 KB)
2016-12-14 14:06:42.031 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.1 KB, free 363.6 KB)
2016-12-14 14:06:42.031 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_74_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:42.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 74 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:42.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[333] at count at LogStream.java:120)
2016-12-14 14:06:42.032 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 74.0 with 1 tasks
2016-12-14 14:06:42.033 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 74.0 (TID 74, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:42.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 74.0 (TID 74)
2016-12-14 14:06:42.034 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:42.035 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:42.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 74.0 (TID 74). 1241 bytes result sent to driver
2016-12-14 14:06:42.036 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 74.0 (TID 74) in 3 ms on localhost (1/1)
2016-12-14 14:06:42.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 74 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:42.036 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2016-12-14 14:06:42.037 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 37 finished: take at LogStream.java:127, took 0.019442 s
2016-12-14 14:06:42.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695602000 ms.1 from job set of time 1481695602000 ms
2016-12-14 14:06:42.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.042 s for time 1481695602000 ms (execution: 0.029 s)
2016-12-14 14:06:42.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 316 from persistence list
2016-12-14 14:06:42.044 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[316] at createStream at LogStream.java:100 of time 1481695602000 ms
2016-12-14 14:06:42.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 324 from persistence list
2016-12-14 14:06:42.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 316
2016-12-14 14:06:42.044 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 324
2016-12-14 14:06:42.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 323 from persistence list
2016-12-14 14:06:42.045 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 323
2016-12-14 14:06:42.045 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 322 from persistence list
2016-12-14 14:06:42.045 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 322
2016-12-14 14:06:42.045 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 321 from persistence list
2016-12-14 14:06:42.045 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 321
2016-12-14 14:06:42.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 319 from persistence list
2016-12-14 14:06:42.045 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 319
2016-12-14 14:06:42.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 318 from persistence list
2016-12-14 14:06:42.046 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 318
2016-12-14 14:06:42.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 317 from persistence list
2016-12-14 14:06:42.046 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 317
2016-12-14 14:06:42.046 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695600000 ms)
2016-12-14 14:06:42.046 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695600000 ms
2016-12-14 14:06:43.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695603000 ms
2016-12-14 14:06:43.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695603000 ms.0 from job set of time 1481695603000 ms
2016-12-14 14:06:43.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695603000 ms.0 from job set of time 1481695603000 ms
2016-12-14 14:06:43.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695603000 ms.1 from job set of time 1481695603000 ms
2016-12-14 14:06:43.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 339 (union at DStream.scala:617)
2016-12-14 14:06:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 38 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 76 (take at LogStream.java:127)
2016-12-14 14:06:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 75)
2016-12-14 14:06:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 75)
2016-12-14 14:06:43.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 75 (UnionRDD[339] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:43.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_75 stored as values in memory (estimated size 4.2 KB, free 367.8 KB)
2016-12-14 14:06:43.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.4 KB, free 370.2 KB)
2016-12-14 14:06:43.024 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_75_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 75 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:43.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 75 (UnionRDD[339] at union at DStream.scala:617)
2016-12-14 14:06:43.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 75.0 with 1 tasks
2016-12-14 14:06:43.026 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 75.0 (TID 75, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:43.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 75.0 (TID 75)
2016-12-14 14:06:43.026 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 61
2016-12-14 14:06:43.026 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_45_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.028 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 46
2016-12-14 14:06:43.028 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 22
2016-12-14 14:06:43.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 75.0 (TID 75). 1159 bytes result sent to driver
2016-12-14 14:06:43.031 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_44_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.031 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 75.0 (TID 75) in 6 ms on localhost (1/1)
2016-12-14 14:06:43.031 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 75 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 76)
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:43.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 76 (MapPartitionsRDD[342] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:43.033 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 45
2016-12-14 14:06:43.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_76 stored as values in memory (estimated size 3.7 KB, free 361.4 KB)
2016-12-14 14:06:43.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.1 KB, free 363.6 KB)
2016-12-14 14:06:43.035 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_76_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 76 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:43.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[342] at count at LogStream.java:120)
2016-12-14 14:06:43.036 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_43_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 76.0 with 1 tasks
2016-12-14 14:06:43.036 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 44
2016-12-14 14:06:43.037 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 21
2016-12-14 14:06:43.037 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 76.0 (TID 76, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:43.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 76.0 (TID 76)
2016-12-14 14:06:43.038 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_42_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.038 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 43
2016-12-14 14:06:43.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:43.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:06:43.039 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_41_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.039 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 42
2016-12-14 14:06:43.040 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 20
2016-12-14 14:06:43.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 76.0 (TID 76). 1241 bytes result sent to driver
2016-12-14 14:06:43.041 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 76.0 (TID 76) in 4 ms on localhost (1/1)
2016-12-14 14:06:43.041 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_40_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.041 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2016-12-14 14:06:43.041 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 41
2016-12-14 14:06:43.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 76 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:43.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 38 finished: take at LogStream.java:127, took 0.028016 s
2016-12-14 14:06:43.042 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_39_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.042 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 40
2016-12-14 14:06:43.042 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 19
2016-12-14 14:06:43.043 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_38_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.043 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 39
2016-12-14 14:06:43.044 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_37_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.044 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 38
2016-12-14 14:06:43.044 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 18
2016-12-14 14:06:43.045 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_36_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.045 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 37
2016-12-14 14:06:43.046 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_35_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.046 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 36
2016-12-14 14:06:43.046 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 17
2016-12-14 14:06:43.047 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_34_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695603000 ms.1 from job set of time 1481695603000 ms
2016-12-14 14:06:43.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695603000 ms (execution: 0.037 s)
2016-12-14 14:06:43.047 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 325 from persistence list
2016-12-14 14:06:43.047 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 35
2016-12-14 14:06:43.047 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 325
2016-12-14 14:06:43.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[325] at createStream at LogStream.java:100 of time 1481695603000 ms
2016-12-14 14:06:43.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 333 from persistence list
2016-12-14 14:06:43.048 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 333
2016-12-14 14:06:43.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 332 from persistence list
2016-12-14 14:06:43.048 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_33_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.048 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 331 from persistence list
2016-12-14 14:06:43.048 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 332
2016-12-14 14:06:43.048 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 34
2016-12-14 14:06:43.048 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 331
2016-12-14 14:06:43.048 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 330 from persistence list
2016-12-14 14:06:43.049 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 16
2016-12-14 14:06:43.049 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 330
2016-12-14 14:06:43.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 328 from persistence list
2016-12-14 14:06:43.049 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 328
2016-12-14 14:06:43.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 327 from persistence list
2016-12-14 14:06:43.049 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_59_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.049 [block-manager-slave-async-thread-pool-8] INFO  o.apache.spark.storage.BlockManager - Removing RDD 327
2016-12-14 14:06:43.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 326 from persistence list
2016-12-14 14:06:43.049 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 60
2016-12-14 14:06:43.049 [block-manager-slave-async-thread-pool-9] INFO  o.apache.spark.storage.BlockManager - Removing RDD 326
2016-12-14 14:06:43.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695601000 ms)
2016-12-14 14:06:43.050 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 29
2016-12-14 14:06:43.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695601000 ms
2016-12-14 14:06:43.050 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_58_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.050 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 59
2016-12-14 14:06:43.051 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_57_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.051 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 58
2016-12-14 14:06:43.052 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 28
2016-12-14 14:06:43.052 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_56_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.052 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 57
2016-12-14 14:06:43.053 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_55_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.053 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 56
2016-12-14 14:06:43.054 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 27
2016-12-14 14:06:43.054 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_54_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.055 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 55
2016-12-14 14:06:43.055 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_53_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.056 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 54
2016-12-14 14:06:43.056 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 26
2016-12-14 14:06:43.056 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_52_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.057 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 53
2016-12-14 14:06:43.057 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_51_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.058 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 52
2016-12-14 14:06:43.058 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 25
2016-12-14 14:06:43.059 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_50_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.059 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 51
2016-12-14 14:06:43.059 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_49_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.060 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 50
2016-12-14 14:06:43.060 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 24
2016-12-14 14:06:43.061 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_48_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.061 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 49
2016-12-14 14:06:43.062 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_47_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.062 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 48
2016-12-14 14:06:43.062 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 23
2016-12-14 14:06:43.062 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_46_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.063 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 47
2016-12-14 14:06:43.063 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_74_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.063 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 75
2016-12-14 14:06:43.064 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_73_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.064 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 74
2016-12-14 14:06:43.065 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_72_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.065 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 73
2016-12-14 14:06:43.066 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_71_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.066 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 72
2016-12-14 14:06:43.066 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 35
2016-12-14 14:06:43.067 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_70_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.067 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 71
2016-12-14 14:06:43.068 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_69_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.068 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 70
2016-12-14 14:06:43.068 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 34
2016-12-14 14:06:43.069 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_68_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 69
2016-12-14 14:06:43.070 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_67_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.071 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 68
2016-12-14 14:06:43.071 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 33
2016-12-14 14:06:43.072 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_66_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.072 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 67
2016-12-14 14:06:43.073 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_65_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 66
2016-12-14 14:06:43.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 32
2016-12-14 14:06:43.074 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_64_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.074 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 65
2016-12-14 14:06:43.075 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_63_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.075 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 64
2016-12-14 14:06:43.075 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 31
2016-12-14 14:06:43.076 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_62_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:43.076 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 63
2016-12-14 14:06:43.077 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_61_piece0 on localhost:60390 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:43.077 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 62
2016-12-14 14:06:43.077 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 30
2016-12-14 14:06:43.078 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_60_piece0 on localhost:60390 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:44.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695604000 ms
2016-12-14 14:06:44.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695604000 ms.0 from job set of time 1481695604000 ms
2016-12-14 14:06:44.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695604000 ms.0 from job set of time 1481695604000 ms
2016-12-14 14:06:44.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695604000 ms.1 from job set of time 1481695604000 ms
2016-12-14 14:06:44.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 348 (union at DStream.scala:617)
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 39 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 78 (take at LogStream.java:127)
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 77)
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 77)
2016-12-14 14:06:44.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 77 (UnionRDD[348] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:44.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_77 stored as values in memory (estimated size 4.2 KB, free 118.8 KB)
2016-12-14 14:06:44.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.4 KB, free 121.2 KB)
2016-12-14 14:06:44.021 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_77_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:44.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 77 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:44.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 77 (UnionRDD[348] at union at DStream.scala:617)
2016-12-14 14:06:44.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 77.0 with 1 tasks
2016-12-14 14:06:44.025 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 77.0 (TID 77, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:44.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 77.0 (TID 77)
2016-12-14 14:06:44.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 77.0 (TID 77). 1159 bytes result sent to driver
2016-12-14 14:06:44.039 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 77.0 (TID 77) in 14 ms on localhost (1/1)
2016-12-14 14:06:44.039 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2016-12-14 14:06:44.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 77 (union at DStream.scala:617) finished in 0.017 s
2016-12-14 14:06:44.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:44.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:44.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 78)
2016-12-14 14:06:44.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:44.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 78 (MapPartitionsRDD[351] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:44.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_78 stored as values in memory (estimated size 3.7 KB, free 124.9 KB)
2016-12-14 14:06:44.046 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.1 KB, free 127.0 KB)
2016-12-14 14:06:44.049 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_78_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:44.049 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 78 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:44.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[351] at count at LogStream.java:120)
2016-12-14 14:06:44.049 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 78.0 with 1 tasks
2016-12-14 14:06:44.050 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 78.0 (TID 78, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:44.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 78.0 (TID 78)
2016-12-14 14:06:44.051 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:44.051 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:44.052 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 78.0 (TID 78). 1241 bytes result sent to driver
2016-12-14 14:06:44.053 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 78.0 (TID 78) in 3 ms on localhost (1/1)
2016-12-14 14:06:44.053 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2016-12-14 14:06:44.054 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 78 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:06:44.054 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 39 finished: take at LogStream.java:127, took 0.037941 s
2016-12-14 14:06:44.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695604000 ms.1 from job set of time 1481695604000 ms
2016-12-14 14:06:44.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.061 s for time 1481695604000 ms (execution: 0.048 s)
2016-12-14 14:06:44.061 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 334 from persistence list
2016-12-14 14:06:44.062 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[334] at createStream at LogStream.java:100 of time 1481695604000 ms
2016-12-14 14:06:44.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 342 from persistence list
2016-12-14 14:06:44.062 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 334
2016-12-14 14:06:44.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 341 from persistence list
2016-12-14 14:06:44.062 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 342
2016-12-14 14:06:44.063 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 340 from persistence list
2016-12-14 14:06:44.063 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 341
2016-12-14 14:06:44.063 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 339 from persistence list
2016-12-14 14:06:44.063 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 340
2016-12-14 14:06:44.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 337 from persistence list
2016-12-14 14:06:44.064 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 339
2016-12-14 14:06:44.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 336 from persistence list
2016-12-14 14:06:44.065 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 337
2016-12-14 14:06:44.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 335 from persistence list
2016-12-14 14:06:44.065 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 336
2016-12-14 14:06:44.066 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695602000 ms)
2016-12-14 14:06:44.066 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695602000 ms
2016-12-14 14:06:44.066 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 335
2016-12-14 14:06:45.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695605000 ms
2016-12-14 14:06:45.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695605000 ms.0 from job set of time 1481695605000 ms
2016-12-14 14:06:45.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695605000 ms.0 from job set of time 1481695605000 ms
2016-12-14 14:06:45.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695605000 ms.1 from job set of time 1481695605000 ms
2016-12-14 14:06:45.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:06:45.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 357 (union at DStream.scala:617)
2016-12-14 14:06:45.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 40 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:06:45.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 80 (take at LogStream.java:127)
2016-12-14 14:06:45.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 79)
2016-12-14 14:06:45.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 79)
2016-12-14 14:06:45.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 79 (UnionRDD[357] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:06:45.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_79 stored as values in memory (estimated size 4.2 KB, free 131.2 KB)
2016-12-14 14:06:45.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.4 KB, free 133.6 KB)
2016-12-14 14:06:45.021 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_79_piece0 in memory on localhost:60390 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:06:45.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 79 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:45.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 79 (UnionRDD[357] at union at DStream.scala:617)
2016-12-14 14:06:45.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 79.0 with 1 tasks
2016-12-14 14:06:45.022 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 79.0 (TID 79, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:06:45.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 79.0 (TID 79)
2016-12-14 14:06:45.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 79.0 (TID 79). 1159 bytes result sent to driver
2016-12-14 14:06:45.026 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 79.0 (TID 79) in 4 ms on localhost (1/1)
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 79 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:06:45.026 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 80)
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:06:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 80 (MapPartitionsRDD[360] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:06:45.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_80 stored as values in memory (estimated size 3.7 KB, free 137.3 KB)
2016-12-14 14:06:45.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_80_piece0 stored as bytes in memory (estimated size 2.1 KB, free 139.4 KB)
2016-12-14 14:06:45.028 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_80_piece0 in memory on localhost:60390 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:06:45.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 80 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:06:45.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[360] at count at LogStream.java:120)
2016-12-14 14:06:45.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 80.0 with 1 tasks
2016-12-14 14:06:45.029 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 80.0 (TID 80, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:06:45.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 80.0 (TID 80)
2016-12-14 14:06:45.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:06:45.031 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:06:45.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 80.0 (TID 80). 1241 bytes result sent to driver
2016-12-14 14:06:45.033 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 80.0 (TID 80) in 4 ms on localhost (1/1)
2016-12-14 14:06:45.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 80 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:06:45.033 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2016-12-14 14:06:45.033 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 40 finished: take at LogStream.java:127, took 0.015384 s
2016-12-14 14:06:45.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695605000 ms.1 from job set of time 1481695605000 ms
2016-12-14 14:06:45.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.039 s for time 1481695605000 ms (execution: 0.025 s)
2016-12-14 14:06:45.039 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 343 from persistence list
2016-12-14 14:06:45.039 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 343
2016-12-14 14:06:45.039 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[343] at createStream at LogStream.java:100 of time 1481695605000 ms
2016-12-14 14:06:45.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 351 from persistence list
2016-12-14 14:06:45.039 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 351
2016-12-14 14:06:45.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 350 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 350
2016-12-14 14:06:45.040 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 349 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 349
2016-12-14 14:06:45.040 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 348 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 348
2016-12-14 14:06:45.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 346 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 346
2016-12-14 14:06:45.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 345 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-7] INFO  o.apache.spark.storage.BlockManager - Removing RDD 345
2016-12-14 14:06:45.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 344 from persistence list
2016-12-14 14:06:45.040 [block-manager-slave-async-thread-pool-10] INFO  o.apache.spark.storage.BlockManager - Removing RDD 344
2016-12-14 14:06:45.041 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695603000 ms)
2016-12-14 14:06:45.041 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695603000 ms
2016-12-14 14:06:45.360 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 14:06:45.364 [dispatcher-event-loop-2] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 14:06:45.365 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 14:06:45.366 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 14:06:45.389 [dispatcher-event-loop-0] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05af closed
2016-12-14 14:06:45.389 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 14:06:45.391 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 14:06:45.392 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 14:06:45.393 [dispatcher-event-loop-1] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 14:06:45.394 [dispatcher-event-loop-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 14:06:45.395 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 14:06:45.601 [dispatcher-event-loop-0] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695605600
2016-12-14 14:06:45.602 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 14:06:45.612 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 14:06:45.613 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 14:06:45.613 [dispatcher-event-loop-0] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 14:06:45.614 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 14:06:45.615 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 14:06:45.616 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 40194 ms on localhost (1/1)
2016-12-14 14:06:45.616 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 40.207 s
2016-12-14 14:06:45.616 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:06:45.617 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 14:06:45.619 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 14:06:45.619 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 14:06:45.620 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695605000
2016-12-14 14:06:45.621 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 14:06:45.627 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 14:06:45.630 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 14:06:45.632 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 14:06:45.634 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 14:06:45.635 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 14:06:45.636 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 14:06:45.650 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 14:06:45.650 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 14:06:45.652 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:06:45.652 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:06:45.653 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:06:45.653 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:06:45.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:06:45.654 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:06:45.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:06:45.655 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:06:45.656 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:06:45.658 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:06:45.659 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:06:45.659 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:06:45.660 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:06:45.660 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:06:45.661 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:06:45.662 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:06:45.715 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 14:06:45.727 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:06:45.745 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 14:06:45.746 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 14:06:45.747 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 14:06:45.750 [dispatcher-event-loop-3] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 14:06:45.752 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 14:06:45.756 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:06:45.757 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-5c86ef31-22e9-4ff1-b593-d52741e781de
2016-12-14 14:06:45.761 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 14:06:45.764 [sparkDriverActorSystem-akka.actor.default-dispatcher-4] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:07:57.969 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:07:58.458 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:07:58.519 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:07:59.234 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:07:59.628 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:07:59.641 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:07:59.642 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:07:59.643 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:07:59.643 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:07:59.644 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:07:59.697 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:07:59.719 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:07:59.730 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05b0, negotiated timeout = 40000
2016-12-14 14:07:59.874 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:08:01.301 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:08:01.314 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:08:01.323 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:08:01.331 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:08:01.334 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:08:01.334 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:08:01.334 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:08:01.350 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:08:01.350 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:08:01.835 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:08:02.203 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:08:02.268 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:08:02.269 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:08:02.270 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:08:03.115 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60464.
2016-12-14 14:08:04.127 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:08:04.213 [sparkDriverActorSystem-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2016-12-14 14:08:04.423 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:60465]
2016-12-14 14:08:04.434 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 60465.
2016-12-14 14:08:04.457 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:08:04.486 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:08:04.504 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-ae6eeeea-5260-4886-ae6a-a89da59e0e12
2016-12-14 14:08:04.516 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:08:04.603 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:08:04.987 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:08:05.039 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:08:05.040 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:08:05.042 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:08:05.153 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:08:05.180 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60466.
2016-12-14 14:08:05.182 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 60466
2016-12-14 14:08:05.184 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:08:05.187 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:60466 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 60466)
2016-12-14 14:08:05.190 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:08:06.308 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - Starting 1 receivers
2016-12-14 14:08:06.310 [streaming-start] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker started
2016-12-14 14:08:06.318 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.321 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.321 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:08:06.322 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.323 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:08:06.323 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@3e29060e
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@bcd6d68
2016-12-14 14:08:06.324 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.325 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.325 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.325 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.325 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.325 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.326 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.326 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.326 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - metadataCleanupDelay = -1
2016-12-14 14:08:06.326 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Slide time = 1000 ms
2016-12-14 14:08:06.326 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Checkpoint interval = null
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.kafka.KafkaInputDStream - Initialized and validated org.apache.spark.streaming.kafka.KafkaInputDStream@3e29060e
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@5df59ca0
2016-12-14 14:08:06.327 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Slide time = 1000 ms
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Checkpoint interval = null
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.FilteredDStream - Initialized and validated org.apache.spark.streaming.dstream.FilteredDStream@4e6ebf42
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@3881d9f7
2016-12-14 14:08:06.328 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Slide time = 1000 ms
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Checkpoint interval = null
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.TransformedDStream - Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@584745a2
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Slide time = 1000 ms
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Checkpoint interval = null
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.ShuffledDStream - Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@29a6d296
2016-12-14 14:08:06.329 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@1209ec4f
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Slide time = 1000 ms
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Checkpoint interval = null
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.MappedDStream - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@24f1c198
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Slide time = 1000 ms
2016-12-14 14:08:06.330 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Storage level = StorageLevel(false, false, false, false, 1)
2016-12-14 14:08:06.331 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Checkpoint interval = null
2016-12-14 14:08:06.331 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Remember duration = 1000 ms
2016-12-14 14:08:06.331 [streaming-start] INFO  o.a.s.s.dstream.ForEachDStream - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@4679eaf1
2016-12-14 14:08:06.404 [streaming-start] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for JobGenerator at time 1481695687000
2016-12-14 14:08:06.405 [streaming-start] INFO  o.a.s.s.scheduler.JobGenerator - Started JobGenerator at 1481695687000 ms
2016-12-14 14:08:06.406 [streaming-start] INFO  o.a.s.s.scheduler.JobScheduler - Started JobScheduler
2016-12-14 14:08:06.411 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Receiver 0 started
2016-12-14 14:08:06.415 [main] INFO  o.a.spark.streaming.StreamingContext - StreamingContext started
2016-12-14 14:08:06.421 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (start at LogStream.java:135) with 1 output partitions
2016-12-14 14:08:06.422 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (start at LogStream.java:135)
2016-12-14 14:08:06.423 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2016-12-14 14:08:06.424 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2016-12-14 14:08:06.436 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588), which has no missing parents
2016-12-14 14:08:06.584 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 76.2 KB, free 76.2 KB)
2016-12-14 14:08:06.602 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.9 KB, free 102.1 KB)
2016-12-14 14:08:06.606 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on localhost:60466 (size: 25.9 KB, free: 1140.3 MB)
2016-12-14 14:08:06.608 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:06.616 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:588)
2016-12-14 14:08:06.619 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2016-12-14 14:08:06.682 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2982 bytes)
2016-12-14 14:08:06.697 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2016-12-14 14:08:06.786 [Executor task launch worker-0] INFO  o.a.s.streaming.util.RecurringTimer - Started timer for BlockGenerator at time 1481695686800
2016-12-14 14:08:06.787 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Started block pushing thread
2016-12-14 14:08:06.787 [Executor task launch worker-0] INFO  o.a.s.s.receiver.BlockGenerator - Started BlockGenerator
2016-12-14 14:08:06.802 [dispatcher-event-loop-3] INFO  o.a.s.s.scheduler.ReceiverTracker - Registered receiver for stream 0 from 192.168.109.104:60464
2016-12-14 14:08:06.803 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Starting receiver
2016-12-14 14:08:06.804 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: recsys_group0 security.protocol: default
2016-12-14 14:08:06.806 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connecting to Zookeeper: hdp1:2181
2016-12-14 14:08:06.900 [Executor task launch worker-0] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@31629c9a
2016-12-14 14:08:06.903 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:08:06.904 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:08:06.908 [Executor task launch worker-0-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05b1, negotiated timeout = 6000
2016-12-14 14:08:07.005 [Executor task launch worker-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Connected to hdp1:2181
2016-12-14 14:08:07.111 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695687000 ms
2016-12-14 14:08:07.116 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695687000 ms.0 from job set of time 1481695687000 ms
2016-12-14 14:08:07.123 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695687000 ms.0 from job set of time 1481695687000 ms
2016-12-14 14:08:07.123 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695687000 ms.1 from job set of time 1481695687000 ms
2016-12-14 14:08:07.154 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:07.169 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 6 (union at DStream.scala:617)
2016-12-14 14:08:07.171 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:07.171 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (take at LogStream.java:127)
2016-12-14 14:08:07.171 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2016-12-14 14:08:07.171 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2016-12-14 14:08:07.173 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (UnionRDD[6] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:07.188 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 106.3 KB)
2016-12-14 14:08:07.191 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 108.7 KB)
2016-12-14 14:08:07.192 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:07.193 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:07.195 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (UnionRDD[6] at union at DStream.scala:617)
2016-12-14 14:08:07.195 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2016-12-14 14:08:07.200 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:07.201 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2016-12-14 14:08:07.307 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1159 bytes result sent to driver
2016-12-14 14:08:07.318 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 119 ms on localhost (1/1)
2016-12-14 14:08:07.319 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-12-14 14:08:07.322 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (union at DStream.scala:617) finished in 0.126 s
2016-12-14 14:08:07.323 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:07.324 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:07.324 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2016-12-14 14:08:07.325 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:07.327 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:07.332 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 112.4 KB)
2016-12-14 14:08:07.341 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 114.5 KB)
2016-12-14 14:08:07.342 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:07.343 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:07.344 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at count at LogStream.java:120)
2016-12-14 14:08:07.344 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2016-12-14 14:08:07.356 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:07.357 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2016-12-14 14:08:07.524 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:07.525 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 150 ms
2016-12-14 14:08:07.541 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:07.608 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1241 bytes result sent to driver
2016-12-14 14:08:07.610 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 262 ms on localhost (1/1)
2016-12-14 14:08:07.611 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-12-14 14:08:07.611 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (take at LogStream.java:127) finished in 0.264 s
2016-12-14 14:08:07.626 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: take at LogStream.java:127, took 0.470957 s
2016-12-14 14:08:07.790 [KafkaMessageHandler-0] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:08:07.790 [KafkaMessageHandler-2] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:08:07.790 [KafkaMessageHandler-1] INFO  o.a.s.streaming.kafka.KafkaReceiver - Starting MessageHandler.
2016-12-14 14:08:07.790 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStart
2016-12-14 14:08:07.791 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Waiting for receiver to be stopped
2016-12-14 14:08:08.029 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695688000 ms
2016-12-14 14:08:08.176 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695687000 ms.1 from job set of time 1481695687000 ms
2016-12-14 14:08:08.178 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 1.176 s for time 1481695687000 ms (execution: 1.063 s)
2016-12-14 14:08:08.178 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695688000 ms.0 from job set of time 1481695688000 ms
2016-12-14 14:08:08.179 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695688000 ms.0 from job set of time 1481695688000 ms
2016-12-14 14:08:08.179 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695688000 ms.1 from job set of time 1481695688000 ms
2016-12-14 14:08:08.185 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:08:08.186 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:08:08.190 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:08.191 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 15 (union at DStream.scala:617)
2016-12-14 14:08:08.192 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:08.192 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (take at LogStream.java:127)
2016-12-14 14:08:08.192 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 3)
2016-12-14 14:08:08.192 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 3)
2016-12-14 14:08:08.193 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 3 (UnionRDD[15] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:08.196 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 112.1 KB)
2016-12-14 14:08:08.197 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 114.5 KB)
2016-12-14 14:08:08.198 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:08.198 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:08.199 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 3 (UnionRDD[15] at union at DStream.scala:617)
2016-12-14 14:08:08.199 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
2016-12-14 14:08:08.200 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:08.201 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2016-12-14 14:08:08.209 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1159 bytes result sent to driver
2016-12-14 14:08:08.210 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (1/1)
2016-12-14 14:08:08.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 3 (union at DStream.scala:617) finished in 0.011 s
2016-12-14 14:08:08.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:08.210 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-12-14 14:08:08.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:08.211 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 4)
2016-12-14 14:08:08.211 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:08.211 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[18] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:08.214 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.7 KB, free 118.2 KB)
2016-12-14 14:08:08.215 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 120.3 KB)
2016-12-14 14:08:08.216 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:08.217 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:08.218 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at count at LogStream.java:120)
2016-12-14 14:08:08.218 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks
2016-12-14 14:08:08.219 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:08.219 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2016-12-14 14:08:08.223 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:08.223 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:08.226 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1241 bytes result sent to driver
2016-12-14 14:08:08.228 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (1/1)
2016-12-14 14:08:08.228 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:08:08.228 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-12-14 14:08:08.229 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: take at LogStream.java:127, took 0.038666 s
2016-12-14 14:08:08.244 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695688000 ms.1 from job set of time 1481695688000 ms
2016-12-14 14:08:08.245 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.244 s for time 1481695688000 ms (execution: 0.066 s)
2016-12-14 14:08:08.245 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 1 from persistence list
2016-12-14 14:08:08.251 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 1
2016-12-14 14:08:08.252 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[1] at createStream at LogStream.java:100 of time 1481695688000 ms
2016-12-14 14:08:08.253 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 9 from persistence list
2016-12-14 14:08:08.254 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 9
2016-12-14 14:08:08.255 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 8 from persistence list
2016-12-14 14:08:08.255 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 8
2016-12-14 14:08:08.256 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 7 from persistence list
2016-12-14 14:08:08.256 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 7
2016-12-14 14:08:08.257 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 6 from persistence list
2016-12-14 14:08:08.257 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 6
2016-12-14 14:08:08.257 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 4 from persistence list
2016-12-14 14:08:08.260 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 4
2016-12-14 14:08:08.260 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 3 from persistence list
2016-12-14 14:08:08.261 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 3
2016-12-14 14:08:08.261 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 2 from persistence list
2016-12-14 14:08:08.262 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 2
2016-12-14 14:08:08.263 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer()
2016-12-14 14:08:08.263 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 
2016-12-14 14:08:09.024 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695689000 ms
2016-12-14 14:08:09.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695689000 ms.0 from job set of time 1481695689000 ms
2016-12-14 14:08:09.025 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695689000 ms.0 from job set of time 1481695689000 ms
2016-12-14 14:08:09.025 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695689000 ms.1 from job set of time 1481695689000 ms
2016-12-14 14:08:09.032 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:09.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 24 (union at DStream.scala:617)
2016-12-14 14:08:09.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:09.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (take at LogStream.java:127)
2016-12-14 14:08:09.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 5)
2016-12-14 14:08:09.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 5)
2016-12-14 14:08:09.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 5 (UnionRDD[24] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:09.039 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 4.2 KB, free 124.5 KB)
2016-12-14 14:08:09.041 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 127.0 KB)
2016-12-14 14:08:09.042 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:09.043 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:09.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 5 (UnionRDD[24] at union at DStream.scala:617)
2016-12-14 14:08:09.043 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks
2016-12-14 14:08:09.046 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:09.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2016-12-14 14:08:09.055 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1159 bytes result sent to driver
2016-12-14 14:08:09.057 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (1/1)
2016-12-14 14:08:09.057 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-12-14 14:08:09.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 5 (union at DStream.scala:617) finished in 0.014 s
2016-12-14 14:08:09.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:09.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:09.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 6)
2016-12-14 14:08:09.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:09.059 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[27] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:09.061 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 130.7 KB)
2016-12-14 14:08:09.066 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 132.8 KB)
2016-12-14 14:08:09.068 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:09.068 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:09.069 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at count at LogStream.java:120)
2016-12-14 14:08:09.069 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks
2016-12-14 14:08:09.070 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:09.070 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2016-12-14 14:08:09.074 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:09.074 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:09.076 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1241 bytes result sent to driver
2016-12-14 14:08:09.077 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (1/1)
2016-12-14 14:08:09.078 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-12-14 14:08:09.078 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (take at LogStream.java:127) finished in 0.009 s
2016-12-14 14:08:09.080 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: take at LogStream.java:127, took 0.047935 s
2016-12-14 14:08:09.089 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695689000 ms.1 from job set of time 1481695689000 ms
2016-12-14 14:08:09.089 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.088 s for time 1481695689000 ms (execution: 0.064 s)
2016-12-14 14:08:09.089 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 10 from persistence list
2016-12-14 14:08:09.090 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 10
2016-12-14 14:08:09.090 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[10] at createStream at LogStream.java:100 of time 1481695689000 ms
2016-12-14 14:08:09.090 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 18 from persistence list
2016-12-14 14:08:09.091 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 18
2016-12-14 14:08:09.091 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 17 from persistence list
2016-12-14 14:08:09.091 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 17
2016-12-14 14:08:09.091 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 16 from persistence list
2016-12-14 14:08:09.092 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 16
2016-12-14 14:08:09.092 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 15 from persistence list
2016-12-14 14:08:09.093 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 15
2016-12-14 14:08:09.093 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 13 from persistence list
2016-12-14 14:08:09.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 12 from persistence list
2016-12-14 14:08:09.094 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 13
2016-12-14 14:08:09.094 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 12
2016-12-14 14:08:09.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 11 from persistence list
2016-12-14 14:08:09.095 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 11
2016-12-14 14:08:09.096 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695687000 ms)
2016-12-14 14:08:09.096 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695687000 ms
2016-12-14 14:08:10.023 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695690000 ms
2016-12-14 14:08:10.023 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695690000 ms.0 from job set of time 1481695690000 ms
2016-12-14 14:08:10.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695690000 ms.0 from job set of time 1481695690000 ms
2016-12-14 14:08:10.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695690000 ms.1 from job set of time 1481695690000 ms
2016-12-14 14:08:10.029 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:10.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 33 (union at DStream.scala:617)
2016-12-14 14:08:10.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:10.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (take at LogStream.java:127)
2016-12-14 14:08:10.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 7)
2016-12-14 14:08:10.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 7)
2016-12-14 14:08:10.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 7 (UnionRDD[33] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:10.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 137.0 KB)
2016-12-14 14:08:10.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 139.4 KB)
2016-12-14 14:08:10.039 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:10.040 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:10.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 7 (UnionRDD[33] at union at DStream.scala:617)
2016-12-14 14:08:10.040 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks
2016-12-14 14:08:10.041 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:10.042 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2016-12-14 14:08:10.048 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 1159 bytes result sent to driver
2016-12-14 14:08:10.050 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (1/1)
2016-12-14 14:08:10.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 7 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:08:10.050 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-12-14 14:08:10.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:10.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:10.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 8)
2016-12-14 14:08:10.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:10.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[36] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:10.053 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 143.1 KB)
2016-12-14 14:08:10.055 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.1 KB, free 145.2 KB)
2016-12-14 14:08:10.056 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:10.057 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:10.057 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[36] at count at LogStream.java:120)
2016-12-14 14:08:10.057 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks
2016-12-14 14:08:10.058 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:10.059 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2016-12-14 14:08:10.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:10.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:10.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1241 bytes result sent to driver
2016-12-14 14:08:10.065 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 7 ms on localhost (1/1)
2016-12-14 14:08:10.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:10.065 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-12-14 14:08:10.065 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: take at LogStream.java:127, took 0.036278 s
2016-12-14 14:08:10.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695690000 ms.1 from job set of time 1481695690000 ms
2016-12-14 14:08:10.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.072 s for time 1481695690000 ms (execution: 0.049 s)
2016-12-14 14:08:10.072 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 19 from persistence list
2016-12-14 14:08:10.073 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 19
2016-12-14 14:08:10.073 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[19] at createStream at LogStream.java:100 of time 1481695690000 ms
2016-12-14 14:08:10.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 27 from persistence list
2016-12-14 14:08:10.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 27
2016-12-14 14:08:10.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 26 from persistence list
2016-12-14 14:08:10.075 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 26
2016-12-14 14:08:10.076 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 25 from persistence list
2016-12-14 14:08:10.076 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 25
2016-12-14 14:08:10.077 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 24 from persistence list
2016-12-14 14:08:10.077 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 24
2016-12-14 14:08:10.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 22 from persistence list
2016-12-14 14:08:10.078 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 22
2016-12-14 14:08:10.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 21 from persistence list
2016-12-14 14:08:10.079 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 21
2016-12-14 14:08:10.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 20 from persistence list
2016-12-14 14:08:10.080 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 20
2016-12-14 14:08:10.081 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695688000 ms)
2016-12-14 14:08:10.081 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695688000 ms
2016-12-14 14:08:11.018 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695691000 ms
2016-12-14 14:08:11.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695691000 ms.0 from job set of time 1481695691000 ms
2016-12-14 14:08:11.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695691000 ms.0 from job set of time 1481695691000 ms
2016-12-14 14:08:11.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695691000 ms.1 from job set of time 1481695691000 ms
2016-12-14 14:08:11.024 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:11.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 42 (union at DStream.scala:617)
2016-12-14 14:08:11.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:11.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (take at LogStream.java:127)
2016-12-14 14:08:11.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 9)
2016-12-14 14:08:11.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 9)
2016-12-14 14:08:11.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (UnionRDD[42] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:11.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 4.2 KB, free 149.4 KB)
2016-12-14 14:08:11.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 151.9 KB)
2016-12-14 14:08:11.033 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:11.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:11.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 9 (UnionRDD[42] at union at DStream.scala:617)
2016-12-14 14:08:11.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks
2016-12-14 14:08:11.036 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:11.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2016-12-14 14:08:11.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1159 bytes result sent to driver
2016-12-14 14:08:11.045 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 9 ms on localhost (1/1)
2016-12-14 14:08:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:08:11.045 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-12-14 14:08:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 10)
2016-12-14 14:08:11.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:11.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[45] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:11.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 3.7 KB, free 155.6 KB)
2016-12-14 14:08:11.050 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.1 KB, free 157.7 KB)
2016-12-14 14:08:11.051 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:11.052 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:11.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at count at LogStream.java:120)
2016-12-14 14:08:11.052 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks
2016-12-14 14:08:11.053 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:11.054 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2016-12-14 14:08:11.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:11.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:11.059 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 1241 bytes result sent to driver
2016-12-14 14:08:11.060 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on localhost (1/1)
2016-12-14 14:08:11.060 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-12-14 14:08:11.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:11.061 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: take at LogStream.java:127, took 0.036161 s
2016-12-14 14:08:11.066 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695691000 ms.1 from job set of time 1481695691000 ms
2016-12-14 14:08:11.067 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 28 from persistence list
2016-12-14 14:08:11.067 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.066 s for time 1481695691000 ms (execution: 0.047 s)
2016-12-14 14:08:11.067 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 28
2016-12-14 14:08:11.068 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[28] at createStream at LogStream.java:100 of time 1481695691000 ms
2016-12-14 14:08:11.068 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 36 from persistence list
2016-12-14 14:08:11.068 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 36
2016-12-14 14:08:11.068 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 35 from persistence list
2016-12-14 14:08:11.069 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 35
2016-12-14 14:08:11.069 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 34 from persistence list
2016-12-14 14:08:11.069 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 34
2016-12-14 14:08:11.070 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 33 from persistence list
2016-12-14 14:08:11.070 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 33
2016-12-14 14:08:11.070 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 31 from persistence list
2016-12-14 14:08:11.071 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 31
2016-12-14 14:08:11.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 30 from persistence list
2016-12-14 14:08:11.071 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 30
2016-12-14 14:08:11.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 29 from persistence list
2016-12-14 14:08:11.072 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 29
2016-12-14 14:08:11.072 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695689000 ms)
2016-12-14 14:08:11.072 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695689000 ms
2016-12-14 14:08:12.020 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695692000 ms
2016-12-14 14:08:12.021 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695692000 ms.0 from job set of time 1481695692000 ms
2016-12-14 14:08:12.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695692000 ms.0 from job set of time 1481695692000 ms
2016-12-14 14:08:12.022 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695692000 ms.1 from job set of time 1481695692000 ms
2016-12-14 14:08:12.027 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:12.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 51 (union at DStream.scala:617)
2016-12-14 14:08:12.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:12.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (take at LogStream.java:127)
2016-12-14 14:08:12.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 11)
2016-12-14 14:08:12.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 11)
2016-12-14 14:08:12.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 11 (UnionRDD[51] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:12.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 4.2 KB, free 161.9 KB)
2016-12-14 14:08:12.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 164.3 KB)
2016-12-14 14:08:12.037 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:12.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:12.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 11 (UnionRDD[51] at union at DStream.scala:617)
2016-12-14 14:08:12.038 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks
2016-12-14 14:08:12.040 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:12.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2016-12-14 14:08:12.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1159 bytes result sent to driver
2016-12-14 14:08:12.047 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 8 ms on localhost (1/1)
2016-12-14 14:08:12.047 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 11 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:08:12.047 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-12-14 14:08:12.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:12.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:12.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 12)
2016-12-14 14:08:12.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:12.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[54] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:12.051 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 3.7 KB, free 168.0 KB)
2016-12-14 14:08:12.053 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.1 KB, free 170.1 KB)
2016-12-14 14:08:12.054 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:12.055 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:12.055 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at count at LogStream.java:120)
2016-12-14 14:08:12.056 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks
2016-12-14 14:08:12.057 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:12.058 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2016-12-14 14:08:12.060 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:12.060 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:12.062 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1241 bytes result sent to driver
2016-12-14 14:08:12.063 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 6 ms on localhost (1/1)
2016-12-14 14:08:12.063 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-12-14 14:08:12.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:12.064 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: take at LogStream.java:127, took 0.036542 s
2016-12-14 14:08:12.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695692000 ms.1 from job set of time 1481695692000 ms
2016-12-14 14:08:12.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.072 s for time 1481695692000 ms (execution: 0.051 s)
2016-12-14 14:08:12.072 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 37 from persistence list
2016-12-14 14:08:12.074 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 37
2016-12-14 14:08:12.074 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[37] at createStream at LogStream.java:100 of time 1481695692000 ms
2016-12-14 14:08:12.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 45 from persistence list
2016-12-14 14:08:12.076 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 45
2016-12-14 14:08:12.076 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 44 from persistence list
2016-12-14 14:08:12.077 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 44
2016-12-14 14:08:12.077 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 43 from persistence list
2016-12-14 14:08:12.077 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 43
2016-12-14 14:08:12.077 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 42 from persistence list
2016-12-14 14:08:12.078 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 42
2016-12-14 14:08:12.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 40 from persistence list
2016-12-14 14:08:12.079 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 40
2016-12-14 14:08:12.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 39 from persistence list
2016-12-14 14:08:12.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 38 from persistence list
2016-12-14 14:08:12.080 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 39
2016-12-14 14:08:12.081 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 38
2016-12-14 14:08:12.081 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695690000 ms)
2016-12-14 14:08:12.082 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695690000 ms
2016-12-14 14:08:13.017 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695693000 ms
2016-12-14 14:08:13.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695693000 ms.0 from job set of time 1481695693000 ms
2016-12-14 14:08:13.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695693000 ms.0 from job set of time 1481695693000 ms
2016-12-14 14:08:13.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695693000 ms.1 from job set of time 1481695693000 ms
2016-12-14 14:08:13.025 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:13.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 60 (union at DStream.scala:617)
2016-12-14 14:08:13.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:13.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (take at LogStream.java:127)
2016-12-14 14:08:13.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 13)
2016-12-14 14:08:13.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 13)
2016-12-14 14:08:13.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 13 (UnionRDD[60] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:13.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 4.2 KB, free 174.3 KB)
2016-12-14 14:08:13.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 176.8 KB)
2016-12-14 14:08:13.035 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:13.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:13.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 13 (UnionRDD[60] at union at DStream.scala:617)
2016-12-14 14:08:13.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks
2016-12-14 14:08:13.038 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:13.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2016-12-14 14:08:13.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 1159 bytes result sent to driver
2016-12-14 14:08:13.044 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 7 ms on localhost (1/1)
2016-12-14 14:08:13.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 13 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:13.044 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-12-14 14:08:13.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:13.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:13.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 14)
2016-12-14 14:08:13.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:13.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[63] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:13.047 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 3.7 KB, free 180.5 KB)
2016-12-14 14:08:13.050 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.1 KB, free 182.6 KB)
2016-12-14 14:08:13.050 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:13.051 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:13.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[63] at count at LogStream.java:120)
2016-12-14 14:08:13.051 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks
2016-12-14 14:08:13.053 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:13.053 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2016-12-14 14:08:13.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:13.057 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:13.061 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1241 bytes result sent to driver
2016-12-14 14:08:13.062 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 10 ms on localhost (1/1)
2016-12-14 14:08:13.062 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:08:13.062 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-12-14 14:08:13.063 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: take at LogStream.java:127, took 0.037466 s
2016-12-14 14:08:13.069 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695693000 ms.1 from job set of time 1481695693000 ms
2016-12-14 14:08:13.070 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 46 from persistence list
2016-12-14 14:08:13.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.069 s for time 1481695693000 ms (execution: 0.052 s)
2016-12-14 14:08:13.070 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 46
2016-12-14 14:08:13.071 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[46] at createStream at LogStream.java:100 of time 1481695693000 ms
2016-12-14 14:08:13.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 54 from persistence list
2016-12-14 14:08:13.071 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 54
2016-12-14 14:08:13.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 53 from persistence list
2016-12-14 14:08:13.072 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 53
2016-12-14 14:08:13.073 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 52 from persistence list
2016-12-14 14:08:13.073 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 52
2016-12-14 14:08:13.073 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 51 from persistence list
2016-12-14 14:08:13.073 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 51
2016-12-14 14:08:13.073 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 49 from persistence list
2016-12-14 14:08:13.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 49
2016-12-14 14:08:13.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 48 from persistence list
2016-12-14 14:08:13.074 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 48
2016-12-14 14:08:13.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 47 from persistence list
2016-12-14 14:08:13.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 47
2016-12-14 14:08:13.075 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695691000 ms)
2016-12-14 14:08:13.075 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695691000 ms
2016-12-14 14:08:14.019 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695694000 ms
2016-12-14 14:08:14.021 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695694000 ms.0 from job set of time 1481695694000 ms
2016-12-14 14:08:14.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695694000 ms.0 from job set of time 1481695694000 ms
2016-12-14 14:08:14.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695694000 ms.1 from job set of time 1481695694000 ms
2016-12-14 14:08:14.027 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:14.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 69 (union at DStream.scala:617)
2016-12-14 14:08:14.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:14.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (take at LogStream.java:127)
2016-12-14 14:08:14.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 15)
2016-12-14 14:08:14.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 15)
2016-12-14 14:08:14.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 15 (UnionRDD[69] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:14.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 4.2 KB, free 186.8 KB)
2016-12-14 14:08:14.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 189.2 KB)
2016-12-14 14:08:14.036 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:14.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:14.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 15 (UnionRDD[69] at union at DStream.scala:617)
2016-12-14 14:08:14.038 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks
2016-12-14 14:08:14.039 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:14.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2016-12-14 14:08:14.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 1159 bytes result sent to driver
2016-12-14 14:08:14.047 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 8 ms on localhost (1/1)
2016-12-14 14:08:14.048 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-12-14 14:08:14.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 15 (union at DStream.scala:617) finished in 0.011 s
2016-12-14 14:08:14.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:14.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:14.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 16)
2016-12-14 14:08:14.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:14.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[72] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:14.052 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 3.7 KB, free 192.9 KB)
2016-12-14 14:08:14.054 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.1 KB, free 195.0 KB)
2016-12-14 14:08:14.055 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:14.055 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:14.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[72] at count at LogStream.java:120)
2016-12-14 14:08:14.056 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks
2016-12-14 14:08:14.057 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:14.058 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2016-12-14 14:08:14.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:14.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:14.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1241 bytes result sent to driver
2016-12-14 14:08:14.065 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 8 ms on localhost (1/1)
2016-12-14 14:08:14.065 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-12-14 14:08:14.066 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (take at LogStream.java:127) finished in 0.009 s
2016-12-14 14:08:14.067 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: take at LogStream.java:127, took 0.040287 s
2016-12-14 14:08:14.073 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695694000 ms.1 from job set of time 1481695694000 ms
2016-12-14 14:08:14.073 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 55 from persistence list
2016-12-14 14:08:14.073 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.073 s for time 1481695694000 ms (execution: 0.053 s)
2016-12-14 14:08:14.073 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 55
2016-12-14 14:08:14.074 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[55] at createStream at LogStream.java:100 of time 1481695694000 ms
2016-12-14 14:08:14.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 63 from persistence list
2016-12-14 14:08:14.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 63
2016-12-14 14:08:14.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 62 from persistence list
2016-12-14 14:08:14.075 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 62
2016-12-14 14:08:14.075 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 61 from persistence list
2016-12-14 14:08:14.076 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 61
2016-12-14 14:08:14.076 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 60 from persistence list
2016-12-14 14:08:14.076 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 60
2016-12-14 14:08:14.076 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 58 from persistence list
2016-12-14 14:08:14.077 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 58
2016-12-14 14:08:14.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 57 from persistence list
2016-12-14 14:08:14.077 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 57
2016-12-14 14:08:14.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 56 from persistence list
2016-12-14 14:08:14.078 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 56
2016-12-14 14:08:14.078 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695692000 ms)
2016-12-14 14:08:14.078 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695692000 ms
2016-12-14 14:08:15.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695695000 ms
2016-12-14 14:08:15.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695695000 ms.0 from job set of time 1481695695000 ms
2016-12-14 14:08:15.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695695000 ms.0 from job set of time 1481695695000 ms
2016-12-14 14:08:15.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695695000 ms.1 from job set of time 1481695695000 ms
2016-12-14 14:08:15.023 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:15.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 78 (union at DStream.scala:617)
2016-12-14 14:08:15.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:15.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 18 (take at LogStream.java:127)
2016-12-14 14:08:15.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 17)
2016-12-14 14:08:15.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 17)
2016-12-14 14:08:15.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 17 (UnionRDD[78] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:15.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 4.2 KB, free 199.2 KB)
2016-12-14 14:08:15.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.4 KB, free 201.7 KB)
2016-12-14 14:08:15.033 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:15.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:15.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 17 (UnionRDD[78] at union at DStream.scala:617)
2016-12-14 14:08:15.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 1 tasks
2016-12-14 14:08:15.035 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:15.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2016-12-14 14:08:15.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 1159 bytes result sent to driver
2016-12-14 14:08:15.043 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 7 ms on localhost (1/1)
2016-12-14 14:08:15.043 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-12-14 14:08:15.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 17 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:15.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:15.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:15.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 18)
2016-12-14 14:08:15.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:15.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 18 (MapPartitionsRDD[81] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:15.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 3.7 KB, free 205.4 KB)
2016-12-14 14:08:15.051 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.1 KB, free 207.5 KB)
2016-12-14 14:08:15.052 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:15.052 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:15.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[81] at count at LogStream.java:120)
2016-12-14 14:08:15.052 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 18.0 with 1 tasks
2016-12-14 14:08:15.053 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 18.0 (TID 18, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:15.054 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 18.0 (TID 18)
2016-12-14 14:08:15.056 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:15.056 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:15.058 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 18.0 (TID 18). 1241 bytes result sent to driver
2016-12-14 14:08:15.060 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 18.0 (TID 18) in 7 ms on localhost (1/1)
2016-12-14 14:08:15.060 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-12-14 14:08:15.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 18 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:15.062 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: take at LogStream.java:127, took 0.038192 s
2016-12-14 14:08:15.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695695000 ms.1 from job set of time 1481695695000 ms
2016-12-14 14:08:15.073 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.072 s for time 1481695695000 ms (execution: 0.056 s)
2016-12-14 14:08:15.073 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 64 from persistence list
2016-12-14 14:08:15.073 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 64
2016-12-14 14:08:15.074 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[64] at createStream at LogStream.java:100 of time 1481695695000 ms
2016-12-14 14:08:15.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 72 from persistence list
2016-12-14 14:08:15.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 72
2016-12-14 14:08:15.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 71 from persistence list
2016-12-14 14:08:15.075 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 71
2016-12-14 14:08:15.075 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 70 from persistence list
2016-12-14 14:08:15.075 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 70
2016-12-14 14:08:15.076 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 69 from persistence list
2016-12-14 14:08:15.076 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 69
2016-12-14 14:08:15.076 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 67 from persistence list
2016-12-14 14:08:15.076 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 67
2016-12-14 14:08:15.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 66 from persistence list
2016-12-14 14:08:15.080 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 66
2016-12-14 14:08:15.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 65 from persistence list
2016-12-14 14:08:15.081 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 65
2016-12-14 14:08:15.082 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695693000 ms)
2016-12-14 14:08:15.082 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695693000 ms
2016-12-14 14:08:16.019 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695696000 ms
2016-12-14 14:08:16.019 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695696000 ms.0 from job set of time 1481695696000 ms
2016-12-14 14:08:16.020 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695696000 ms.0 from job set of time 1481695696000 ms
2016-12-14 14:08:16.020 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695696000 ms.1 from job set of time 1481695696000 ms
2016-12-14 14:08:16.026 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:16.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 87 (union at DStream.scala:617)
2016-12-14 14:08:16.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:16.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (take at LogStream.java:127)
2016-12-14 14:08:16.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 19)
2016-12-14 14:08:16.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 19)
2016-12-14 14:08:16.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 19 (UnionRDD[87] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:16.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 4.2 KB, free 211.7 KB)
2016-12-14 14:08:16.031 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 214.1 KB)
2016-12-14 14:08:16.032 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:16.032 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:16.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 19 (UnionRDD[87] at union at DStream.scala:617)
2016-12-14 14:08:16.033 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks
2016-12-14 14:08:16.034 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:16.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2016-12-14 14:08:16.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 1159 bytes result sent to driver
2016-12-14 14:08:16.038 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 5 ms on localhost (1/1)
2016-12-14 14:08:16.038 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 19 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 20)
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:16.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[90] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:16.041 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 3.7 KB, free 217.8 KB)
2016-12-14 14:08:16.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.1 KB, free 219.9 KB)
2016-12-14 14:08:16.044 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:16.045 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:16.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[90] at count at LogStream.java:120)
2016-12-14 14:08:16.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks
2016-12-14 14:08:16.046 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:16.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2016-12-14 14:08:16.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:16.049 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:16.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1241 bytes result sent to driver
2016-12-14 14:08:16.052 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 5 ms on localhost (1/1)
2016-12-14 14:08:16.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:16.052 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-12-14 14:08:16.052 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: take at LogStream.java:127, took 0.026313 s
2016-12-14 14:08:16.059 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695696000 ms.1 from job set of time 1481695696000 ms
2016-12-14 14:08:16.060 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 73 from persistence list
2016-12-14 14:08:16.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.059 s for time 1481695696000 ms (execution: 0.040 s)
2016-12-14 14:08:16.060 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 73
2016-12-14 14:08:16.060 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[73] at createStream at LogStream.java:100 of time 1481695696000 ms
2016-12-14 14:08:16.060 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 81 from persistence list
2016-12-14 14:08:16.060 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 81
2016-12-14 14:08:16.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 80 from persistence list
2016-12-14 14:08:16.061 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 80
2016-12-14 14:08:16.061 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 79 from persistence list
2016-12-14 14:08:16.061 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 79
2016-12-14 14:08:16.061 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 78 from persistence list
2016-12-14 14:08:16.062 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 78
2016-12-14 14:08:16.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 76 from persistence list
2016-12-14 14:08:16.062 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 76
2016-12-14 14:08:16.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 75 from persistence list
2016-12-14 14:08:16.063 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 75
2016-12-14 14:08:16.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 74 from persistence list
2016-12-14 14:08:16.064 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695694000 ms)
2016-12-14 14:08:16.064 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 74
2016-12-14 14:08:16.064 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695694000 ms
2016-12-14 14:08:17.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695697000 ms
2016-12-14 14:08:17.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695697000 ms.0 from job set of time 1481695697000 ms
2016-12-14 14:08:17.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695697000 ms.0 from job set of time 1481695697000 ms
2016-12-14 14:08:17.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695697000 ms.1 from job set of time 1481695697000 ms
2016-12-14 14:08:17.022 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:17.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 96 (union at DStream.scala:617)
2016-12-14 14:08:17.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:17.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 22 (take at LogStream.java:127)
2016-12-14 14:08:17.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 21)
2016-12-14 14:08:17.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 21)
2016-12-14 14:08:17.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 21 (UnionRDD[96] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:17.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 4.2 KB, free 224.1 KB)
2016-12-14 14:08:17.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.4 KB, free 226.6 KB)
2016-12-14 14:08:17.029 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:17.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:17.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 21 (UnionRDD[96] at union at DStream.scala:617)
2016-12-14 14:08:17.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 21.0 with 1 tasks
2016-12-14 14:08:17.030 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 21.0 (TID 21, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:17.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 21)
2016-12-14 14:08:17.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 21). 1159 bytes result sent to driver
2016-12-14 14:08:17.034 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 21.0 (TID 21) in 4 ms on localhost (1/1)
2016-12-14 14:08:17.034 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 21 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 22)
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:17.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 22 (MapPartitionsRDD[99] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:17.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 3.7 KB, free 230.3 KB)
2016-12-14 14:08:17.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 2.1 KB, free 232.4 KB)
2016-12-14 14:08:17.039 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:17.039 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:17.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[99] at count at LogStream.java:120)
2016-12-14 14:08:17.039 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 22.0 with 1 tasks
2016-12-14 14:08:17.040 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 22.0 (TID 22, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:17.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 22.0 (TID 22)
2016-12-14 14:08:17.042 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:17.043 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:17.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 22.0 (TID 22). 1241 bytes result sent to driver
2016-12-14 14:08:17.045 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 22.0 (TID 22) in 5 ms on localhost (1/1)
2016-12-14 14:08:17.046 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-12-14 14:08:17.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 22 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:17.046 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: take at LogStream.java:127, took 0.023723 s
2016-12-14 14:08:17.052 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695697000 ms.1 from job set of time 1481695697000 ms
2016-12-14 14:08:17.053 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 82 from persistence list
2016-12-14 14:08:17.053 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.052 s for time 1481695697000 ms (execution: 0.036 s)
2016-12-14 14:08:17.053 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 82
2016-12-14 14:08:17.053 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[82] at createStream at LogStream.java:100 of time 1481695697000 ms
2016-12-14 14:08:17.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 90 from persistence list
2016-12-14 14:08:17.054 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 90
2016-12-14 14:08:17.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 89 from persistence list
2016-12-14 14:08:17.055 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 89
2016-12-14 14:08:17.055 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 88 from persistence list
2016-12-14 14:08:17.056 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 88
2016-12-14 14:08:17.056 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 87 from persistence list
2016-12-14 14:08:17.056 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 87
2016-12-14 14:08:17.056 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 85 from persistence list
2016-12-14 14:08:17.057 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 85
2016-12-14 14:08:17.057 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 84 from persistence list
2016-12-14 14:08:17.057 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 84
2016-12-14 14:08:17.058 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 83 from persistence list
2016-12-14 14:08:17.058 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695695000 ms)
2016-12-14 14:08:17.058 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 83
2016-12-14 14:08:17.059 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695695000 ms
2016-12-14 14:08:18.017 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695698000 ms
2016-12-14 14:08:18.020 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695698000 ms.0 from job set of time 1481695698000 ms
2016-12-14 14:08:18.021 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695698000 ms.0 from job set of time 1481695698000 ms
2016-12-14 14:08:18.021 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695698000 ms.1 from job set of time 1481695698000 ms
2016-12-14 14:08:18.026 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:18.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 105 (union at DStream.scala:617)
2016-12-14 14:08:18.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:18.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 24 (take at LogStream.java:127)
2016-12-14 14:08:18.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 23)
2016-12-14 14:08:18.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 23)
2016-12-14 14:08:18.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 23 (UnionRDD[105] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:18.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 4.2 KB, free 236.6 KB)
2016-12-14 14:08:18.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.4 KB, free 239.0 KB)
2016-12-14 14:08:18.038 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_23_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:18.039 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:18.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 23 (UnionRDD[105] at union at DStream.scala:617)
2016-12-14 14:08:18.039 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 23.0 with 1 tasks
2016-12-14 14:08:18.040 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 23.0 (TID 23, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:18.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 23.0 (TID 23)
2016-12-14 14:08:18.047 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 23.0 (TID 23). 1159 bytes result sent to driver
2016-12-14 14:08:18.048 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 23.0 (TID 23) in 9 ms on localhost (1/1)
2016-12-14 14:08:18.048 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-12-14 14:08:18.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 23 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:08:18.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:18.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:18.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 24)
2016-12-14 14:08:18.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:18.050 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 24 (MapPartitionsRDD[108] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:18.052 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 242.7 KB)
2016-12-14 14:08:18.059 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.1 KB, free 244.8 KB)
2016-12-14 14:08:18.060 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_24_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:18.060 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:18.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[108] at count at LogStream.java:120)
2016-12-14 14:08:18.061 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 24.0 with 1 tasks
2016-12-14 14:08:18.062 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 24.0 (TID 24, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:18.062 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 24.0 (TID 24)
2016-12-14 14:08:18.064 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:18.064 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:18.065 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 24.0 (TID 24). 1241 bytes result sent to driver
2016-12-14 14:08:18.067 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 24.0 (TID 24) in 6 ms on localhost (1/1)
2016-12-14 14:08:18.067 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 24 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:18.067 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-12-14 14:08:18.068 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: take at LogStream.java:127, took 0.041910 s
2016-12-14 14:08:18.076 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695698000 ms.1 from job set of time 1481695698000 ms
2016-12-14 14:08:18.076 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.076 s for time 1481695698000 ms (execution: 0.056 s)
2016-12-14 14:08:18.077 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 91 from persistence list
2016-12-14 14:08:18.078 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 91
2016-12-14 14:08:18.078 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[91] at createStream at LogStream.java:100 of time 1481695698000 ms
2016-12-14 14:08:18.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 99 from persistence list
2016-12-14 14:08:18.080 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 99
2016-12-14 14:08:18.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 98 from persistence list
2016-12-14 14:08:18.080 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 98
2016-12-14 14:08:18.080 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 97 from persistence list
2016-12-14 14:08:18.081 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 97
2016-12-14 14:08:18.081 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 96 from persistence list
2016-12-14 14:08:18.081 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 96
2016-12-14 14:08:18.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 94 from persistence list
2016-12-14 14:08:18.082 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 94
2016-12-14 14:08:18.082 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 93 from persistence list
2016-12-14 14:08:18.082 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 93
2016-12-14 14:08:18.082 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 92 from persistence list
2016-12-14 14:08:18.083 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 92
2016-12-14 14:08:18.083 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695696000 ms)
2016-12-14 14:08:18.083 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695696000 ms
2016-12-14 14:08:19.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695699000 ms
2016-12-14 14:08:19.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695699000 ms.0 from job set of time 1481695699000 ms
2016-12-14 14:08:19.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695699000 ms.0 from job set of time 1481695699000 ms
2016-12-14 14:08:19.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695699000 ms.1 from job set of time 1481695699000 ms
2016-12-14 14:08:19.020 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:19.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 114 (union at DStream.scala:617)
2016-12-14 14:08:19.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:19.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 26 (take at LogStream.java:127)
2016-12-14 14:08:19.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 25)
2016-12-14 14:08:19.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 25)
2016-12-14 14:08:19.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 25 (UnionRDD[114] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:19.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 4.2 KB, free 249.0 KB)
2016-12-14 14:08:19.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.4 KB, free 251.5 KB)
2016-12-14 14:08:19.032 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_25_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:19.033 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:19.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 25 (UnionRDD[114] at union at DStream.scala:617)
2016-12-14 14:08:19.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 25.0 with 1 tasks
2016-12-14 14:08:19.036 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 25.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:19.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 25.0 (TID 25)
2016-12-14 14:08:19.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 25.0 (TID 25). 1159 bytes result sent to driver
2016-12-14 14:08:19.042 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 25.0 (TID 25) in 6 ms on localhost (1/1)
2016-12-14 14:08:19.042 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-12-14 14:08:19.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 25 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:19.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:19.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:19.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 26)
2016-12-14 14:08:19.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:19.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 26 (MapPartitionsRDD[117] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:19.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 255.2 KB)
2016-12-14 14:08:19.049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.1 KB, free 257.3 KB)
2016-12-14 14:08:19.050 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_26_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:19.051 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:19.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[117] at count at LogStream.java:120)
2016-12-14 14:08:19.052 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 26.0 with 1 tasks
2016-12-14 14:08:19.053 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 26.0 (TID 26, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:19.054 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 26.0 (TID 26)
2016-12-14 14:08:19.055 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:19.056 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:19.057 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 26.0 (TID 26). 1241 bytes result sent to driver
2016-12-14 14:08:19.059 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 26.0 (TID 26) in 6 ms on localhost (1/1)
2016-12-14 14:08:19.059 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-12-14 14:08:19.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 26 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:19.060 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: take at LogStream.java:127, took 0.039965 s
2016-12-14 14:08:19.067 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695699000 ms.1 from job set of time 1481695699000 ms
2016-12-14 14:08:19.067 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 100 from persistence list
2016-12-14 14:08:19.067 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.067 s for time 1481695699000 ms (execution: 0.053 s)
2016-12-14 14:08:19.068 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 100
2016-12-14 14:08:19.069 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[100] at createStream at LogStream.java:100 of time 1481695699000 ms
2016-12-14 14:08:19.069 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 108 from persistence list
2016-12-14 14:08:19.069 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 108
2016-12-14 14:08:19.069 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 107 from persistence list
2016-12-14 14:08:19.070 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 107
2016-12-14 14:08:19.070 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 106 from persistence list
2016-12-14 14:08:19.070 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 106
2016-12-14 14:08:19.070 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 105 from persistence list
2016-12-14 14:08:19.070 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 105
2016-12-14 14:08:19.070 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 103 from persistence list
2016-12-14 14:08:19.071 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 103
2016-12-14 14:08:19.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 102 from persistence list
2016-12-14 14:08:19.071 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 102
2016-12-14 14:08:19.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 101 from persistence list
2016-12-14 14:08:19.071 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 101
2016-12-14 14:08:19.072 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695697000 ms)
2016-12-14 14:08:19.072 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695697000 ms
2016-12-14 14:08:20.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695700000 ms.0 from job set of time 1481695700000 ms
2016-12-14 14:08:20.015 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695700000 ms
2016-12-14 14:08:20.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695700000 ms.0 from job set of time 1481695700000 ms
2016-12-14 14:08:20.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695700000 ms.1 from job set of time 1481695700000 ms
2016-12-14 14:08:20.025 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:20.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 123 (union at DStream.scala:617)
2016-12-14 14:08:20.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:20.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 28 (take at LogStream.java:127)
2016-12-14 14:08:20.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 27)
2016-12-14 14:08:20.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 27)
2016-12-14 14:08:20.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 27 (UnionRDD[123] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:20.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 4.2 KB, free 261.5 KB)
2016-12-14 14:08:20.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.4 KB, free 263.9 KB)
2016-12-14 14:08:20.039 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_27_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:20.040 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:20.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 27 (UnionRDD[123] at union at DStream.scala:617)
2016-12-14 14:08:20.040 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 27.0 with 1 tasks
2016-12-14 14:08:20.042 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 27.0 (TID 27, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:20.045 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 27.0 (TID 27)
2016-12-14 14:08:20.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 27.0 (TID 27). 1159 bytes result sent to driver
2016-12-14 14:08:20.052 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 27.0 (TID 27) in 10 ms on localhost (1/1)
2016-12-14 14:08:20.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 27 (union at DStream.scala:617) finished in 0.011 s
2016-12-14 14:08:20.052 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-12-14 14:08:20.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:20.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:20.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 28)
2016-12-14 14:08:20.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:20.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 28 (MapPartitionsRDD[126] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:20.054 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 3.7 KB, free 267.6 KB)
2016-12-14 14:08:20.058 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 2.1 KB, free 269.7 KB)
2016-12-14 14:08:20.059 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_28_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:20.059 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:20.059 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[126] at count at LogStream.java:120)
2016-12-14 14:08:20.060 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 28.0 with 1 tasks
2016-12-14 14:08:20.061 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 28.0 (TID 28, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:20.061 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 28.0 (TID 28)
2016-12-14 14:08:20.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:20.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:20.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 28.0 (TID 28). 1241 bytes result sent to driver
2016-12-14 14:08:20.065 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 28.0 (TID 28) in 5 ms on localhost (1/1)
2016-12-14 14:08:20.065 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-12-14 14:08:20.066 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 28 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:20.066 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: take at LogStream.java:127, took 0.040206 s
2016-12-14 14:08:20.075 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695700000 ms.1 from job set of time 1481695700000 ms
2016-12-14 14:08:20.076 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.075 s for time 1481695700000 ms (execution: 0.059 s)
2016-12-14 14:08:20.076 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 109 from persistence list
2016-12-14 14:08:20.076 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 109
2016-12-14 14:08:20.077 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[109] at createStream at LogStream.java:100 of time 1481695700000 ms
2016-12-14 14:08:20.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 117 from persistence list
2016-12-14 14:08:20.077 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 117
2016-12-14 14:08:20.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 116 from persistence list
2016-12-14 14:08:20.077 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 116
2016-12-14 14:08:20.078 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 115 from persistence list
2016-12-14 14:08:20.078 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 115
2016-12-14 14:08:20.078 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 114 from persistence list
2016-12-14 14:08:20.078 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 114
2016-12-14 14:08:20.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 112 from persistence list
2016-12-14 14:08:20.079 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 112
2016-12-14 14:08:20.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 111 from persistence list
2016-12-14 14:08:20.079 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 111
2016-12-14 14:08:20.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 110 from persistence list
2016-12-14 14:08:20.079 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 110
2016-12-14 14:08:20.079 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695698000 ms)
2016-12-14 14:08:20.079 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695698000 ms
2016-12-14 14:08:21.024 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695701000 ms
2016-12-14 14:08:21.025 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695701000 ms.0 from job set of time 1481695701000 ms
2016-12-14 14:08:21.031 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:21.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695701000 ms.0 from job set of time 1481695701000 ms
2016-12-14 14:08:21.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695701000 ms.1 from job set of time 1481695701000 ms
2016-12-14 14:08:21.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 132 (union at DStream.scala:617)
2016-12-14 14:08:21.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:21.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 30 (take at LogStream.java:127)
2016-12-14 14:08:21.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 29)
2016-12-14 14:08:21.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 29)
2016-12-14 14:08:21.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 29 (UnionRDD[132] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:21.036 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 4.2 KB, free 273.9 KB)
2016-12-14 14:08:21.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 KB, free 276.4 KB)
2016-12-14 14:08:21.043 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_29_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:21.044 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:21.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 29 (UnionRDD[132] at union at DStream.scala:617)
2016-12-14 14:08:21.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 29.0 with 1 tasks
2016-12-14 14:08:21.047 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 29.0 (TID 29, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:21.048 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 29.0 (TID 29)
2016-12-14 14:08:21.052 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 29.0 (TID 29). 1159 bytes result sent to driver
2016-12-14 14:08:21.052 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 29.0 (TID 29) in 7 ms on localhost (1/1)
2016-12-14 14:08:21.053 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 29 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 30)
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:21.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 30 (MapPartitionsRDD[135] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:21.055 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_30 stored as values in memory (estimated size 3.7 KB, free 280.1 KB)
2016-12-14 14:08:21.059 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.1 KB, free 282.2 KB)
2016-12-14 14:08:21.059 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_30_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:21.059 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:21.060 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[135] at count at LogStream.java:120)
2016-12-14 14:08:21.060 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 30.0 with 1 tasks
2016-12-14 14:08:21.060 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 30.0 (TID 30, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:21.061 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 30.0 (TID 30)
2016-12-14 14:08:21.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:21.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:21.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 30.0 (TID 30). 1241 bytes result sent to driver
2016-12-14 14:08:21.065 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 30.0 (TID 30) in 5 ms on localhost (1/1)
2016-12-14 14:08:21.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 30 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:21.065 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-12-14 14:08:21.065 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: take at LogStream.java:127, took 0.033762 s
2016-12-14 14:08:21.071 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695701000 ms.1 from job set of time 1481695701000 ms
2016-12-14 14:08:21.071 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.071 s for time 1481695701000 ms (execution: 0.047 s)
2016-12-14 14:08:21.071 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 118 from persistence list
2016-12-14 14:08:21.072 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 118
2016-12-14 14:08:21.072 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[118] at createStream at LogStream.java:100 of time 1481695701000 ms
2016-12-14 14:08:21.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 126 from persistence list
2016-12-14 14:08:21.073 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 126
2016-12-14 14:08:21.073 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 125 from persistence list
2016-12-14 14:08:21.073 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 125
2016-12-14 14:08:21.073 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 124 from persistence list
2016-12-14 14:08:21.073 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 124
2016-12-14 14:08:21.074 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 123 from persistence list
2016-12-14 14:08:21.074 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 123
2016-12-14 14:08:21.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 121 from persistence list
2016-12-14 14:08:21.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 121
2016-12-14 14:08:21.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 120 from persistence list
2016-12-14 14:08:21.074 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 120
2016-12-14 14:08:21.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 119 from persistence list
2016-12-14 14:08:21.075 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 119
2016-12-14 14:08:21.075 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695699000 ms)
2016-12-14 14:08:21.075 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695699000 ms
2016-12-14 14:08:22.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695702000 ms
2016-12-14 14:08:22.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695702000 ms.0 from job set of time 1481695702000 ms
2016-12-14 14:08:22.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695702000 ms.0 from job set of time 1481695702000 ms
2016-12-14 14:08:22.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695702000 ms.1 from job set of time 1481695702000 ms
2016-12-14 14:08:22.017 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:22.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 141 (union at DStream.scala:617)
2016-12-14 14:08:22.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:22.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 32 (take at LogStream.java:127)
2016-12-14 14:08:22.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 31)
2016-12-14 14:08:22.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 31)
2016-12-14 14:08:22.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 31 (UnionRDD[141] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:22.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_31 stored as values in memory (estimated size 4.2 KB, free 286.4 KB)
2016-12-14 14:08:22.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.4 KB, free 288.8 KB)
2016-12-14 14:08:22.027 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_31_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:22.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:22.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 31 (UnionRDD[141] at union at DStream.scala:617)
2016-12-14 14:08:22.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 31.0 with 1 tasks
2016-12-14 14:08:22.037 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 31.0 (TID 31, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:22.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 31.0 (TID 31)
2016-12-14 14:08:22.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 31.0 (TID 31). 1159 bytes result sent to driver
2016-12-14 14:08:22.044 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 31.0 (TID 31) in 8 ms on localhost (1/1)
2016-12-14 14:08:22.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 31 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:08:22.045 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-12-14 14:08:22.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:22.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:22.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 32)
2016-12-14 14:08:22.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:22.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 32 (MapPartitionsRDD[144] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:22.047 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_32 stored as values in memory (estimated size 3.7 KB, free 292.5 KB)
2016-12-14 14:08:22.051 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.1 KB, free 294.6 KB)
2016-12-14 14:08:22.052 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_32_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:22.053 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:22.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[144] at count at LogStream.java:120)
2016-12-14 14:08:22.053 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 32.0 with 1 tasks
2016-12-14 14:08:22.060 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 32.0 (TID 32, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:22.060 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 32.0 (TID 32)
2016-12-14 14:08:22.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:22.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:22.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 32.0 (TID 32). 1241 bytes result sent to driver
2016-12-14 14:08:22.065 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 32.0 (TID 32) in 5 ms on localhost (1/1)
2016-12-14 14:08:22.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 32 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:08:22.065 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-12-14 14:08:22.065 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: take at LogStream.java:127, took 0.047621 s
2016-12-14 14:08:22.071 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695702000 ms.1 from job set of time 1481695702000 ms
2016-12-14 14:08:22.071 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 127 from persistence list
2016-12-14 14:08:22.071 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.071 s for time 1481695702000 ms (execution: 0.058 s)
2016-12-14 14:08:22.071 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 127
2016-12-14 14:08:22.071 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[127] at createStream at LogStream.java:100 of time 1481695702000 ms
2016-12-14 14:08:22.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 135 from persistence list
2016-12-14 14:08:22.072 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 135
2016-12-14 14:08:22.072 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 134 from persistence list
2016-12-14 14:08:22.072 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 134
2016-12-14 14:08:22.072 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 133 from persistence list
2016-12-14 14:08:22.073 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 133
2016-12-14 14:08:22.073 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 132 from persistence list
2016-12-14 14:08:22.073 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 132
2016-12-14 14:08:22.073 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 130 from persistence list
2016-12-14 14:08:22.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 130
2016-12-14 14:08:22.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 129 from persistence list
2016-12-14 14:08:22.075 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 129
2016-12-14 14:08:22.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 128 from persistence list
2016-12-14 14:08:22.076 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 128
2016-12-14 14:08:22.077 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695700000 ms)
2016-12-14 14:08:22.077 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695700000 ms
2016-12-14 14:08:23.015 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695703000 ms
2016-12-14 14:08:23.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695703000 ms.0 from job set of time 1481695703000 ms
2016-12-14 14:08:23.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695703000 ms.0 from job set of time 1481695703000 ms
2016-12-14 14:08:23.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695703000 ms.1 from job set of time 1481695703000 ms
2016-12-14 14:08:23.020 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:23.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 150 (union at DStream.scala:617)
2016-12-14 14:08:23.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 17 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:23.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 34 (take at LogStream.java:127)
2016-12-14 14:08:23.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 33)
2016-12-14 14:08:23.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 33)
2016-12-14 14:08:23.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 33 (UnionRDD[150] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:23.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_33 stored as values in memory (estimated size 4.2 KB, free 298.8 KB)
2016-12-14 14:08:23.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.4 KB, free 301.3 KB)
2016-12-14 14:08:23.034 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_33_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:23.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:23.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 33 (UnionRDD[150] at union at DStream.scala:617)
2016-12-14 14:08:23.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 33.0 with 1 tasks
2016-12-14 14:08:23.036 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 33.0 (TID 33, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:23.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 33.0 (TID 33)
2016-12-14 14:08:23.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 33.0 (TID 33). 1159 bytes result sent to driver
2016-12-14 14:08:23.042 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 33.0 (TID 33) in 6 ms on localhost (1/1)
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 33 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:08:23.042 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 34)
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:23.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 34 (MapPartitionsRDD[153] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:23.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_34 stored as values in memory (estimated size 3.7 KB, free 305.0 KB)
2016-12-14 14:08:23.048 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 2.1 KB, free 307.1 KB)
2016-12-14 14:08:23.048 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_34_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:23.049 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:23.049 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[153] at count at LogStream.java:120)
2016-12-14 14:08:23.049 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 34.0 with 1 tasks
2016-12-14 14:08:23.050 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 34.0 (TID 34, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:23.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 34.0 (TID 34)
2016-12-14 14:08:23.052 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:23.053 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:23.057 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 34.0 (TID 34). 1241 bytes result sent to driver
2016-12-14 14:08:23.062 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 34.0 (TID 34) in 12 ms on localhost (1/1)
2016-12-14 14:08:23.062 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-12-14 14:08:23.063 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 34 (take at LogStream.java:127) finished in 0.013 s
2016-12-14 14:08:23.064 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 finished: take at LogStream.java:127, took 0.043575 s
2016-12-14 14:08:23.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695703000 ms.1 from job set of time 1481695703000 ms
2016-12-14 14:08:23.070 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.070 s for time 1481695703000 ms (execution: 0.055 s)
2016-12-14 14:08:23.070 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 136 from persistence list
2016-12-14 14:08:23.071 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 136
2016-12-14 14:08:23.071 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[136] at createStream at LogStream.java:100 of time 1481695703000 ms
2016-12-14 14:08:23.071 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 144 from persistence list
2016-12-14 14:08:23.072 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 144
2016-12-14 14:08:23.073 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 143 from persistence list
2016-12-14 14:08:23.074 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 143
2016-12-14 14:08:23.077 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 142 from persistence list
2016-12-14 14:08:23.078 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 142
2016-12-14 14:08:23.078 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 141 from persistence list
2016-12-14 14:08:23.079 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 141
2016-12-14 14:08:23.079 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 139 from persistence list
2016-12-14 14:08:23.080 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 139
2016-12-14 14:08:23.080 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 138 from persistence list
2016-12-14 14:08:23.081 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 138
2016-12-14 14:08:23.081 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 137 from persistence list
2016-12-14 14:08:23.081 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 137
2016-12-14 14:08:23.082 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695701000 ms)
2016-12-14 14:08:23.082 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695701000 ms
2016-12-14 14:08:24.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695704000 ms
2016-12-14 14:08:24.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695704000 ms.0 from job set of time 1481695704000 ms
2016-12-14 14:08:24.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695704000 ms.0 from job set of time 1481695704000 ms
2016-12-14 14:08:24.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695704000 ms.1 from job set of time 1481695704000 ms
2016-12-14 14:08:24.017 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:24.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 159 (union at DStream.scala:617)
2016-12-14 14:08:24.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:24.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 36 (take at LogStream.java:127)
2016-12-14 14:08:24.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 35)
2016-12-14 14:08:24.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 35)
2016-12-14 14:08:24.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 35 (UnionRDD[159] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:24.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 4.2 KB, free 311.3 KB)
2016-12-14 14:08:24.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.4 KB, free 313.7 KB)
2016-12-14 14:08:24.023 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_35_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:24.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:24.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 35 (UnionRDD[159] at union at DStream.scala:617)
2016-12-14 14:08:24.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 35.0 with 1 tasks
2016-12-14 14:08:24.025 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 35.0 (TID 35, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:24.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 35.0 (TID 35)
2016-12-14 14:08:24.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 35.0 (TID 35). 1159 bytes result sent to driver
2016-12-14 14:08:24.031 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 35.0 (TID 35) in 6 ms on localhost (1/1)
2016-12-14 14:08:24.032 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-12-14 14:08:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 35 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 36)
2016-12-14 14:08:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:24.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 36 (MapPartitionsRDD[162] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:24.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_36 stored as values in memory (estimated size 3.7 KB, free 317.4 KB)
2016-12-14 14:08:24.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.1 KB, free 319.5 KB)
2016-12-14 14:08:24.047 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_36_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:24.047 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 36 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:24.048 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[162] at count at LogStream.java:120)
2016-12-14 14:08:24.048 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 36.0 with 1 tasks
2016-12-14 14:08:24.049 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 36.0 (TID 36, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:24.049 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 36.0 (TID 36)
2016-12-14 14:08:24.050 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:24.051 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:24.051 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 36.0 (TID 36). 1241 bytes result sent to driver
2016-12-14 14:08:24.052 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 36.0 (TID 36) in 4 ms on localhost (1/1)
2016-12-14 14:08:24.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 36 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:24.052 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-12-14 14:08:24.053 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: take at LogStream.java:127, took 0.035591 s
2016-12-14 14:08:24.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695704000 ms.1 from job set of time 1481695704000 ms
2016-12-14 14:08:24.060 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 145 from persistence list
2016-12-14 14:08:24.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.060 s for time 1481695704000 ms (execution: 0.048 s)
2016-12-14 14:08:24.060 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 145
2016-12-14 14:08:24.061 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[145] at createStream at LogStream.java:100 of time 1481695704000 ms
2016-12-14 14:08:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 153 from persistence list
2016-12-14 14:08:24.061 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 153
2016-12-14 14:08:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 152 from persistence list
2016-12-14 14:08:24.062 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 151 from persistence list
2016-12-14 14:08:24.062 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 152
2016-12-14 14:08:24.062 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 150 from persistence list
2016-12-14 14:08:24.063 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 151
2016-12-14 14:08:24.064 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 150
2016-12-14 14:08:24.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 148 from persistence list
2016-12-14 14:08:24.064 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 148
2016-12-14 14:08:24.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 147 from persistence list
2016-12-14 14:08:24.065 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 147
2016-12-14 14:08:24.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 146 from persistence list
2016-12-14 14:08:24.065 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 146
2016-12-14 14:08:24.066 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695702000 ms)
2016-12-14 14:08:24.066 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695702000 ms
2016-12-14 14:08:25.018 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695705000 ms
2016-12-14 14:08:25.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695705000 ms.0 from job set of time 1481695705000 ms
2016-12-14 14:08:25.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695705000 ms.0 from job set of time 1481695705000 ms
2016-12-14 14:08:25.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695705000 ms.1 from job set of time 1481695705000 ms
2016-12-14 14:08:25.023 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:25.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 168 (union at DStream.scala:617)
2016-12-14 14:08:25.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:25.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 38 (take at LogStream.java:127)
2016-12-14 14:08:25.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 37)
2016-12-14 14:08:25.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 37)
2016-12-14 14:08:25.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 37 (UnionRDD[168] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:25.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_37 stored as values in memory (estimated size 4.2 KB, free 323.7 KB)
2016-12-14 14:08:25.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.4 KB, free 326.2 KB)
2016-12-14 14:08:25.033 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_37_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:25.033 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 37 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:25.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 37 (UnionRDD[168] at union at DStream.scala:617)
2016-12-14 14:08:25.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 37.0 with 1 tasks
2016-12-14 14:08:25.035 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 37.0 (TID 37, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:25.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 37.0 (TID 37)
2016-12-14 14:08:25.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 37.0 (TID 37). 1159 bytes result sent to driver
2016-12-14 14:08:25.041 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 37.0 (TID 37) in 6 ms on localhost (1/1)
2016-12-14 14:08:25.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 37 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:25.041 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-12-14 14:08:25.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:25.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:25.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 38)
2016-12-14 14:08:25.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:25.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 38 (MapPartitionsRDD[171] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:25.045 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_38 stored as values in memory (estimated size 3.7 KB, free 329.9 KB)
2016-12-14 14:08:25.049 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.1 KB, free 332.0 KB)
2016-12-14 14:08:25.049 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_38_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:25.052 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 38 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:25.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[171] at count at LogStream.java:120)
2016-12-14 14:08:25.052 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 38.0 with 1 tasks
2016-12-14 14:08:25.060 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 38.0 (TID 38, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:25.061 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 38.0 (TID 38)
2016-12-14 14:08:25.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:25.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:25.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 38.0 (TID 38). 1241 bytes result sent to driver
2016-12-14 14:08:25.065 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 38.0 (TID 38) in 5 ms on localhost (1/1)
2016-12-14 14:08:25.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 38 (take at LogStream.java:127) finished in 0.013 s
2016-12-14 14:08:25.065 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-12-14 14:08:25.065 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: take at LogStream.java:127, took 0.042264 s
2016-12-14 14:08:25.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695705000 ms.1 from job set of time 1481695705000 ms
2016-12-14 14:08:25.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.072 s for time 1481695705000 ms (execution: 0.054 s)
2016-12-14 14:08:25.072 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 154 from persistence list
2016-12-14 14:08:25.073 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 154
2016-12-14 14:08:25.074 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[154] at createStream at LogStream.java:100 of time 1481695705000 ms
2016-12-14 14:08:25.074 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 162 from persistence list
2016-12-14 14:08:25.074 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 162
2016-12-14 14:08:25.075 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 161 from persistence list
2016-12-14 14:08:25.075 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 161
2016-12-14 14:08:25.075 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 160 from persistence list
2016-12-14 14:08:25.076 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 160
2016-12-14 14:08:25.076 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 159 from persistence list
2016-12-14 14:08:25.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 157 from persistence list
2016-12-14 14:08:25.077 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 159
2016-12-14 14:08:25.077 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 157
2016-12-14 14:08:25.077 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 156 from persistence list
2016-12-14 14:08:25.078 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 156
2016-12-14 14:08:25.078 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 155 from persistence list
2016-12-14 14:08:25.078 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 155
2016-12-14 14:08:25.078 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695703000 ms)
2016-12-14 14:08:25.079 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695703000 ms
2016-12-14 14:08:26.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695706000 ms
2016-12-14 14:08:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695706000 ms.0 from job set of time 1481695706000 ms
2016-12-14 14:08:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695706000 ms.0 from job set of time 1481695706000 ms
2016-12-14 14:08:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695706000 ms.1 from job set of time 1481695706000 ms
2016-12-14 14:08:26.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:26.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 177 (union at DStream.scala:617)
2016-12-14 14:08:26.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 20 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:26.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 40 (take at LogStream.java:127)
2016-12-14 14:08:26.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 39)
2016-12-14 14:08:26.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 39)
2016-12-14 14:08:26.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 39 (UnionRDD[177] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:26.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_39 stored as values in memory (estimated size 4.2 KB, free 336.2 KB)
2016-12-14 14:08:26.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.4 KB, free 338.6 KB)
2016-12-14 14:08:26.043 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_39_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.043 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 39 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:26.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 39 (UnionRDD[177] at union at DStream.scala:617)
2016-12-14 14:08:26.044 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 39.0 with 1 tasks
2016-12-14 14:08:26.044 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.044 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 39.0 (TID 39, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:26.045 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 39.0 (TID 39)
2016-12-14 14:08:26.047 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 20
2016-12-14 14:08:26.050 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 39.0 (TID 39). 1159 bytes result sent to driver
2016-12-14 14:08:26.051 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 39.0 (TID 39) in 7 ms on localhost (1/1)
2016-12-14 14:08:26.051 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-12-14 14:08:26.052 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 9
2016-12-14 14:08:26.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 39 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:26.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:26.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:26.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 40)
2016-12-14 14:08:26.052 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:26.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 40 (MapPartitionsRDD[180] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:26.054 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_18_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.054 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_40 stored as values in memory (estimated size 3.7 KB, free 330.7 KB)
2016-12-14 14:08:26.055 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 19
2016-12-14 14:08:26.055 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_40_piece0 stored as bytes in memory (estimated size 2.1 KB, free 332.8 KB)
2016-12-14 14:08:26.056 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_40_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.056 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.056 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 40 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:26.057 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[180] at count at LogStream.java:120)
2016-12-14 14:08:26.057 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 40.0 with 1 tasks
2016-12-14 14:08:26.057 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 18
2016-12-14 14:08:26.057 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 8
2016-12-14 14:08:26.058 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 17
2016-12-14 14:08:26.058 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 40.0 (TID 40, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:26.060 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 40.0 (TID 40)
2016-12-14 14:08:26.061 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.062 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:26.063 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:26.063 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 16
2016-12-14 14:08:26.063 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 7
2016-12-14 14:08:26.064 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 40.0 (TID 40). 1241 bytes result sent to driver
2016-12-14 14:08:26.065 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 40.0 (TID 40) in 6 ms on localhost (1/1)
2016-12-14 14:08:26.065 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.065 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-12-14 14:08:26.065 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 40 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:08:26.065 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 finished: take at LogStream.java:127, took 0.045684 s
2016-12-14 14:08:26.066 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 15
2016-12-14 14:08:26.068 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.069 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 14
2016-12-14 14:08:26.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 6
2016-12-14 14:08:26.071 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695706000 ms.1 from job set of time 1481695706000 ms
2016-12-14 14:08:26.072 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.071 s for time 1481695706000 ms (execution: 0.058 s)
2016-12-14 14:08:26.072 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.072 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 13
2016-12-14 14:08:26.073 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.074 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 12
2016-12-14 14:08:26.076 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 5
2016-12-14 14:08:26.077 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.078 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 11
2016-12-14 14:08:26.079 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.080 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 10
2016-12-14 14:08:26.080 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 4
2016-12-14 14:08:26.081 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.082 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 9
2016-12-14 14:08:26.082 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 8
2016-12-14 14:08:26.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 3
2016-12-14 14:08:26.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 15
2016-12-14 14:08:26.084 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_30_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.085 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 31
2016-12-14 14:08:26.086 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_29_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.086 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 163 from persistence list
2016-12-14 14:08:26.086 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 163
2016-12-14 14:08:26.086 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 30
2016-12-14 14:08:26.087 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 14
2016-12-14 14:08:26.087 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[163] at createStream at LogStream.java:100 of time 1481695706000 ms
2016-12-14 14:08:26.087 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 171 from persistence list
2016-12-14 14:08:26.087 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_28_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.088 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 171
2016-12-14 14:08:26.088 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 29
2016-12-14 14:08:26.088 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 170 from persistence list
2016-12-14 14:08:26.089 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_27_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.089 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 170
2016-12-14 14:08:26.089 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 28
2016-12-14 14:08:26.090 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 13
2016-12-14 14:08:26.090 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 169 from persistence list
2016-12-14 14:08:26.090 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_26_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.091 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 169
2016-12-14 14:08:26.091 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 27
2016-12-14 14:08:26.091 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 168 from persistence list
2016-12-14 14:08:26.091 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_25_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.092 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 168
2016-12-14 14:08:26.092 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 26
2016-12-14 14:08:26.092 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 12
2016-12-14 14:08:26.093 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 166 from persistence list
2016-12-14 14:08:26.093 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_24_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.093 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 166
2016-12-14 14:08:26.093 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 25
2016-12-14 14:08:26.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 165 from persistence list
2016-12-14 14:08:26.094 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 165
2016-12-14 14:08:26.094 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_23_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.094 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 164 from persistence list
2016-12-14 14:08:26.095 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 24
2016-12-14 14:08:26.095 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 164
2016-12-14 14:08:26.095 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 11
2016-12-14 14:08:26.095 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_22_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.095 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695704000 ms)
2016-12-14 14:08:26.096 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695704000 ms
2016-12-14 14:08:26.096 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 23
2016-12-14 14:08:26.097 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_21_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.097 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 22
2016-12-14 14:08:26.098 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 10
2016-12-14 14:08:26.099 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_20_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.099 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 21
2016-12-14 14:08:26.100 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_19_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.101 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.102 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 7
2016-12-14 14:08:26.102 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.103 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 6
2016-12-14 14:08:26.103 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 2
2016-12-14 14:08:26.104 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.104 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 5
2016-12-14 14:08:26.105 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.106 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 4
2016-12-14 14:08:26.106 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 1
2016-12-14 14:08:26.107 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_38_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.107 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 39
2016-12-14 14:08:26.108 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_37_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.109 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 38
2016-12-14 14:08:26.110 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_36_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.110 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 37
2016-12-14 14:08:26.111 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_35_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.111 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 36
2016-12-14 14:08:26.112 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 17
2016-12-14 14:08:26.113 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_34_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.113 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 35
2016-12-14 14:08:26.114 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_33_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.114 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 34
2016-12-14 14:08:26.115 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 16
2016-12-14 14:08:26.116 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_32_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:26.116 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 33
2016-12-14 14:08:26.117 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_31_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:26.117 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 32
2016-12-14 14:08:27.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695707000 ms
2016-12-14 14:08:27.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695707000 ms.0 from job set of time 1481695707000 ms
2016-12-14 14:08:27.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695707000 ms.0 from job set of time 1481695707000 ms
2016-12-14 14:08:27.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695707000 ms.1 from job set of time 1481695707000 ms
2016-12-14 14:08:27.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:27.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 186 (union at DStream.scala:617)
2016-12-14 14:08:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 21 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 42 (take at LogStream.java:127)
2016-12-14 14:08:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 41)
2016-12-14 14:08:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 41)
2016-12-14 14:08:27.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 41 (UnionRDD[186] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:27.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_41 stored as values in memory (estimated size 4.2 KB, free 124.6 KB)
2016-12-14 14:08:27.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.4 KB, free 127.0 KB)
2016-12-14 14:08:27.023 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_41_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:27.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 41 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:27.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 41 (UnionRDD[186] at union at DStream.scala:617)
2016-12-14 14:08:27.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 41.0 with 1 tasks
2016-12-14 14:08:27.025 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 41.0 (TID 41, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:27.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 41.0 (TID 41)
2016-12-14 14:08:27.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 41.0 (TID 41). 1159 bytes result sent to driver
2016-12-14 14:08:27.030 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 41.0 (TID 41) in 5 ms on localhost (1/1)
2016-12-14 14:08:27.031 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 41 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 42)
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:27.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 42 (MapPartitionsRDD[189] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:27.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_42 stored as values in memory (estimated size 3.7 KB, free 130.7 KB)
2016-12-14 14:08:27.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.1 KB, free 132.8 KB)
2016-12-14 14:08:27.035 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_42_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:27.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 42 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:27.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[189] at count at LogStream.java:120)
2016-12-14 14:08:27.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 42.0 with 1 tasks
2016-12-14 14:08:27.036 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 42.0 (TID 42, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:27.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 42.0 (TID 42)
2016-12-14 14:08:27.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:27.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:27.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 42.0 (TID 42). 1241 bytes result sent to driver
2016-12-14 14:08:27.040 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 42.0 (TID 42) in 4 ms on localhost (1/1)
2016-12-14 14:08:27.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 42 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:27.040 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-12-14 14:08:27.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 21 finished: take at LogStream.java:127, took 0.021816 s
2016-12-14 14:08:27.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695707000 ms.1 from job set of time 1481695707000 ms
2016-12-14 14:08:27.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.046 s for time 1481695707000 ms (execution: 0.033 s)
2016-12-14 14:08:27.047 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 172 from persistence list
2016-12-14 14:08:27.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[172] at createStream at LogStream.java:100 of time 1481695707000 ms
2016-12-14 14:08:27.048 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 172
2016-12-14 14:08:27.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 180 from persistence list
2016-12-14 14:08:27.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 179 from persistence list
2016-12-14 14:08:27.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 180
2016-12-14 14:08:27.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 179
2016-12-14 14:08:27.049 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 178 from persistence list
2016-12-14 14:08:27.050 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 177 from persistence list
2016-12-14 14:08:27.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 178
2016-12-14 14:08:27.051 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 177
2016-12-14 14:08:27.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 175 from persistence list
2016-12-14 14:08:27.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 175
2016-12-14 14:08:27.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 174 from persistence list
2016-12-14 14:08:27.051 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 174
2016-12-14 14:08:27.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 173 from persistence list
2016-12-14 14:08:27.052 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 173
2016-12-14 14:08:27.052 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695705000 ms)
2016-12-14 14:08:27.052 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695705000 ms
2016-12-14 14:08:28.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695708000 ms
2016-12-14 14:08:28.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695708000 ms.0 from job set of time 1481695708000 ms
2016-12-14 14:08:28.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695708000 ms.0 from job set of time 1481695708000 ms
2016-12-14 14:08:28.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695708000 ms.1 from job set of time 1481695708000 ms
2016-12-14 14:08:28.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:28.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 195 (union at DStream.scala:617)
2016-12-14 14:08:28.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 22 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:28.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 44 (take at LogStream.java:127)
2016-12-14 14:08:28.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 43)
2016-12-14 14:08:28.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 43)
2016-12-14 14:08:28.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 43 (UnionRDD[195] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:28.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_43 stored as values in memory (estimated size 4.2 KB, free 137.0 KB)
2016-12-14 14:08:28.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.4 KB, free 139.4 KB)
2016-12-14 14:08:28.022 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_43_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:28.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 43 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:28.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 43 (UnionRDD[195] at union at DStream.scala:617)
2016-12-14 14:08:28.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 43.0 with 1 tasks
2016-12-14 14:08:28.024 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 43.0 (TID 43, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:28.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 43.0 (TID 43)
2016-12-14 14:08:28.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 43.0 (TID 43). 1159 bytes result sent to driver
2016-12-14 14:08:28.029 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 43.0 (TID 43) in 6 ms on localhost (1/1)
2016-12-14 14:08:28.029 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 43 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 44)
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:28.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 44 (MapPartitionsRDD[198] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:28.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_44 stored as values in memory (estimated size 3.7 KB, free 143.1 KB)
2016-12-14 14:08:28.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.1 KB, free 145.2 KB)
2016-12-14 14:08:28.034 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_44_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:28.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 44 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:28.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[198] at count at LogStream.java:120)
2016-12-14 14:08:28.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 44.0 with 1 tasks
2016-12-14 14:08:28.036 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 44.0 (TID 44, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:28.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 44.0 (TID 44)
2016-12-14 14:08:28.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:28.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:28.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 44.0 (TID 44). 1241 bytes result sent to driver
2016-12-14 14:08:28.040 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 44.0 (TID 44) in 4 ms on localhost (1/1)
2016-12-14 14:08:28.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 44 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:28.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-12-14 14:08:28.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 22 finished: take at LogStream.java:127, took 0.022340 s
2016-12-14 14:08:28.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695708000 ms.1 from job set of time 1481695708000 ms
2016-12-14 14:08:28.048 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 181 from persistence list
2016-12-14 14:08:28.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695708000 ms (execution: 0.033 s)
2016-12-14 14:08:28.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 181
2016-12-14 14:08:28.048 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[181] at createStream at LogStream.java:100 of time 1481695708000 ms
2016-12-14 14:08:28.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 189 from persistence list
2016-12-14 14:08:28.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 189
2016-12-14 14:08:28.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 188 from persistence list
2016-12-14 14:08:28.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 188
2016-12-14 14:08:28.048 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 187 from persistence list
2016-12-14 14:08:28.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 187
2016-12-14 14:08:28.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 186 from persistence list
2016-12-14 14:08:28.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 186
2016-12-14 14:08:28.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 184 from persistence list
2016-12-14 14:08:28.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 184
2016-12-14 14:08:28.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 183 from persistence list
2016-12-14 14:08:28.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 183
2016-12-14 14:08:28.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 182 from persistence list
2016-12-14 14:08:28.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 182
2016-12-14 14:08:28.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695706000 ms)
2016-12-14 14:08:28.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695706000 ms
2016-12-14 14:08:29.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695709000 ms
2016-12-14 14:08:29.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695709000 ms.0 from job set of time 1481695709000 ms
2016-12-14 14:08:29.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695709000 ms.0 from job set of time 1481695709000 ms
2016-12-14 14:08:29.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695709000 ms.1 from job set of time 1481695709000 ms
2016-12-14 14:08:29.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:29.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 204 (union at DStream.scala:617)
2016-12-14 14:08:29.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 23 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:29.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 46 (take at LogStream.java:127)
2016-12-14 14:08:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 45)
2016-12-14 14:08:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 45)
2016-12-14 14:08:29.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 45 (UnionRDD[204] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:29.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_45 stored as values in memory (estimated size 4.2 KB, free 149.5 KB)
2016-12-14 14:08:29.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.4 KB, free 151.9 KB)
2016-12-14 14:08:29.019 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_45_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:29.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 45 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:29.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 45 (UnionRDD[204] at union at DStream.scala:617)
2016-12-14 14:08:29.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 45.0 with 1 tasks
2016-12-14 14:08:29.022 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 45.0 (TID 45, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:29.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 45.0 (TID 45)
2016-12-14 14:08:29.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 45.0 (TID 45). 1159 bytes result sent to driver
2016-12-14 14:08:29.026 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 45.0 (TID 45) in 5 ms on localhost (1/1)
2016-12-14 14:08:29.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 45 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:29.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:29.027 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-12-14 14:08:29.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:29.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 46)
2016-12-14 14:08:29.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:29.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 46 (MapPartitionsRDD[207] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:29.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_46 stored as values in memory (estimated size 3.7 KB, free 155.6 KB)
2016-12-14 14:08:29.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_46_piece0 stored as bytes in memory (estimated size 2.1 KB, free 157.7 KB)
2016-12-14 14:08:29.031 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_46_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:29.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 46 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:29.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[207] at count at LogStream.java:120)
2016-12-14 14:08:29.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 46.0 with 1 tasks
2016-12-14 14:08:29.033 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 46.0 (TID 46, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:29.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 46.0 (TID 46)
2016-12-14 14:08:29.035 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:29.036 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:29.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 46.0 (TID 46). 1241 bytes result sent to driver
2016-12-14 14:08:29.039 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 46.0 (TID 46) in 6 ms on localhost (1/1)
2016-12-14 14:08:29.039 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-12-14 14:08:29.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 46 (take at LogStream.java:127) finished in 0.007 s
2016-12-14 14:08:29.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 23 finished: take at LogStream.java:127, took 0.025191 s
2016-12-14 14:08:29.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695709000 ms.1 from job set of time 1481695709000 ms
2016-12-14 14:08:29.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.046 s for time 1481695709000 ms (execution: 0.035 s)
2016-12-14 14:08:29.047 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 190 from persistence list
2016-12-14 14:08:29.047 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 190
2016-12-14 14:08:29.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[190] at createStream at LogStream.java:100 of time 1481695709000 ms
2016-12-14 14:08:29.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 198 from persistence list
2016-12-14 14:08:29.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 198
2016-12-14 14:08:29.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 197 from persistence list
2016-12-14 14:08:29.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 197
2016-12-14 14:08:29.049 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 196 from persistence list
2016-12-14 14:08:29.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 196
2016-12-14 14:08:29.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 195 from persistence list
2016-12-14 14:08:29.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 195
2016-12-14 14:08:29.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 193 from persistence list
2016-12-14 14:08:29.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 193
2016-12-14 14:08:29.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 192 from persistence list
2016-12-14 14:08:29.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 192
2016-12-14 14:08:29.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 191 from persistence list
2016-12-14 14:08:29.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 191
2016-12-14 14:08:29.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695707000 ms)
2016-12-14 14:08:29.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695707000 ms
2016-12-14 14:08:30.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695710000 ms
2016-12-14 14:08:30.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695710000 ms.0 from job set of time 1481695710000 ms
2016-12-14 14:08:30.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695710000 ms.0 from job set of time 1481695710000 ms
2016-12-14 14:08:30.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695710000 ms.1 from job set of time 1481695710000 ms
2016-12-14 14:08:30.017 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:30.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 213 (union at DStream.scala:617)
2016-12-14 14:08:30.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 24 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:30.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 48 (take at LogStream.java:127)
2016-12-14 14:08:30.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 47)
2016-12-14 14:08:30.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 47)
2016-12-14 14:08:30.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 47 (UnionRDD[213] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:30.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_47 stored as values in memory (estimated size 4.2 KB, free 161.9 KB)
2016-12-14 14:08:30.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KB, free 164.3 KB)
2016-12-14 14:08:30.023 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_47_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:30.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 47 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:30.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 47 (UnionRDD[213] at union at DStream.scala:617)
2016-12-14 14:08:30.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 47.0 with 1 tasks
2016-12-14 14:08:30.024 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 47.0 (TID 47, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:30.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 47.0 (TID 47)
2016-12-14 14:08:30.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 47.0 (TID 47). 1159 bytes result sent to driver
2016-12-14 14:08:30.029 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 47.0 (TID 47) in 5 ms on localhost (1/1)
2016-12-14 14:08:30.029 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 47 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:08:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 48)
2016-12-14 14:08:30.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:30.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 48 (MapPartitionsRDD[216] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:30.031 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_48 stored as values in memory (estimated size 3.7 KB, free 168.0 KB)
2016-12-14 14:08:30.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 170.1 KB)
2016-12-14 14:08:30.033 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_48_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:30.034 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 48 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:30.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[216] at count at LogStream.java:120)
2016-12-14 14:08:30.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 48.0 with 1 tasks
2016-12-14 14:08:30.035 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 48.0 (TID 48, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:30.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 48.0 (TID 48)
2016-12-14 14:08:30.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:30.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:30.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 48.0 (TID 48). 1241 bytes result sent to driver
2016-12-14 14:08:30.039 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 48.0 (TID 48) in 4 ms on localhost (1/1)
2016-12-14 14:08:30.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-12-14 14:08:30.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 48 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:30.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 24 finished: take at LogStream.java:127, took 0.023708 s
2016-12-14 14:08:30.051 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695710000 ms.1 from job set of time 1481695710000 ms
2016-12-14 14:08:30.051 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 199 from persistence list
2016-12-14 14:08:30.051 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.051 s for time 1481695710000 ms (execution: 0.039 s)
2016-12-14 14:08:30.052 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 199
2016-12-14 14:08:30.052 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[199] at createStream at LogStream.java:100 of time 1481695710000 ms
2016-12-14 14:08:30.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 207 from persistence list
2016-12-14 14:08:30.052 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 207
2016-12-14 14:08:30.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 206 from persistence list
2016-12-14 14:08:30.052 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 206
2016-12-14 14:08:30.053 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 205 from persistence list
2016-12-14 14:08:30.053 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 205
2016-12-14 14:08:30.053 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 204 from persistence list
2016-12-14 14:08:30.053 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 204
2016-12-14 14:08:30.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 202 from persistence list
2016-12-14 14:08:30.053 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 202
2016-12-14 14:08:30.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 201 from persistence list
2016-12-14 14:08:30.054 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 201
2016-12-14 14:08:30.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 200 from persistence list
2016-12-14 14:08:30.054 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 200
2016-12-14 14:08:30.054 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695708000 ms)
2016-12-14 14:08:30.054 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695708000 ms
2016-12-14 14:08:31.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695711000 ms
2016-12-14 14:08:31.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695711000 ms.0 from job set of time 1481695711000 ms
2016-12-14 14:08:31.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695711000 ms.0 from job set of time 1481695711000 ms
2016-12-14 14:08:31.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695711000 ms.1 from job set of time 1481695711000 ms
2016-12-14 14:08:31.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 222 (union at DStream.scala:617)
2016-12-14 14:08:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 25 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 50 (take at LogStream.java:127)
2016-12-14 14:08:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 49)
2016-12-14 14:08:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 49)
2016-12-14 14:08:31.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 49 (UnionRDD[222] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:31.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_49 stored as values in memory (estimated size 4.2 KB, free 174.4 KB)
2016-12-14 14:08:31.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.4 KB, free 176.8 KB)
2016-12-14 14:08:31.018 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_49_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:31.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 49 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:31.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 49 (UnionRDD[222] at union at DStream.scala:617)
2016-12-14 14:08:31.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 49.0 with 1 tasks
2016-12-14 14:08:31.020 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 49.0 (TID 49, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:31.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 49.0 (TID 49)
2016-12-14 14:08:31.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 49.0 (TID 49). 1159 bytes result sent to driver
2016-12-14 14:08:31.024 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 49.0 (TID 49) in 5 ms on localhost (1/1)
2016-12-14 14:08:31.024 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 49 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 50)
2016-12-14 14:08:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 50 (MapPartitionsRDD[225] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:31.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_50 stored as values in memory (estimated size 3.7 KB, free 180.5 KB)
2016-12-14 14:08:31.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 182.6 KB)
2016-12-14 14:08:31.028 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_50_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:31.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 50 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:31.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[225] at count at LogStream.java:120)
2016-12-14 14:08:31.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 50.0 with 1 tasks
2016-12-14 14:08:31.031 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 50.0 (TID 50, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:31.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 50.0 (TID 50)
2016-12-14 14:08:31.033 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:31.033 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:31.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 50.0 (TID 50). 1241 bytes result sent to driver
2016-12-14 14:08:31.036 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 50.0 (TID 50) in 4 ms on localhost (1/1)
2016-12-14 14:08:31.036 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-12-14 14:08:31.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 50 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:31.036 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 25 finished: take at LogStream.java:127, took 0.023272 s
2016-12-14 14:08:31.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695711000 ms.1 from job set of time 1481695711000 ms
2016-12-14 14:08:31.042 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 208 from persistence list
2016-12-14 14:08:31.042 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.042 s for time 1481695711000 ms (execution: 0.032 s)
2016-12-14 14:08:31.043 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 208
2016-12-14 14:08:31.043 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[208] at createStream at LogStream.java:100 of time 1481695711000 ms
2016-12-14 14:08:31.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 216 from persistence list
2016-12-14 14:08:31.043 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 216
2016-12-14 14:08:31.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 215 from persistence list
2016-12-14 14:08:31.043 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 215
2016-12-14 14:08:31.043 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 214 from persistence list
2016-12-14 14:08:31.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 214
2016-12-14 14:08:31.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 213 from persistence list
2016-12-14 14:08:31.044 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 213
2016-12-14 14:08:31.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 211 from persistence list
2016-12-14 14:08:31.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 211
2016-12-14 14:08:31.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 210 from persistence list
2016-12-14 14:08:31.044 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 210
2016-12-14 14:08:31.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 209 from persistence list
2016-12-14 14:08:31.045 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 209
2016-12-14 14:08:31.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695709000 ms)
2016-12-14 14:08:31.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695709000 ms
2016-12-14 14:08:32.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695712000 ms
2016-12-14 14:08:32.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695712000 ms.0 from job set of time 1481695712000 ms
2016-12-14 14:08:32.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695712000 ms.0 from job set of time 1481695712000 ms
2016-12-14 14:08:32.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695712000 ms.1 from job set of time 1481695712000 ms
2016-12-14 14:08:32.019 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 231 (union at DStream.scala:617)
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 26 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 52 (take at LogStream.java:127)
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 51)
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 51)
2016-12-14 14:08:32.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 51 (UnionRDD[231] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:32.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_51 stored as values in memory (estimated size 4.2 KB, free 186.8 KB)
2016-12-14 14:08:32.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.4 KB, free 189.2 KB)
2016-12-14 14:08:32.024 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_51_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:32.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 51 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:32.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 51 (UnionRDD[231] at union at DStream.scala:617)
2016-12-14 14:08:32.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 51.0 with 1 tasks
2016-12-14 14:08:32.026 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 51.0 (TID 51, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:32.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 51.0 (TID 51)
2016-12-14 14:08:32.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 51.0 (TID 51). 1159 bytes result sent to driver
2016-12-14 14:08:32.030 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 51.0 (TID 51) in 4 ms on localhost (1/1)
2016-12-14 14:08:32.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 51 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:32.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:32.031 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:32.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 52)
2016-12-14 14:08:32.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:32.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 52 (MapPartitionsRDD[234] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:32.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_52 stored as values in memory (estimated size 3.7 KB, free 192.9 KB)
2016-12-14 14:08:32.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.1 KB, free 195.0 KB)
2016-12-14 14:08:32.035 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_52_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:32.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 52 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:32.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[234] at count at LogStream.java:120)
2016-12-14 14:08:32.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 52.0 with 1 tasks
2016-12-14 14:08:32.036 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 52.0 (TID 52, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:32.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 52.0 (TID 52)
2016-12-14 14:08:32.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:32.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:32.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 52.0 (TID 52). 1241 bytes result sent to driver
2016-12-14 14:08:32.040 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 52.0 (TID 52) in 4 ms on localhost (1/1)
2016-12-14 14:08:32.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 52 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:32.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-12-14 14:08:32.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 26 finished: take at LogStream.java:127, took 0.021174 s
2016-12-14 14:08:32.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695712000 ms.1 from job set of time 1481695712000 ms
2016-12-14 14:08:32.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.046 s for time 1481695712000 ms (execution: 0.033 s)
2016-12-14 14:08:32.046 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 217 from persistence list
2016-12-14 14:08:32.046 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 217
2016-12-14 14:08:32.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[217] at createStream at LogStream.java:100 of time 1481695712000 ms
2016-12-14 14:08:32.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 225 from persistence list
2016-12-14 14:08:32.047 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 225
2016-12-14 14:08:32.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 224 from persistence list
2016-12-14 14:08:32.047 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 224
2016-12-14 14:08:32.047 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 223 from persistence list
2016-12-14 14:08:32.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 223
2016-12-14 14:08:32.048 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 222 from persistence list
2016-12-14 14:08:32.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 222
2016-12-14 14:08:32.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 220 from persistence list
2016-12-14 14:08:32.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 220
2016-12-14 14:08:32.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 219 from persistence list
2016-12-14 14:08:32.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 219
2016-12-14 14:08:32.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 218 from persistence list
2016-12-14 14:08:32.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 218
2016-12-14 14:08:32.049 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695710000 ms)
2016-12-14 14:08:32.049 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695710000 ms
2016-12-14 14:08:33.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695713000 ms
2016-12-14 14:08:33.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695713000 ms.0 from job set of time 1481695713000 ms
2016-12-14 14:08:33.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695713000 ms.0 from job set of time 1481695713000 ms
2016-12-14 14:08:33.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695713000 ms.1 from job set of time 1481695713000 ms
2016-12-14 14:08:33.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 240 (union at DStream.scala:617)
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 27 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 54 (take at LogStream.java:127)
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 53)
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 53)
2016-12-14 14:08:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 53 (UnionRDD[240] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:33.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_53 stored as values in memory (estimated size 4.2 KB, free 199.3 KB)
2016-12-14 14:08:33.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.4 KB, free 201.7 KB)
2016-12-14 14:08:33.018 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_53_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:33.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 53 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 53 (UnionRDD[240] at union at DStream.scala:617)
2016-12-14 14:08:33.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 53.0 with 1 tasks
2016-12-14 14:08:33.019 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 53.0 (TID 53, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:33.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 53.0 (TID 53)
2016-12-14 14:08:33.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 53.0 (TID 53). 1159 bytes result sent to driver
2016-12-14 14:08:33.023 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 53.0 (TID 53) in 4 ms on localhost (1/1)
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 53 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:33.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 54)
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 54 (MapPartitionsRDD[243] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:33.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_54 stored as values in memory (estimated size 3.7 KB, free 205.4 KB)
2016-12-14 14:08:33.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.1 KB, free 207.5 KB)
2016-12-14 14:08:33.026 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_54_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:33.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 54 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:33.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[243] at count at LogStream.java:120)
2016-12-14 14:08:33.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 54.0 with 1 tasks
2016-12-14 14:08:33.028 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 54.0 (TID 54, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:33.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 54.0 (TID 54)
2016-12-14 14:08:33.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:33.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:33.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 54.0 (TID 54). 1241 bytes result sent to driver
2016-12-14 14:08:33.031 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 54.0 (TID 54) in 4 ms on localhost (1/1)
2016-12-14 14:08:33.031 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2016-12-14 14:08:33.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 54 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:33.032 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 27 finished: take at LogStream.java:127, took 0.016537 s
2016-12-14 14:08:33.036 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695713000 ms.1 from job set of time 1481695713000 ms
2016-12-14 14:08:33.036 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 226 from persistence list
2016-12-14 14:08:33.036 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.036 s for time 1481695713000 ms (execution: 0.027 s)
2016-12-14 14:08:33.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 226
2016-12-14 14:08:33.037 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[226] at createStream at LogStream.java:100 of time 1481695713000 ms
2016-12-14 14:08:33.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 234 from persistence list
2016-12-14 14:08:33.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 234
2016-12-14 14:08:33.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 233 from persistence list
2016-12-14 14:08:33.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 233
2016-12-14 14:08:33.037 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 232 from persistence list
2016-12-14 14:08:33.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 232
2016-12-14 14:08:33.037 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 231 from persistence list
2016-12-14 14:08:33.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 231
2016-12-14 14:08:33.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 229 from persistence list
2016-12-14 14:08:33.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 229
2016-12-14 14:08:33.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 228 from persistence list
2016-12-14 14:08:33.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 228
2016-12-14 14:08:33.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 227 from persistence list
2016-12-14 14:08:33.039 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 227
2016-12-14 14:08:33.039 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695711000 ms)
2016-12-14 14:08:33.039 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695711000 ms
2016-12-14 14:08:34.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695714000 ms
2016-12-14 14:08:34.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695714000 ms.0 from job set of time 1481695714000 ms
2016-12-14 14:08:34.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695714000 ms.0 from job set of time 1481695714000 ms
2016-12-14 14:08:34.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695714000 ms.1 from job set of time 1481695714000 ms
2016-12-14 14:08:34.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:34.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 249 (union at DStream.scala:617)
2016-12-14 14:08:34.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 28 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:34.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 56 (take at LogStream.java:127)
2016-12-14 14:08:34.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 55)
2016-12-14 14:08:34.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 55)
2016-12-14 14:08:34.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 55 (UnionRDD[249] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:34.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_55 stored as values in memory (estimated size 4.2 KB, free 211.7 KB)
2016-12-14 14:08:34.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.4 KB, free 214.1 KB)
2016-12-14 14:08:34.015 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_55_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:34.015 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 55 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:34.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 55 (UnionRDD[249] at union at DStream.scala:617)
2016-12-14 14:08:34.016 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 55.0 with 1 tasks
2016-12-14 14:08:34.016 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 55.0 (TID 55, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:34.016 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 55.0 (TID 55)
2016-12-14 14:08:34.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 55.0 (TID 55). 1159 bytes result sent to driver
2016-12-14 14:08:34.021 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 55.0 (TID 55) in 5 ms on localhost (1/1)
2016-12-14 14:08:34.021 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2016-12-14 14:08:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 55 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 56)
2016-12-14 14:08:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:34.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 56 (MapPartitionsRDD[252] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:34.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_56 stored as values in memory (estimated size 3.7 KB, free 217.8 KB)
2016-12-14 14:08:34.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.1 KB, free 219.9 KB)
2016-12-14 14:08:34.025 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_56_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:34.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 56 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:34.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[252] at count at LogStream.java:120)
2016-12-14 14:08:34.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 56.0 with 1 tasks
2016-12-14 14:08:34.026 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 56.0 (TID 56, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:34.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 56.0 (TID 56)
2016-12-14 14:08:34.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:34.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:34.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 56.0 (TID 56). 1241 bytes result sent to driver
2016-12-14 14:08:34.029 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 56.0 (TID 56) in 3 ms on localhost (1/1)
2016-12-14 14:08:34.030 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2016-12-14 14:08:34.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 56 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:08:34.030 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 28 finished: take at LogStream.java:127, took 0.019126 s
2016-12-14 14:08:34.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695714000 ms.1 from job set of time 1481695714000 ms
2016-12-14 14:08:34.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.035 s for time 1481695714000 ms (execution: 0.027 s)
2016-12-14 14:08:34.035 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 235 from persistence list
2016-12-14 14:08:34.035 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 235
2016-12-14 14:08:34.035 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[235] at createStream at LogStream.java:100 of time 1481695714000 ms
2016-12-14 14:08:34.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 243 from persistence list
2016-12-14 14:08:34.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 243
2016-12-14 14:08:34.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 242 from persistence list
2016-12-14 14:08:34.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 242
2016-12-14 14:08:34.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 241 from persistence list
2016-12-14 14:08:34.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 241
2016-12-14 14:08:34.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 240 from persistence list
2016-12-14 14:08:34.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 240
2016-12-14 14:08:34.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 238 from persistence list
2016-12-14 14:08:34.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 238
2016-12-14 14:08:34.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 237 from persistence list
2016-12-14 14:08:34.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 237
2016-12-14 14:08:34.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 236 from persistence list
2016-12-14 14:08:34.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 236
2016-12-14 14:08:34.037 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695712000 ms)
2016-12-14 14:08:34.037 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695712000 ms
2016-12-14 14:08:35.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695715000 ms
2016-12-14 14:08:35.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695715000 ms.0 from job set of time 1481695715000 ms
2016-12-14 14:08:35.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695715000 ms.0 from job set of time 1481695715000 ms
2016-12-14 14:08:35.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695715000 ms.1 from job set of time 1481695715000 ms
2016-12-14 14:08:35.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 258 (union at DStream.scala:617)
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 29 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 58 (take at LogStream.java:127)
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 57)
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 57)
2016-12-14 14:08:35.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 57 (UnionRDD[258] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:35.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_57 stored as values in memory (estimated size 4.2 KB, free 224.1 KB)
2016-12-14 14:08:35.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.4 KB, free 226.6 KB)
2016-12-14 14:08:35.028 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_57_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:35.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 57 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:35.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 57 (UnionRDD[258] at union at DStream.scala:617)
2016-12-14 14:08:35.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 57.0 with 1 tasks
2016-12-14 14:08:35.030 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 57.0 (TID 57, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:35.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 57.0 (TID 57)
2016-12-14 14:08:35.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 57.0 (TID 57). 1159 bytes result sent to driver
2016-12-14 14:08:35.033 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 57.0 (TID 57) in 4 ms on localhost (1/1)
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 57 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:35.034 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 58)
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:35.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 58 (MapPartitionsRDD[261] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:35.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_58 stored as values in memory (estimated size 3.7 KB, free 230.3 KB)
2016-12-14 14:08:35.037 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.1 KB, free 232.4 KB)
2016-12-14 14:08:35.038 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_58_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:35.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 58 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:35.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[261] at count at LogStream.java:120)
2016-12-14 14:08:35.038 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 58.0 with 1 tasks
2016-12-14 14:08:35.039 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 58.0 (TID 58, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:35.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 58.0 (TID 58)
2016-12-14 14:08:35.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:35.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:35.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 58.0 (TID 58). 1241 bytes result sent to driver
2016-12-14 14:08:35.042 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 58.0 (TID 58) in 3 ms on localhost (1/1)
2016-12-14 14:08:35.042 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2016-12-14 14:08:35.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 58 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:35.042 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 29 finished: take at LogStream.java:127, took 0.028213 s
2016-12-14 14:08:35.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695715000 ms.1 from job set of time 1481695715000 ms
2016-12-14 14:08:35.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.049 s for time 1481695715000 ms (execution: 0.038 s)
2016-12-14 14:08:35.050 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 244 from persistence list
2016-12-14 14:08:35.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 244
2016-12-14 14:08:35.050 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[244] at createStream at LogStream.java:100 of time 1481695715000 ms
2016-12-14 14:08:35.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 252 from persistence list
2016-12-14 14:08:35.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 252
2016-12-14 14:08:35.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 251 from persistence list
2016-12-14 14:08:35.051 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 251
2016-12-14 14:08:35.051 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 250 from persistence list
2016-12-14 14:08:35.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 250
2016-12-14 14:08:35.051 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 249 from persistence list
2016-12-14 14:08:35.052 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 249
2016-12-14 14:08:35.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 247 from persistence list
2016-12-14 14:08:35.052 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 247
2016-12-14 14:08:35.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 246 from persistence list
2016-12-14 14:08:35.052 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 246
2016-12-14 14:08:35.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 245 from persistence list
2016-12-14 14:08:35.053 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 245
2016-12-14 14:08:35.053 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695713000 ms)
2016-12-14 14:08:35.053 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695713000 ms
2016-12-14 14:08:36.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695716000 ms
2016-12-14 14:08:36.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695716000 ms.0 from job set of time 1481695716000 ms
2016-12-14 14:08:36.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695716000 ms.0 from job set of time 1481695716000 ms
2016-12-14 14:08:36.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695716000 ms.1 from job set of time 1481695716000 ms
2016-12-14 14:08:36.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:36.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 267 (union at DStream.scala:617)
2016-12-14 14:08:36.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 30 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:36.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 60 (take at LogStream.java:127)
2016-12-14 14:08:36.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 59)
2016-12-14 14:08:36.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 59)
2016-12-14 14:08:36.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 59 (UnionRDD[267] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:36.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_59 stored as values in memory (estimated size 4.2 KB, free 236.6 KB)
2016-12-14 14:08:36.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.4 KB, free 239.0 KB)
2016-12-14 14:08:36.020 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_59_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:36.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 59 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 59 (UnionRDD[267] at union at DStream.scala:617)
2016-12-14 14:08:36.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 59.0 with 1 tasks
2016-12-14 14:08:36.021 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 59.0 (TID 59, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:36.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 59.0 (TID 59)
2016-12-14 14:08:36.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 59.0 (TID 59). 1159 bytes result sent to driver
2016-12-14 14:08:36.025 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 59.0 (TID 59) in 4 ms on localhost (1/1)
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 59 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:36.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 60)
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:36.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 60 (MapPartitionsRDD[270] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:36.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_60 stored as values in memory (estimated size 3.7 KB, free 242.7 KB)
2016-12-14 14:08:36.037 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.1 KB, free 244.8 KB)
2016-12-14 14:08:36.037 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_60_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:36.038 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 60 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:36.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[270] at count at LogStream.java:120)
2016-12-14 14:08:36.038 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 60.0 with 1 tasks
2016-12-14 14:08:36.038 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 60.0 (TID 60, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:36.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 60.0 (TID 60)
2016-12-14 14:08:36.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:36.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:36.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 60.0 (TID 60). 1241 bytes result sent to driver
2016-12-14 14:08:36.042 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 60.0 (TID 60) in 3 ms on localhost (1/1)
2016-12-14 14:08:36.042 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2016-12-14 14:08:36.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 60 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:36.042 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 30 finished: take at LogStream.java:127, took 0.026218 s
2016-12-14 14:08:36.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695716000 ms.1 from job set of time 1481695716000 ms
2016-12-14 14:08:36.047 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 253 from persistence list
2016-12-14 14:08:36.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695716000 ms (execution: 0.036 s)
2016-12-14 14:08:36.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 253
2016-12-14 14:08:36.048 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[253] at createStream at LogStream.java:100 of time 1481695716000 ms
2016-12-14 14:08:36.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 261 from persistence list
2016-12-14 14:08:36.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 261
2016-12-14 14:08:36.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 260 from persistence list
2016-12-14 14:08:36.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 260
2016-12-14 14:08:36.049 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 259 from persistence list
2016-12-14 14:08:36.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 259
2016-12-14 14:08:36.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 258 from persistence list
2016-12-14 14:08:36.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 258
2016-12-14 14:08:36.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 256 from persistence list
2016-12-14 14:08:36.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 256
2016-12-14 14:08:36.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 255 from persistence list
2016-12-14 14:08:36.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 255
2016-12-14 14:08:36.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 254 from persistence list
2016-12-14 14:08:36.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 254
2016-12-14 14:08:36.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695714000 ms)
2016-12-14 14:08:36.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695714000 ms
2016-12-14 14:08:37.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695717000 ms
2016-12-14 14:08:37.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695717000 ms.0 from job set of time 1481695717000 ms
2016-12-14 14:08:37.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695717000 ms.0 from job set of time 1481695717000 ms
2016-12-14 14:08:37.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695717000 ms.1 from job set of time 1481695717000 ms
2016-12-14 14:08:37.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:37.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 276 (union at DStream.scala:617)
2016-12-14 14:08:37.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 31 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:37.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 62 (take at LogStream.java:127)
2016-12-14 14:08:37.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 61)
2016-12-14 14:08:37.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 61)
2016-12-14 14:08:37.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 61 (UnionRDD[276] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:37.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_61 stored as values in memory (estimated size 4.2 KB, free 249.1 KB)
2016-12-14 14:08:37.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.4 KB, free 251.5 KB)
2016-12-14 14:08:37.021 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_61_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:37.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 61 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:37.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 61 (UnionRDD[276] at union at DStream.scala:617)
2016-12-14 14:08:37.022 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 61.0 with 1 tasks
2016-12-14 14:08:37.023 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 61.0 (TID 61, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:37.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 61.0 (TID 61)
2016-12-14 14:08:37.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 61.0 (TID 61). 1159 bytes result sent to driver
2016-12-14 14:08:37.030 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 61.0 (TID 61) in 7 ms on localhost (1/1)
2016-12-14 14:08:37.031 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 61 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 62)
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:37.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 62 (MapPartitionsRDD[279] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:37.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_62 stored as values in memory (estimated size 3.7 KB, free 255.2 KB)
2016-12-14 14:08:37.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.1 KB, free 257.3 KB)
2016-12-14 14:08:37.035 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_62_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:37.036 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 62 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:37.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[279] at count at LogStream.java:120)
2016-12-14 14:08:37.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 62.0 with 1 tasks
2016-12-14 14:08:37.037 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 62.0 (TID 62, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:37.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 62.0 (TID 62)
2016-12-14 14:08:37.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:37.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:37.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 62.0 (TID 62). 1241 bytes result sent to driver
2016-12-14 14:08:37.041 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 62.0 (TID 62) in 4 ms on localhost (1/1)
2016-12-14 14:08:37.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 62 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:37.041 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2016-12-14 14:08:37.042 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 31 finished: take at LogStream.java:127, took 0.028182 s
2016-12-14 14:08:37.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695717000 ms.1 from job set of time 1481695717000 ms
2016-12-14 14:08:37.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695717000 ms (execution: 0.037 s)
2016-12-14 14:08:37.048 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 262 from persistence list
2016-12-14 14:08:37.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 262
2016-12-14 14:08:37.048 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[262] at createStream at LogStream.java:100 of time 1481695717000 ms
2016-12-14 14:08:37.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 270 from persistence list
2016-12-14 14:08:37.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 270
2016-12-14 14:08:37.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 269 from persistence list
2016-12-14 14:08:37.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 269
2016-12-14 14:08:37.049 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 268 from persistence list
2016-12-14 14:08:37.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 268
2016-12-14 14:08:37.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 267 from persistence list
2016-12-14 14:08:37.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 267
2016-12-14 14:08:37.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 265 from persistence list
2016-12-14 14:08:37.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 265
2016-12-14 14:08:37.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 264 from persistence list
2016-12-14 14:08:37.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 264
2016-12-14 14:08:37.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 263 from persistence list
2016-12-14 14:08:37.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 263
2016-12-14 14:08:37.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695715000 ms)
2016-12-14 14:08:37.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695715000 ms
2016-12-14 14:08:38.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695718000 ms
2016-12-14 14:08:38.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695718000 ms.0 from job set of time 1481695718000 ms
2016-12-14 14:08:38.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695718000 ms.0 from job set of time 1481695718000 ms
2016-12-14 14:08:38.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695718000 ms.1 from job set of time 1481695718000 ms
2016-12-14 14:08:38.021 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:38.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 285 (union at DStream.scala:617)
2016-12-14 14:08:38.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 32 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:38.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 64 (take at LogStream.java:127)
2016-12-14 14:08:38.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 63)
2016-12-14 14:08:38.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 63)
2016-12-14 14:08:38.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 63 (UnionRDD[285] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:38.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_63 stored as values in memory (estimated size 4.2 KB, free 261.5 KB)
2016-12-14 14:08:38.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.4 KB, free 263.9 KB)
2016-12-14 14:08:38.026 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_63_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:38.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 63 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:38.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 63 (UnionRDD[285] at union at DStream.scala:617)
2016-12-14 14:08:38.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 63.0 with 1 tasks
2016-12-14 14:08:38.027 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 63.0 (TID 63, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:38.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 63.0 (TID 63)
2016-12-14 14:08:38.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 63.0 (TID 63). 1159 bytes result sent to driver
2016-12-14 14:08:38.031 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 63.0 (TID 63) in 4 ms on localhost (1/1)
2016-12-14 14:08:38.032 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 63 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 64)
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:38.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 64 (MapPartitionsRDD[288] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:38.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_64 stored as values in memory (estimated size 3.7 KB, free 267.6 KB)
2016-12-14 14:08:38.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.1 KB, free 269.8 KB)
2016-12-14 14:08:38.035 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_64_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:38.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 64 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:38.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[288] at count at LogStream.java:120)
2016-12-14 14:08:38.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 64.0 with 1 tasks
2016-12-14 14:08:38.036 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 64.0 (TID 64, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:38.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 64.0 (TID 64)
2016-12-14 14:08:38.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:38.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:38.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 64.0 (TID 64). 1241 bytes result sent to driver
2016-12-14 14:08:38.040 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 64.0 (TID 64) in 4 ms on localhost (1/1)
2016-12-14 14:08:38.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 64 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:38.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2016-12-14 14:08:38.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 32 finished: take at LogStream.java:127, took 0.019594 s
2016-12-14 14:08:38.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695718000 ms.1 from job set of time 1481695718000 ms
2016-12-14 14:08:38.047 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695718000 ms (execution: 0.030 s)
2016-12-14 14:08:38.047 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 271 from persistence list
2016-12-14 14:08:38.047 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 271
2016-12-14 14:08:38.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[271] at createStream at LogStream.java:100 of time 1481695718000 ms
2016-12-14 14:08:38.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 279 from persistence list
2016-12-14 14:08:38.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 279
2016-12-14 14:08:38.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 278 from persistence list
2016-12-14 14:08:38.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 278
2016-12-14 14:08:38.048 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 277 from persistence list
2016-12-14 14:08:38.048 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 277
2016-12-14 14:08:38.048 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 276 from persistence list
2016-12-14 14:08:38.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 276
2016-12-14 14:08:38.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 274 from persistence list
2016-12-14 14:08:38.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 274
2016-12-14 14:08:38.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 273 from persistence list
2016-12-14 14:08:38.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 273
2016-12-14 14:08:38.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 272 from persistence list
2016-12-14 14:08:38.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 272
2016-12-14 14:08:38.050 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695716000 ms)
2016-12-14 14:08:38.050 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695716000 ms
2016-12-14 14:08:39.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695719000 ms
2016-12-14 14:08:39.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695719000 ms.0 from job set of time 1481695719000 ms
2016-12-14 14:08:39.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695719000 ms.0 from job set of time 1481695719000 ms
2016-12-14 14:08:39.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695719000 ms.1 from job set of time 1481695719000 ms
2016-12-14 14:08:39.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 294 (union at DStream.scala:617)
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 33 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 66 (take at LogStream.java:127)
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 65)
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 65)
2016-12-14 14:08:39.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 65 (UnionRDD[294] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:39.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_65 stored as values in memory (estimated size 4.2 KB, free 274.0 KB)
2016-12-14 14:08:39.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.4 KB, free 276.4 KB)
2016-12-14 14:08:39.019 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_65_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:39.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 65 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 65 (UnionRDD[294] at union at DStream.scala:617)
2016-12-14 14:08:39.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 65.0 with 1 tasks
2016-12-14 14:08:39.021 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 65.0 (TID 65, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:39.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 65.0 (TID 65)
2016-12-14 14:08:39.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 65.0 (TID 65). 1159 bytes result sent to driver
2016-12-14 14:08:39.026 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 65.0 (TID 65) in 4 ms on localhost (1/1)
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 65 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:39.026 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 66)
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:39.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 66 (MapPartitionsRDD[297] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:39.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_66 stored as values in memory (estimated size 3.7 KB, free 280.1 KB)
2016-12-14 14:08:39.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.1 KB, free 282.2 KB)
2016-12-14 14:08:39.029 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_66_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:39.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 66 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:39.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[297] at count at LogStream.java:120)
2016-12-14 14:08:39.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 66.0 with 1 tasks
2016-12-14 14:08:39.031 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 66.0 (TID 66, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:39.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 66.0 (TID 66)
2016-12-14 14:08:39.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:39.033 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:39.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 66.0 (TID 66). 1241 bytes result sent to driver
2016-12-14 14:08:39.034 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 66.0 (TID 66) in 3 ms on localhost (1/1)
2016-12-14 14:08:39.035 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2016-12-14 14:08:39.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 66 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:39.035 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 33 finished: take at LogStream.java:127, took 0.018874 s
2016-12-14 14:08:39.040 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695719000 ms.1 from job set of time 1481695719000 ms
2016-12-14 14:08:39.041 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.040 s for time 1481695719000 ms (execution: 0.028 s)
2016-12-14 14:08:39.041 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 280 from persistence list
2016-12-14 14:08:39.041 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 280
2016-12-14 14:08:39.041 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[280] at createStream at LogStream.java:100 of time 1481695719000 ms
2016-12-14 14:08:39.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 288 from persistence list
2016-12-14 14:08:39.041 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 287 from persistence list
2016-12-14 14:08:39.042 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 288
2016-12-14 14:08:39.042 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 286 from persistence list
2016-12-14 14:08:39.042 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 287
2016-12-14 14:08:39.043 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 285 from persistence list
2016-12-14 14:08:39.043 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 286
2016-12-14 14:08:39.043 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 283 from persistence list
2016-12-14 14:08:39.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 285
2016-12-14 14:08:39.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 282 from persistence list
2016-12-14 14:08:39.044 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 283
2016-12-14 14:08:39.045 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 282
2016-12-14 14:08:39.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 281 from persistence list
2016-12-14 14:08:39.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695717000 ms)
2016-12-14 14:08:39.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695717000 ms
2016-12-14 14:08:39.045 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 281
2016-12-14 14:08:40.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695720000 ms
2016-12-14 14:08:40.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695720000 ms.0 from job set of time 1481695720000 ms
2016-12-14 14:08:40.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695720000 ms.0 from job set of time 1481695720000 ms
2016-12-14 14:08:40.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695720000 ms.1 from job set of time 1481695720000 ms
2016-12-14 14:08:40.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:40.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 303 (union at DStream.scala:617)
2016-12-14 14:08:40.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 34 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:40.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 68 (take at LogStream.java:127)
2016-12-14 14:08:40.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 67)
2016-12-14 14:08:40.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 67)
2016-12-14 14:08:40.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 67 (UnionRDD[303] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:40.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_67 stored as values in memory (estimated size 4.2 KB, free 286.4 KB)
2016-12-14 14:08:40.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_67_piece0 stored as bytes in memory (estimated size 2.4 KB, free 288.9 KB)
2016-12-14 14:08:40.022 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_67_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:40.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 67 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:40.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 67 (UnionRDD[303] at union at DStream.scala:617)
2016-12-14 14:08:40.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 67.0 with 1 tasks
2016-12-14 14:08:40.024 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 67.0 (TID 67, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:40.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 67.0 (TID 67)
2016-12-14 14:08:40.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 67.0 (TID 67). 1159 bytes result sent to driver
2016-12-14 14:08:40.027 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 67.0 (TID 67) in 4 ms on localhost (1/1)
2016-12-14 14:08:40.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 67 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:40.027 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2016-12-14 14:08:40.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:40.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:40.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 68)
2016-12-14 14:08:40.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:40.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 68 (MapPartitionsRDD[306] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:40.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_68 stored as values in memory (estimated size 3.7 KB, free 292.5 KB)
2016-12-14 14:08:40.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.1 KB, free 294.7 KB)
2016-12-14 14:08:40.031 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_68_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:40.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 68 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:40.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[306] at count at LogStream.java:120)
2016-12-14 14:08:40.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 68.0 with 1 tasks
2016-12-14 14:08:40.032 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 68.0 (TID 68, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:40.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 68.0 (TID 68)
2016-12-14 14:08:40.034 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:40.034 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:40.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 68.0 (TID 68). 1241 bytes result sent to driver
2016-12-14 14:08:40.036 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 68.0 (TID 68) in 4 ms on localhost (1/1)
2016-12-14 14:08:40.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 68 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:40.036 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2016-12-14 14:08:40.037 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 34 finished: take at LogStream.java:127, took 0.018315 s
2016-12-14 14:08:40.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695720000 ms.1 from job set of time 1481695720000 ms
2016-12-14 14:08:40.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.043 s for time 1481695720000 ms (execution: 0.029 s)
2016-12-14 14:08:40.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 289 from persistence list
2016-12-14 14:08:40.043 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 289
2016-12-14 14:08:40.043 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[289] at createStream at LogStream.java:100 of time 1481695720000 ms
2016-12-14 14:08:40.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 297 from persistence list
2016-12-14 14:08:40.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 297
2016-12-14 14:08:40.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 296 from persistence list
2016-12-14 14:08:40.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 295 from persistence list
2016-12-14 14:08:40.044 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 296
2016-12-14 14:08:40.045 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 295
2016-12-14 14:08:40.045 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 294 from persistence list
2016-12-14 14:08:40.045 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 292 from persistence list
2016-12-14 14:08:40.045 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 294
2016-12-14 14:08:40.046 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 292
2016-12-14 14:08:40.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 291 from persistence list
2016-12-14 14:08:40.046 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 291
2016-12-14 14:08:40.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 290 from persistence list
2016-12-14 14:08:40.046 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 290
2016-12-14 14:08:40.047 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695718000 ms)
2016-12-14 14:08:40.047 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695718000 ms
2016-12-14 14:08:41.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695721000 ms
2016-12-14 14:08:41.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695721000 ms.0 from job set of time 1481695721000 ms
2016-12-14 14:08:41.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695721000 ms.0 from job set of time 1481695721000 ms
2016-12-14 14:08:41.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695721000 ms.1 from job set of time 1481695721000 ms
2016-12-14 14:08:41.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:41.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 312 (union at DStream.scala:617)
2016-12-14 14:08:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 35 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 70 (take at LogStream.java:127)
2016-12-14 14:08:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 69)
2016-12-14 14:08:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 69)
2016-12-14 14:08:41.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 69 (UnionRDD[312] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:41.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_69 stored as values in memory (estimated size 4.2 KB, free 298.9 KB)
2016-12-14 14:08:41.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.4 KB, free 301.3 KB)
2016-12-14 14:08:41.021 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_69_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:41.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 69 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:41.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 69 (UnionRDD[312] at union at DStream.scala:617)
2016-12-14 14:08:41.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 69.0 with 1 tasks
2016-12-14 14:08:41.022 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 69.0 (TID 69, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:41.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 69.0 (TID 69)
2016-12-14 14:08:41.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 69.0 (TID 69). 1159 bytes result sent to driver
2016-12-14 14:08:41.027 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 69.0 (TID 69) in 5 ms on localhost (1/1)
2016-12-14 14:08:41.027 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2016-12-14 14:08:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 69 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 70)
2016-12-14 14:08:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:41.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 70 (MapPartitionsRDD[315] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:41.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_70 stored as values in memory (estimated size 3.7 KB, free 305.0 KB)
2016-12-14 14:08:41.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.1 KB, free 307.1 KB)
2016-12-14 14:08:41.032 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_70_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:41.033 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 70 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:41.034 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[315] at count at LogStream.java:120)
2016-12-14 14:08:41.034 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 70.0 with 1 tasks
2016-12-14 14:08:41.035 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 70.0 (TID 70, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:41.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 70.0 (TID 70)
2016-12-14 14:08:41.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:41.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:41.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 70.0 (TID 70). 1241 bytes result sent to driver
2016-12-14 14:08:41.039 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 70.0 (TID 70) in 5 ms on localhost (1/1)
2016-12-14 14:08:41.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 70 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:41.039 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2016-12-14 14:08:41.039 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 35 finished: take at LogStream.java:127, took 0.022950 s
2016-12-14 14:08:41.045 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695721000 ms.1 from job set of time 1481695721000 ms
2016-12-14 14:08:41.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.045 s for time 1481695721000 ms (execution: 0.033 s)
2016-12-14 14:08:41.046 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 298 from persistence list
2016-12-14 14:08:41.047 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[298] at createStream at LogStream.java:100 of time 1481695721000 ms
2016-12-14 14:08:41.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 306 from persistence list
2016-12-14 14:08:41.047 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 298
2016-12-14 14:08:41.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 305 from persistence list
2016-12-14 14:08:41.048 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 306
2016-12-14 14:08:41.048 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 305
2016-12-14 14:08:41.049 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 304 from persistence list
2016-12-14 14:08:41.049 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 304
2016-12-14 14:08:41.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 303 from persistence list
2016-12-14 14:08:41.049 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 303
2016-12-14 14:08:41.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 301 from persistence list
2016-12-14 14:08:41.049 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 301
2016-12-14 14:08:41.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 300 from persistence list
2016-12-14 14:08:41.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 299 from persistence list
2016-12-14 14:08:41.050 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 300
2016-12-14 14:08:41.051 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695719000 ms)
2016-12-14 14:08:41.051 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695719000 ms
2016-12-14 14:08:41.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 299
2016-12-14 14:08:42.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695722000 ms
2016-12-14 14:08:42.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695722000 ms.0 from job set of time 1481695722000 ms
2016-12-14 14:08:42.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695722000 ms.0 from job set of time 1481695722000 ms
2016-12-14 14:08:42.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695722000 ms.1 from job set of time 1481695722000 ms
2016-12-14 14:08:42.020 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:42.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 321 (union at DStream.scala:617)
2016-12-14 14:08:42.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 36 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:42.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 72 (take at LogStream.java:127)
2016-12-14 14:08:42.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 71)
2016-12-14 14:08:42.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 71)
2016-12-14 14:08:42.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 71 (UnionRDD[321] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:42.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_71 stored as values in memory (estimated size 4.2 KB, free 311.3 KB)
2016-12-14 14:08:42.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.4 KB, free 313.8 KB)
2016-12-14 14:08:42.032 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_71_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:42.032 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 71 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:42.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 71 (UnionRDD[321] at union at DStream.scala:617)
2016-12-14 14:08:42.032 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 71.0 with 1 tasks
2016-12-14 14:08:42.033 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 71.0 (TID 71, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:42.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 71.0 (TID 71)
2016-12-14 14:08:42.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 71.0 (TID 71). 1159 bytes result sent to driver
2016-12-14 14:08:42.037 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 71.0 (TID 71) in 4 ms on localhost (1/1)
2016-12-14 14:08:42.037 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 71 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 72)
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:42.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 72 (MapPartitionsRDD[324] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:42.039 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_72 stored as values in memory (estimated size 3.7 KB, free 317.5 KB)
2016-12-14 14:08:42.040 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.1 KB, free 319.6 KB)
2016-12-14 14:08:42.041 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_72_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:42.041 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 72 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:42.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[324] at count at LogStream.java:120)
2016-12-14 14:08:42.041 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 72.0 with 1 tasks
2016-12-14 14:08:42.041 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 72.0 (TID 72, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:42.042 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 72.0 (TID 72)
2016-12-14 14:08:42.043 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:42.043 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:42.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 72.0 (TID 72). 1241 bytes result sent to driver
2016-12-14 14:08:42.044 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 72.0 (TID 72) in 3 ms on localhost (1/1)
2016-12-14 14:08:42.044 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 72 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:08:42.044 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2016-12-14 14:08:42.044 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 36 finished: take at LogStream.java:127, took 0.024200 s
2016-12-14 14:08:42.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695722000 ms.1 from job set of time 1481695722000 ms
2016-12-14 14:08:42.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.049 s for time 1481695722000 ms (execution: 0.036 s)
2016-12-14 14:08:42.050 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 307 from persistence list
2016-12-14 14:08:42.050 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 307
2016-12-14 14:08:42.050 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[307] at createStream at LogStream.java:100 of time 1481695722000 ms
2016-12-14 14:08:42.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 315 from persistence list
2016-12-14 14:08:42.050 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 315
2016-12-14 14:08:42.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 314 from persistence list
2016-12-14 14:08:42.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 314
2016-12-14 14:08:42.051 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 313 from persistence list
2016-12-14 14:08:42.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 313
2016-12-14 14:08:42.051 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 312 from persistence list
2016-12-14 14:08:42.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 312
2016-12-14 14:08:42.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 310 from persistence list
2016-12-14 14:08:42.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 310
2016-12-14 14:08:42.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 309 from persistence list
2016-12-14 14:08:42.052 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 309
2016-12-14 14:08:42.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 308 from persistence list
2016-12-14 14:08:42.052 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 308
2016-12-14 14:08:42.052 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695720000 ms)
2016-12-14 14:08:42.052 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695720000 ms
2016-12-14 14:08:43.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695723000 ms
2016-12-14 14:08:43.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695723000 ms.0 from job set of time 1481695723000 ms
2016-12-14 14:08:43.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695723000 ms.0 from job set of time 1481695723000 ms
2016-12-14 14:08:43.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695723000 ms.1 from job set of time 1481695723000 ms
2016-12-14 14:08:43.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:43.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 330 (union at DStream.scala:617)
2016-12-14 14:08:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 37 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 74 (take at LogStream.java:127)
2016-12-14 14:08:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 73)
2016-12-14 14:08:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 73)
2016-12-14 14:08:43.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 73 (UnionRDD[330] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:43.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_73 stored as values in memory (estimated size 4.2 KB, free 323.8 KB)
2016-12-14 14:08:43.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_73_piece0 stored as bytes in memory (estimated size 2.4 KB, free 326.2 KB)
2016-12-14 14:08:43.020 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_73_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:43.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 73 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:43.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 73 (UnionRDD[330] at union at DStream.scala:617)
2016-12-14 14:08:43.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 73.0 with 1 tasks
2016-12-14 14:08:43.022 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 73.0 (TID 73, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:43.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 73.0 (TID 73)
2016-12-14 14:08:43.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 73.0 (TID 73). 1159 bytes result sent to driver
2016-12-14 14:08:43.027 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 73.0 (TID 73) in 6 ms on localhost (1/1)
2016-12-14 14:08:43.027 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2016-12-14 14:08:43.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 73 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:43.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:43.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:43.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 74)
2016-12-14 14:08:43.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:43.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 74 (MapPartitionsRDD[333] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:43.031 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_74 stored as values in memory (estimated size 3.7 KB, free 329.9 KB)
2016-12-14 14:08:43.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.1 KB, free 332.0 KB)
2016-12-14 14:08:43.034 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_74_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:43.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 74 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:43.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[333] at count at LogStream.java:120)
2016-12-14 14:08:43.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 74.0 with 1 tasks
2016-12-14 14:08:43.036 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 74.0 (TID 74, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:43.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 74.0 (TID 74)
2016-12-14 14:08:43.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:43.039 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:43.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 74.0 (TID 74). 1241 bytes result sent to driver
2016-12-14 14:08:43.041 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 74.0 (TID 74) in 4 ms on localhost (1/1)
2016-12-14 14:08:43.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 74 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:43.041 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2016-12-14 14:08:43.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 37 finished: take at LogStream.java:127, took 0.028097 s
2016-12-14 14:08:43.045 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695723000 ms.1 from job set of time 1481695723000 ms
2016-12-14 14:08:43.046 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 316 from persistence list
2016-12-14 14:08:43.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.045 s for time 1481695723000 ms (execution: 0.037 s)
2016-12-14 14:08:43.046 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 316
2016-12-14 14:08:43.046 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[316] at createStream at LogStream.java:100 of time 1481695723000 ms
2016-12-14 14:08:43.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 324 from persistence list
2016-12-14 14:08:43.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 323 from persistence list
2016-12-14 14:08:43.046 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 324
2016-12-14 14:08:43.047 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 323
2016-12-14 14:08:43.047 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 322 from persistence list
2016-12-14 14:08:43.047 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 322
2016-12-14 14:08:43.047 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 321 from persistence list
2016-12-14 14:08:46.496 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 321
2016-12-14 14:08:46.496 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 319 from persistence list
2016-12-14 14:08:46.496 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 319
2016-12-14 14:08:46.496 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 318 from persistence list
2016-12-14 14:08:46.496 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 318
2016-12-14 14:08:46.496 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 317 from persistence list
2016-12-14 14:08:46.496 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 317
2016-12-14 14:08:46.497 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695721000 ms)
2016-12-14 14:08:46.497 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695721000 ms
2016-12-14 14:08:46.503 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695724000 ms
2016-12-14 14:08:46.503 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695724000 ms.0 from job set of time 1481695724000 ms
2016-12-14 14:08:46.503 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695724000 ms.0 from job set of time 1481695724000 ms
2016-12-14 14:08:46.503 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695724000 ms.1 from job set of time 1481695724000 ms
2016-12-14 14:08:46.507 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:46.508 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 339 (union at DStream.scala:617)
2016-12-14 14:08:46.508 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 38 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:46.508 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 76 (take at LogStream.java:127)
2016-12-14 14:08:46.508 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 75)
2016-12-14 14:08:46.508 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 75)
2016-12-14 14:08:46.509 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 75 (UnionRDD[339] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:46.510 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_75 stored as values in memory (estimated size 4.2 KB, free 336.2 KB)
2016-12-14 14:08:46.511 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.4 KB, free 338.7 KB)
2016-12-14 14:08:46.511 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_75_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:46.512 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695725000 ms
2016-12-14 14:08:46.512 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 75 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.512 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 75 (UnionRDD[339] at union at DStream.scala:617)
2016-12-14 14:08:46.512 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 75.0 with 1 tasks
2016-12-14 14:08:46.513 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 75.0 (TID 75, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:46.513 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 75.0 (TID 75)
2016-12-14 14:08:46.518 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 75.0 (TID 75). 1159 bytes result sent to driver
2016-12-14 14:08:46.520 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 75.0 (TID 75) in 6 ms on localhost (1/1)
2016-12-14 14:08:46.520 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 75 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:46.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:46.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:46.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 76)
2016-12-14 14:08:46.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:46.521 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 76 (MapPartitionsRDD[342] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:46.522 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_76 stored as values in memory (estimated size 3.7 KB, free 342.4 KB)
2016-12-14 14:08:46.523 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695726000 ms
2016-12-14 14:08:46.523 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.1 KB, free 344.5 KB)
2016-12-14 14:08:46.523 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_76_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:46.524 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 76 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.524 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[342] at count at LogStream.java:120)
2016-12-14 14:08:46.524 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 76.0 with 1 tasks
2016-12-14 14:08:46.525 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 76.0 (TID 76, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:46.525 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 76.0 (TID 76)
2016-12-14 14:08:46.527 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:46.527 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:46.528 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 76.0 (TID 76). 1241 bytes result sent to driver
2016-12-14 14:08:46.529 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 76.0 (TID 76) in 4 ms on localhost (1/1)
2016-12-14 14:08:46.529 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.530 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 76 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:46.530 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 38 finished: take at LogStream.java:127, took 0.022951 s
2016-12-14 14:08:46.536 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695724000 ms.1 from job set of time 1481695724000 ms
2016-12-14 14:08:46.536 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 2.536 s for time 1481695724000 ms (execution: 0.033 s)
2016-12-14 14:08:46.536 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695725000 ms.0 from job set of time 1481695725000 ms
2016-12-14 14:08:46.536 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695725000 ms.0 from job set of time 1481695725000 ms
2016-12-14 14:08:46.536 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695725000 ms.1 from job set of time 1481695725000 ms
2016-12-14 14:08:46.538 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 325 from persistence list
2016-12-14 14:08:46.539 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 348 (union at DStream.scala:617)
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 39 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 78 (take at LogStream.java:127)
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 77)
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 77)
2016-12-14 14:08:46.541 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 77 (UnionRDD[348] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:46.542 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_77 stored as values in memory (estimated size 4.2 KB, free 348.7 KB)
2016-12-14 14:08:46.543 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.4 KB, free 351.1 KB)
2016-12-14 14:08:46.545 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 325
2016-12-14 14:08:46.545 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[325] at createStream at LogStream.java:100 of time 1481695724000 ms
2016-12-14 14:08:46.545 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 333 from persistence list
2016-12-14 14:08:46.546 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_77_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:46.550 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 77 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.551 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 77 (UnionRDD[348] at union at DStream.scala:617)
2016-12-14 14:08:46.551 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 77.0 with 1 tasks
2016-12-14 14:08:46.552 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 332 from persistence list
2016-12-14 14:08:46.552 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 333
2016-12-14 14:08:46.552 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 77.0 (TID 77, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:46.553 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 77.0 (TID 77)
2016-12-14 14:08:46.553 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 331 from persistence list
2016-12-14 14:08:46.553 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 332
2016-12-14 14:08:46.554 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 331
2016-12-14 14:08:46.554 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 330 from persistence list
2016-12-14 14:08:46.554 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 330
2016-12-14 14:08:46.554 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 328 from persistence list
2016-12-14 14:08:46.554 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 328
2016-12-14 14:08:46.554 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 327 from persistence list
2016-12-14 14:08:46.555 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 327
2016-12-14 14:08:46.555 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 326 from persistence list
2016-12-14 14:08:46.555 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 326
2016-12-14 14:08:46.555 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695722000 ms)
2016-12-14 14:08:46.555 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695722000 ms
2016-12-14 14:08:46.557 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 77.0 (TID 77). 1159 bytes result sent to driver
2016-12-14 14:08:46.558 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 77.0 (TID 77) in 6 ms on localhost (1/1)
2016-12-14 14:08:46.558 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.558 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 77 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:46.558 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:46.558 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:46.558 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 78)
2016-12-14 14:08:46.558 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:46.559 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 78 (MapPartitionsRDD[351] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:46.560 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_78 stored as values in memory (estimated size 3.7 KB, free 354.8 KB)
2016-12-14 14:08:46.561 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.1 KB, free 356.9 KB)
2016-12-14 14:08:46.561 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_78_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:46.562 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 78 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.562 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[351] at count at LogStream.java:120)
2016-12-14 14:08:46.562 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 78.0 with 1 tasks
2016-12-14 14:08:46.563 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 78.0 (TID 78, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:46.563 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 78.0 (TID 78)
2016-12-14 14:08:46.564 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:46.564 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:46.565 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 78.0 (TID 78). 1241 bytes result sent to driver
2016-12-14 14:08:46.566 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 78.0 (TID 78) in 3 ms on localhost (1/1)
2016-12-14 14:08:46.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 78 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:46.566 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.567 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 39 finished: take at LogStream.java:127, took 0.027087 s
2016-12-14 14:08:46.573 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695725000 ms.1 from job set of time 1481695725000 ms
2016-12-14 14:08:46.573 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 1.573 s for time 1481695725000 ms (execution: 0.037 s)
2016-12-14 14:08:46.573 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695726000 ms.0 from job set of time 1481695726000 ms
2016-12-14 14:08:46.574 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 334 from persistence list
2016-12-14 14:08:46.574 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695726000 ms.0 from job set of time 1481695726000 ms
2016-12-14 14:08:46.574 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695726000 ms.1 from job set of time 1481695726000 ms
2016-12-14 14:08:46.574 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[334] at createStream at LogStream.java:100 of time 1481695725000 ms
2016-12-14 14:08:46.574 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 342 from persistence list
2016-12-14 14:08:46.575 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 334
2016-12-14 14:08:46.575 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 341 from persistence list
2016-12-14 14:08:46.575 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 342
2016-12-14 14:08:46.577 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 340 from persistence list
2016-12-14 14:08:46.578 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 341
2016-12-14 14:08:46.578 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:46.578 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 339 from persistence list
2016-12-14 14:08:46.578 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 340
2016-12-14 14:08:46.579 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 337 from persistence list
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 357 (union at DStream.scala:617)
2016-12-14 14:08:46.579 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 339
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 40 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 80 (take at LogStream.java:127)
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 79)
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 79)
2016-12-14 14:08:46.579 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 79 (UnionRDD[357] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:46.580 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_79 stored as values in memory (estimated size 4.2 KB, free 361.1 KB)
2016-12-14 14:08:46.580 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 336 from persistence list
2016-12-14 14:08:46.580 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 337
2016-12-14 14:08:46.581 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 335 from persistence list
2016-12-14 14:08:46.581 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 336
2016-12-14 14:08:46.581 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.4 KB, free 363.6 KB)
2016-12-14 14:08:46.582 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_79_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:46.582 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695723000 ms)
2016-12-14 14:08:46.582 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 335
2016-12-14 14:08:46.582 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695723000 ms
2016-12-14 14:08:46.582 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 79 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.582 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 79 (UnionRDD[357] at union at DStream.scala:617)
2016-12-14 14:08:46.582 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 79.0 with 1 tasks
2016-12-14 14:08:46.583 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 79.0 (TID 79, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:46.583 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 79.0 (TID 79)
2016-12-14 14:08:46.586 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 79.0 (TID 79). 1159 bytes result sent to driver
2016-12-14 14:08:46.587 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 79.0 (TID 79) in 4 ms on localhost (1/1)
2016-12-14 14:08:46.587 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 79 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:46.587 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.587 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:46.587 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:46.587 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 80)
2016-12-14 14:08:46.587 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:46.588 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 80 (MapPartitionsRDD[360] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:46.589 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_80 stored as values in memory (estimated size 3.7 KB, free 367.3 KB)
2016-12-14 14:08:46.590 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_80_piece0 stored as bytes in memory (estimated size 2.1 KB, free 369.4 KB)
2016-12-14 14:08:46.591 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_80_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:46.591 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 80 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:46.591 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[360] at count at LogStream.java:120)
2016-12-14 14:08:46.591 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 80.0 with 1 tasks
2016-12-14 14:08:46.592 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 80.0 (TID 80, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:46.593 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 80.0 (TID 80)
2016-12-14 14:08:46.596 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:46.597 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:08:46.597 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 80.0 (TID 80). 1241 bytes result sent to driver
2016-12-14 14:08:46.598 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 80.0 (TID 80) in 6 ms on localhost (1/1)
2016-12-14 14:08:46.598 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2016-12-14 14:08:46.598 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 80 (take at LogStream.java:127) finished in 0.006 s
2016-12-14 14:08:46.599 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 40 finished: take at LogStream.java:127, took 0.020512 s
2016-12-14 14:08:46.605 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695726000 ms.1 from job set of time 1481695726000 ms
2016-12-14 14:08:46.605 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.605 s for time 1481695726000 ms (execution: 0.032 s)
2016-12-14 14:08:46.605 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 343 from persistence list
2016-12-14 14:08:46.605 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 343
2016-12-14 14:08:46.605 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[343] at createStream at LogStream.java:100 of time 1481695726000 ms
2016-12-14 14:08:46.606 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 351 from persistence list
2016-12-14 14:08:46.606 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 351
2016-12-14 14:08:46.606 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 350 from persistence list
2016-12-14 14:08:46.606 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 350
2016-12-14 14:08:46.606 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 349 from persistence list
2016-12-14 14:08:46.606 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 349
2016-12-14 14:08:46.607 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 348 from persistence list
2016-12-14 14:08:46.607 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 348
2016-12-14 14:08:46.607 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 346 from persistence list
2016-12-14 14:08:46.607 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 346
2016-12-14 14:08:46.607 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 345 from persistence list
2016-12-14 14:08:46.607 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 345
2016-12-14 14:08:46.608 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 344 from persistence list
2016-12-14 14:08:46.608 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 344
2016-12-14 14:08:46.608 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695724000 ms)
2016-12-14 14:08:46.608 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695724000 ms
2016-12-14 14:08:47.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695727000 ms
2016-12-14 14:08:47.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695727000 ms.0 from job set of time 1481695727000 ms
2016-12-14 14:08:47.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695727000 ms.0 from job set of time 1481695727000 ms
2016-12-14 14:08:47.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695727000 ms.1 from job set of time 1481695727000 ms
2016-12-14 14:08:47.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 366 (union at DStream.scala:617)
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 41 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 82 (take at LogStream.java:127)
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 81)
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 81)
2016-12-14 14:08:47.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 81 (UnionRDD[366] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:47.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_81 stored as values in memory (estimated size 4.2 KB, free 373.6 KB)
2016-12-14 14:08:47.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_81_piece0 stored as bytes in memory (estimated size 2.4 KB, free 376.0 KB)
2016-12-14 14:08:47.015 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_81_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:47.015 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 81 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:47.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 81 (UnionRDD[366] at union at DStream.scala:617)
2016-12-14 14:08:47.015 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 81.0 with 1 tasks
2016-12-14 14:08:47.016 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 81.0 (TID 81, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:47.016 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 81.0 (TID 81)
2016-12-14 14:08:47.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 81.0 (TID 81). 1159 bytes result sent to driver
2016-12-14 14:08:47.019 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 81.0 (TID 81) in 3 ms on localhost (1/1)
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 81 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:47.019 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 82)
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 82 (MapPartitionsRDD[369] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:47.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_82 stored as values in memory (estimated size 3.7 KB, free 379.7 KB)
2016-12-14 14:08:47.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_82_piece0 stored as bytes in memory (estimated size 2.1 KB, free 381.8 KB)
2016-12-14 14:08:47.022 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_82_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:47.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 82 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:47.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[369] at count at LogStream.java:120)
2016-12-14 14:08:47.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 82.0 with 1 tasks
2016-12-14 14:08:47.023 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 82.0 (TID 82, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:47.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 82.0 (TID 82)
2016-12-14 14:08:47.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:47.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:47.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 82.0 (TID 82). 1241 bytes result sent to driver
2016-12-14 14:08:47.027 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 82.0 (TID 82) in 3 ms on localhost (1/1)
2016-12-14 14:08:47.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 82 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:47.027 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2016-12-14 14:08:47.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 41 finished: take at LogStream.java:127, took 0.015570 s
2016-12-14 14:08:47.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695727000 ms.1 from job set of time 1481695727000 ms
2016-12-14 14:08:47.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.031 s for time 1481695727000 ms (execution: 0.023 s)
2016-12-14 14:08:47.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 352 from persistence list
2016-12-14 14:08:47.032 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 352
2016-12-14 14:08:47.032 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[352] at createStream at LogStream.java:100 of time 1481695727000 ms
2016-12-14 14:08:47.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 360 from persistence list
2016-12-14 14:08:47.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 359 from persistence list
2016-12-14 14:08:47.032 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 360
2016-12-14 14:08:47.033 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 359
2016-12-14 14:08:47.033 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 358 from persistence list
2016-12-14 14:08:47.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 358
2016-12-14 14:08:47.033 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 357 from persistence list
2016-12-14 14:08:47.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 355 from persistence list
2016-12-14 14:08:47.033 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 357
2016-12-14 14:08:47.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 355
2016-12-14 14:08:47.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 354 from persistence list
2016-12-14 14:08:47.034 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 354
2016-12-14 14:08:47.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 353 from persistence list
2016-12-14 14:08:47.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 353
2016-12-14 14:08:47.034 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695725000 ms)
2016-12-14 14:08:47.034 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695725000 ms
2016-12-14 14:08:48.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695728000 ms
2016-12-14 14:08:48.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695728000 ms.0 from job set of time 1481695728000 ms
2016-12-14 14:08:48.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695728000 ms.0 from job set of time 1481695728000 ms
2016-12-14 14:08:48.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695728000 ms.1 from job set of time 1481695728000 ms
2016-12-14 14:08:48.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 375 (union at DStream.scala:617)
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 42 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 84 (take at LogStream.java:127)
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 83)
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 83)
2016-12-14 14:08:48.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 83 (UnionRDD[375] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:48.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_83 stored as values in memory (estimated size 4.2 KB, free 386.0 KB)
2016-12-14 14:08:48.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.4 KB, free 388.5 KB)
2016-12-14 14:08:48.015 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_83_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:48.015 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 83 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:48.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 83 (UnionRDD[375] at union at DStream.scala:617)
2016-12-14 14:08:48.015 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 83.0 with 1 tasks
2016-12-14 14:08:48.016 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 83.0 (TID 83, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:48.016 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 83.0 (TID 83)
2016-12-14 14:08:48.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 83.0 (TID 83). 1159 bytes result sent to driver
2016-12-14 14:08:48.019 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 83.0 (TID 83) in 4 ms on localhost (1/1)
2016-12-14 14:08:48.019 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 83 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 84)
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 84 (MapPartitionsRDD[378] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:48.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_84 stored as values in memory (estimated size 3.7 KB, free 392.2 KB)
2016-12-14 14:08:48.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_84_piece0 stored as bytes in memory (estimated size 2.1 KB, free 394.3 KB)
2016-12-14 14:08:48.022 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_84_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:48.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 84 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[378] at count at LogStream.java:120)
2016-12-14 14:08:48.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 84.0 with 1 tasks
2016-12-14 14:08:48.023 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 84.0 (TID 84, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:48.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 84.0 (TID 84)
2016-12-14 14:08:48.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:48.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:48.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 84.0 (TID 84). 1241 bytes result sent to driver
2016-12-14 14:08:48.026 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 84.0 (TID 84) in 3 ms on localhost (1/1)
2016-12-14 14:08:48.027 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2016-12-14 14:08:48.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 84 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:08:48.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 42 finished: take at LogStream.java:127, took 0.015190 s
2016-12-14 14:08:48.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695728000 ms.1 from job set of time 1481695728000 ms
2016-12-14 14:08:48.033 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.032 s for time 1481695728000 ms (execution: 0.023 s)
2016-12-14 14:08:48.033 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 361 from persistence list
2016-12-14 14:08:48.033 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[361] at createStream at LogStream.java:100 of time 1481695728000 ms
2016-12-14 14:08:48.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 369 from persistence list
2016-12-14 14:08:48.033 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 361
2016-12-14 14:08:48.034 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 369
2016-12-14 14:08:48.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 368 from persistence list
2016-12-14 14:08:48.034 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 368
2016-12-14 14:08:48.034 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 367 from persistence list
2016-12-14 14:08:48.034 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 367
2016-12-14 14:08:48.034 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 366 from persistence list
2016-12-14 14:08:48.034 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 366
2016-12-14 14:08:48.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 364 from persistence list
2016-12-14 14:08:48.034 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 364
2016-12-14 14:08:48.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 363 from persistence list
2016-12-14 14:08:48.035 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 363
2016-12-14 14:08:48.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 362 from persistence list
2016-12-14 14:08:48.035 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 362
2016-12-14 14:08:48.035 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695726000 ms)
2016-12-14 14:08:48.035 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695726000 ms
2016-12-14 14:08:49.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695729000 ms
2016-12-14 14:08:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695729000 ms.0 from job set of time 1481695729000 ms
2016-12-14 14:08:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695729000 ms.0 from job set of time 1481695729000 ms
2016-12-14 14:08:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695729000 ms.1 from job set of time 1481695729000 ms
2016-12-14 14:08:49.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 384 (union at DStream.scala:617)
2016-12-14 14:08:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 43 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 86 (take at LogStream.java:127)
2016-12-14 14:08:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 85)
2016-12-14 14:08:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 85)
2016-12-14 14:08:49.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 85 (UnionRDD[384] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:49.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_85 stored as values in memory (estimated size 4.2 KB, free 398.5 KB)
2016-12-14 14:08:49.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_85_piece0 stored as bytes in memory (estimated size 2.4 KB, free 400.9 KB)
2016-12-14 14:08:49.017 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_85_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:49.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 85 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:49.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 85 (UnionRDD[384] at union at DStream.scala:617)
2016-12-14 14:08:49.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 85.0 with 1 tasks
2016-12-14 14:08:49.019 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 85.0 (TID 85, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:49.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 85.0 (TID 85)
2016-12-14 14:08:49.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 85.0 (TID 85). 1159 bytes result sent to driver
2016-12-14 14:08:49.025 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 85.0 (TID 85) in 6 ms on localhost (1/1)
2016-12-14 14:08:49.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 85 (union at DStream.scala:617) finished in 0.007 s
2016-12-14 14:08:49.025 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2016-12-14 14:08:49.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:49.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:49.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 86)
2016-12-14 14:08:49.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:49.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 86 (MapPartitionsRDD[387] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:49.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_86 stored as values in memory (estimated size 3.7 KB, free 404.6 KB)
2016-12-14 14:08:49.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_86_piece0 stored as bytes in memory (estimated size 2.1 KB, free 406.7 KB)
2016-12-14 14:08:49.029 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_86_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:49.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 86 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:49.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[387] at count at LogStream.java:120)
2016-12-14 14:08:49.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 86.0 with 1 tasks
2016-12-14 14:08:49.030 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 86.0 (TID 86, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:49.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 86.0 (TID 86)
2016-12-14 14:08:49.033 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:49.033 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:49.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 86.0 (TID 86). 1241 bytes result sent to driver
2016-12-14 14:08:49.034 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 86.0 (TID 86) in 4 ms on localhost (1/1)
2016-12-14 14:08:49.034 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2016-12-14 14:08:49.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 86 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:49.035 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 43 finished: take at LogStream.java:127, took 0.023507 s
2016-12-14 14:08:49.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695729000 ms.1 from job set of time 1481695729000 ms
2016-12-14 14:08:49.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 370 from persistence list
2016-12-14 14:08:49.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.043 s for time 1481695729000 ms (execution: 0.035 s)
2016-12-14 14:08:49.044 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[370] at createStream at LogStream.java:100 of time 1481695729000 ms
2016-12-14 14:08:49.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 378 from persistence list
2016-12-14 14:08:49.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 370
2016-12-14 14:08:49.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 377 from persistence list
2016-12-14 14:08:49.047 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 378
2016-12-14 14:08:49.047 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 377
2016-12-14 14:08:49.047 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 376 from persistence list
2016-12-14 14:08:49.048 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 375 from persistence list
2016-12-14 14:08:49.049 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 376
2016-12-14 14:08:49.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 373 from persistence list
2016-12-14 14:08:49.050 [block-manager-slave-async-thread-pool-2] INFO  o.apache.spark.storage.BlockManager - Removing RDD 375
2016-12-14 14:08:49.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 372 from persistence list
2016-12-14 14:08:49.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 373
2016-12-14 14:08:49.051 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 372
2016-12-14 14:08:49.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 371 from persistence list
2016-12-14 14:08:49.051 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695727000 ms)
2016-12-14 14:08:49.051 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695727000 ms
2016-12-14 14:08:49.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 371
2016-12-14 14:08:50.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695730000 ms
2016-12-14 14:08:50.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695730000 ms.0 from job set of time 1481695730000 ms
2016-12-14 14:08:50.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695730000 ms.0 from job set of time 1481695730000 ms
2016-12-14 14:08:50.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695730000 ms.1 from job set of time 1481695730000 ms
2016-12-14 14:08:50.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 393 (union at DStream.scala:617)
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 44 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 88 (take at LogStream.java:127)
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 87)
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 87)
2016-12-14 14:08:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 87 (UnionRDD[393] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:50.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_87 stored as values in memory (estimated size 4.2 KB, free 410.9 KB)
2016-12-14 14:08:50.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.4 KB, free 413.4 KB)
2016-12-14 14:08:50.018 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_87_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:50.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 87 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:50.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 87 (UnionRDD[393] at union at DStream.scala:617)
2016-12-14 14:08:50.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 87.0 with 1 tasks
2016-12-14 14:08:50.019 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 87.0 (TID 87, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:50.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 87.0 (TID 87)
2016-12-14 14:08:50.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 87.0 (TID 87). 1159 bytes result sent to driver
2016-12-14 14:08:50.024 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 87.0 (TID 87) in 4 ms on localhost (1/1)
2016-12-14 14:08:50.024 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 87 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 88)
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 88 (MapPartitionsRDD[396] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:50.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_88 stored as values in memory (estimated size 3.7 KB, free 417.1 KB)
2016-12-14 14:08:50.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_88_piece0 stored as bytes in memory (estimated size 2.1 KB, free 419.2 KB)
2016-12-14 14:08:50.027 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_88_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:50.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 88 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:50.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[396] at count at LogStream.java:120)
2016-12-14 14:08:50.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 88.0 with 1 tasks
2016-12-14 14:08:50.029 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 88.0 (TID 88, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:50.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 88.0 (TID 88)
2016-12-14 14:08:50.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:50.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:50.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 88.0 (TID 88). 1241 bytes result sent to driver
2016-12-14 14:08:50.032 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 88.0 (TID 88) in 4 ms on localhost (1/1)
2016-12-14 14:08:50.032 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2016-12-14 14:08:50.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 88 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:50.033 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 44 finished: take at LogStream.java:127, took 0.018731 s
2016-12-14 14:08:50.038 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695730000 ms.1 from job set of time 1481695730000 ms
2016-12-14 14:08:50.039 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 379 from persistence list
2016-12-14 14:08:50.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.038 s for time 1481695730000 ms (execution: 0.028 s)
2016-12-14 14:08:50.039 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[379] at createStream at LogStream.java:100 of time 1481695730000 ms
2016-12-14 14:08:50.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 387 from persistence list
2016-12-14 14:08:50.040 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 379
2016-12-14 14:08:50.040 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 387
2016-12-14 14:08:50.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 386 from persistence list
2016-12-14 14:08:50.041 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 385 from persistence list
2016-12-14 14:08:50.041 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 386
2016-12-14 14:08:50.041 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 384 from persistence list
2016-12-14 14:08:50.041 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 385
2016-12-14 14:08:56.501 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 384
2016-12-14 14:08:56.501 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 382 from persistence list
2016-12-14 14:08:56.502 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 382
2016-12-14 14:08:56.502 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 381 from persistence list
2016-12-14 14:08:56.502 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 381
2016-12-14 14:08:56.502 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 380 from persistence list
2016-12-14 14:08:56.502 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 380
2016-12-14 14:08:56.502 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695728000 ms)
2016-12-14 14:08:56.502 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695728000 ms
2016-12-14 14:08:56.510 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695731000 ms
2016-12-14 14:08:56.510 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695731000 ms.0 from job set of time 1481695731000 ms
2016-12-14 14:08:56.511 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695731000 ms.0 from job set of time 1481695731000 ms
2016-12-14 14:08:56.511 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695731000 ms.1 from job set of time 1481695731000 ms
2016-12-14 14:08:56.514 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:56.515 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 402 (union at DStream.scala:617)
2016-12-14 14:08:56.516 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 45 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:56.516 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 90 (take at LogStream.java:127)
2016-12-14 14:08:56.516 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 89)
2016-12-14 14:08:56.516 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 89)
2016-12-14 14:08:56.516 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 89 (UnionRDD[402] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:56.517 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_89 stored as values in memory (estimated size 4.2 KB, free 423.4 KB)
2016-12-14 14:08:56.519 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695732000 ms
2016-12-14 14:08:56.519 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_89_piece0 stored as bytes in memory (estimated size 2.4 KB, free 425.8 KB)
2016-12-14 14:08:56.519 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_89_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.520 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 89 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.520 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 89 (UnionRDD[402] at union at DStream.scala:617)
2016-12-14 14:08:56.520 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 89.0 with 1 tasks
2016-12-14 14:08:56.521 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 89.0 (TID 89, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:56.521 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 89.0 (TID 89)
2016-12-14 14:08:56.525 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 89.0 (TID 89). 1159 bytes result sent to driver
2016-12-14 14:08:56.528 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 89.0 (TID 89) in 6 ms on localhost (1/1)
2016-12-14 14:08:56.528 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 89 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 90)
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:56.528 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 90 (MapPartitionsRDD[405] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:56.529 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_90 stored as values in memory (estimated size 3.7 KB, free 429.5 KB)
2016-12-14 14:08:56.531 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_90_piece0 stored as bytes in memory (estimated size 2.1 KB, free 431.6 KB)
2016-12-14 14:08:56.534 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695733000 ms
2016-12-14 14:08:56.540 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_90_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.544 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 90 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.544 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[405] at count at LogStream.java:120)
2016-12-14 14:08:56.544 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695734000 ms
2016-12-14 14:08:56.544 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 90.0 with 1 tasks
2016-12-14 14:08:56.547 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 90.0 (TID 90, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:56.550 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 90.0 (TID 90)
2016-12-14 14:08:56.551 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:56.551 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:56.552 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 90.0 (TID 90). 1241 bytes result sent to driver
2016-12-14 14:08:56.553 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 90.0 (TID 90) in 6 ms on localhost (1/1)
2016-12-14 14:08:56.553 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.553 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 90 (take at LogStream.java:127) finished in 0.009 s
2016-12-14 14:08:56.554 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 45 finished: take at LogStream.java:127, took 0.039004 s
2016-12-14 14:08:56.558 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695731000 ms.1 from job set of time 1481695731000 ms
2016-12-14 14:08:56.558 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 5.558 s for time 1481695731000 ms (execution: 0.048 s)
2016-12-14 14:08:56.558 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695732000 ms.0 from job set of time 1481695732000 ms
2016-12-14 14:08:56.559 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695732000 ms.0 from job set of time 1481695732000 ms
2016-12-14 14:08:56.559 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695732000 ms.1 from job set of time 1481695732000 ms
2016-12-14 14:08:56.562 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:56.563 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 411 (union at DStream.scala:617)
2016-12-14 14:08:56.564 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 46 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:56.564 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 92 (take at LogStream.java:127)
2016-12-14 14:08:56.564 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 91)
2016-12-14 14:08:56.564 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 91)
2016-12-14 14:08:56.564 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695735000 ms
2016-12-14 14:08:56.564 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 91 (UnionRDD[411] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:56.565 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_91 stored as values in memory (estimated size 4.2 KB, free 435.9 KB)
2016-12-14 14:08:56.568 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_91_piece0 stored as bytes in memory (estimated size 2.4 KB, free 438.3 KB)
2016-12-14 14:08:56.568 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_91_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.569 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 91 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.569 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 91 (UnionRDD[411] at union at DStream.scala:617)
2016-12-14 14:08:56.569 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 91.0 with 1 tasks
2016-12-14 14:08:56.570 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 91.0 (TID 91, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:56.570 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 91.0 (TID 91)
2016-12-14 14:08:56.574 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 91.0 (TID 91). 1159 bytes result sent to driver
2016-12-14 14:08:56.575 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 91.0 (TID 91) in 5 ms on localhost (1/1)
2016-12-14 14:08:56.575 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.575 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 91 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:56.576 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:56.576 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:56.576 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 92)
2016-12-14 14:08:56.576 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:56.576 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 92 (MapPartitionsRDD[414] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:56.577 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_92 stored as values in memory (estimated size 3.7 KB, free 442.0 KB)
2016-12-14 14:08:56.599 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_90_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.599 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 91
2016-12-14 14:08:56.600 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_89_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.600 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.1 KB, free 435.9 KB)
2016-12-14 14:08:56.600 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 90
2016-12-14 14:08:56.601 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_92_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.601 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_88_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.601 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 89
2016-12-14 14:08:56.601 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 92 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.602 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_87_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.603 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 88
2016-12-14 14:08:56.603 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[414] at count at LogStream.java:120)
2016-12-14 14:08:56.603 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 92.0 with 1 tasks
2016-12-14 14:08:56.603 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_86_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.604 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 87
2016-12-14 14:08:56.604 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 92.0 (TID 92, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:56.605 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 92.0 (TID 92)
2016-12-14 14:08:56.605 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_85_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.605 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 86
2016-12-14 14:08:56.605 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 42
2016-12-14 14:08:56.606 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:56.606 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:56.606 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_84_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.607 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 85
2016-12-14 14:08:56.607 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 92.0 (TID 92). 1241 bytes result sent to driver
2016-12-14 14:08:56.607 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_83_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:08:56.608 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 84
2016-12-14 14:08:56.609 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 92.0 (TID 92) in 4 ms on localhost (1/1)
2016-12-14 14:08:56.609 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.609 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 41
2016-12-14 14:08:56.609 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 92 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:56.609 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_82_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:08:56.609 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 46 finished: take at LogStream.java:127, took 0.046707 s
2016-12-14 14:08:56.610 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 83
2016-12-14 14:08:56.610 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_81_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.611 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 82
2016-12-14 14:08:56.611 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 40
2016-12-14 14:08:56.611 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_80_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.612 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 81
2016-12-14 14:08:56.612 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_79_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.613 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 80
2016-12-14 14:08:56.613 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 39
2016-12-14 14:08:56.614 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_78_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.614 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 79
2016-12-14 14:08:56.615 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_77_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.615 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 78
2016-12-14 14:08:56.615 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 38
2016-12-14 14:08:56.616 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_76_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.616 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 77
2016-12-14 14:08:56.617 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_75_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.617 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 76
2016-12-14 14:08:56.618 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 37
2016-12-14 14:08:56.618 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_74_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.619 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 75
2016-12-14 14:08:56.619 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695732000 ms.1 from job set of time 1481695732000 ms
2016-12-14 14:08:56.619 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 4.619 s for time 1481695732000 ms (execution: 0.061 s)
2016-12-14 14:08:56.619 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695733000 ms.0 from job set of time 1481695733000 ms
2016-12-14 14:08:56.619 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695733000 ms.0 from job set of time 1481695733000 ms
2016-12-14 14:08:56.620 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695733000 ms.1 from job set of time 1481695733000 ms
2016-12-14 14:08:56.620 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_73_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.620 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 59
2016-12-14 14:08:56.621 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_57_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.621 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 58
2016-12-14 14:08:56.621 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 28
2016-12-14 14:08:56.622 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_56_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.622 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 57
2016-12-14 14:08:56.623 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_55_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.623 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 56
2016-12-14 14:08:56.623 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 27
2016-12-14 14:08:56.624 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_54_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.625 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 55
2016-12-14 14:08:56.625 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:56.625 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_53_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.626 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 54
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 420 (union at DStream.scala:617)
2016-12-14 14:08:56.626 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 26
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 47 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 94 (take at LogStream.java:127)
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 93)
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 93)
2016-12-14 14:08:56.626 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_52_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.626 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 93 (UnionRDD[420] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:56.627 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 53
2016-12-14 14:08:56.627 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_51_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.627 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 52
2016-12-14 14:08:56.627 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_93 stored as values in memory (estimated size 4.2 KB, free 292.2 KB)
2016-12-14 14:08:56.628 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 25
2016-12-14 14:08:56.628 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_50_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.629 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 51
2016-12-14 14:08:56.629 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_93_piece0 stored as bytes in memory (estimated size 2.4 KB, free 288.9 KB)
2016-12-14 14:08:56.629 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_93_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.629 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_49_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.630 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 50
2016-12-14 14:08:56.630 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 93 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.630 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 24
2016-12-14 14:08:56.630 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 93 (UnionRDD[420] at union at DStream.scala:617)
2016-12-14 14:08:56.630 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 93.0 with 1 tasks
2016-12-14 14:08:56.630 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_48_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.631 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 49
2016-12-14 14:08:56.631 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 93.0 (TID 93, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:56.631 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 93.0 (TID 93)
2016-12-14 14:08:56.631 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_47_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.632 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 48
2016-12-14 14:08:56.632 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 23
2016-12-14 14:08:56.632 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_46_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.633 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 47
2016-12-14 14:08:56.633 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_45_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.634 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 46
2016-12-14 14:08:56.634 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 93.0 (TID 93). 1159 bytes result sent to driver
2016-12-14 14:08:56.634 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 22
2016-12-14 14:08:56.634 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 93.0 (TID 93) in 3 ms on localhost (1/1)
2016-12-14 14:08:56.634 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.634 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_44_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 93 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:08:56.635 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 45
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 94)
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:56.635 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_43_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.635 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 94 (MapPartitionsRDD[423] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:56.635 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 44
2016-12-14 14:08:56.636 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 21
2016-12-14 14:08:56.636 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_42_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.636 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 43
2016-12-14 14:08:56.637 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_94 stored as values in memory (estimated size 3.7 KB, free 242.8 KB)
2016-12-14 14:08:56.637 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_41_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.637 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 42
2016-12-14 14:08:56.638 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 20
2016-12-14 14:08:56.638 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_94_piece0 stored as bytes in memory (estimated size 2.1 KB, free 238.2 KB)
2016-12-14 14:08:56.638 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_94_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.639 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_40_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.639 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 41
2016-12-14 14:08:56.639 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 94 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.639 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[423] at count at LogStream.java:120)
2016-12-14 14:08:56.639 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_39_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.639 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 94.0 with 1 tasks
2016-12-14 14:08:56.640 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 74
2016-12-14 14:08:56.640 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 36
2016-12-14 14:08:56.640 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 94.0 (TID 94, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:56.640 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 94.0 (TID 94)
2016-12-14 14:08:56.641 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_72_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.641 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 73
2016-12-14 14:08:56.641 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_71_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.642 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:56.642 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 72
2016-12-14 14:08:56.642 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:56.642 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 35
2016-12-14 14:08:56.643 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_70_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.643 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 71
2016-12-14 14:08:56.643 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 94.0 (TID 94). 1241 bytes result sent to driver
2016-12-14 14:08:56.644 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_69_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.644 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 94.0 (TID 94) in 4 ms on localhost (1/1)
2016-12-14 14:08:56.644 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.644 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 70
2016-12-14 14:08:56.644 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 94 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:08:56.644 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 34
2016-12-14 14:08:56.644 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 47 finished: take at LogStream.java:127, took 0.019540 s
2016-12-14 14:08:56.645 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_68_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.645 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 69
2016-12-14 14:08:56.646 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_67_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.646 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 68
2016-12-14 14:08:56.646 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 33
2016-12-14 14:08:56.647 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_66_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.647 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 67
2016-12-14 14:08:56.648 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_65_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.648 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 66
2016-12-14 14:08:56.648 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 32
2016-12-14 14:08:56.648 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695733000 ms.1 from job set of time 1481695733000 ms
2016-12-14 14:08:56.649 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 3.648 s for time 1481695733000 ms (execution: 0.029 s)
2016-12-14 14:08:56.649 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695734000 ms.0 from job set of time 1481695734000 ms
2016-12-14 14:08:56.649 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695734000 ms.0 from job set of time 1481695734000 ms
2016-12-14 14:08:56.649 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695734000 ms.1 from job set of time 1481695734000 ms
2016-12-14 14:08:56.649 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_64_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.649 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 65
2016-12-14 14:08:56.650 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_63_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.650 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 64
2016-12-14 14:08:56.651 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 31
2016-12-14 14:08:56.651 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_62_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.652 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 63
2016-12-14 14:08:56.652 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_61_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.653 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 62
2016-12-14 14:08:56.653 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 30
2016-12-14 14:08:56.653 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_60_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.654 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 61
2016-12-14 14:08:56.654 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:56.654 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_59_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.655 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 60
2016-12-14 14:08:56.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 429 (union at DStream.scala:617)
2016-12-14 14:08:56.655 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 29
2016-12-14 14:08:56.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 48 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:56.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 96 (take at LogStream.java:127)
2016-12-14 14:08:56.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 95)
2016-12-14 14:08:56.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 95)
2016-12-14 14:08:56.655 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_58_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.656 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 95 (UnionRDD[429] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:56.657 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_95 stored as values in memory (estimated size 4.2 KB, free 137.0 KB)
2016-12-14 14:08:56.658 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_95_piece0 stored as bytes in memory (estimated size 2.4 KB, free 139.4 KB)
2016-12-14 14:08:56.658 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_95_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.659 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 95 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.659 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 95 (UnionRDD[429] at union at DStream.scala:617)
2016-12-14 14:08:56.659 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 95.0 with 1 tasks
2016-12-14 14:08:56.660 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 95.0 (TID 95, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:56.660 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 95.0 (TID 95)
2016-12-14 14:08:56.663 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695736000 ms
2016-12-14 14:08:56.663 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 388 from persistence list
2016-12-14 14:08:56.663 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 388
2016-12-14 14:08:56.663 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 95.0 (TID 95). 1159 bytes result sent to driver
2016-12-14 14:08:56.664 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 95.0 (TID 95) in 4 ms on localhost (1/1)
2016-12-14 14:08:56.664 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[388] at createStream at LogStream.java:100 of time 1481695731000 ms
2016-12-14 14:08:56.664 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 95 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 96)
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:56.664 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 396 from persistence list
2016-12-14 14:08:56.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 96 (MapPartitionsRDD[432] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:56.664 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 396
2016-12-14 14:08:56.665 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 395 from persistence list
2016-12-14 14:08:56.665 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 395
2016-12-14 14:08:56.665 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 394 from persistence list
2016-12-14 14:08:56.666 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_96 stored as values in memory (estimated size 3.7 KB, free 143.1 KB)
2016-12-14 14:08:56.666 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 394
2016-12-14 14:08:56.666 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 393 from persistence list
2016-12-14 14:08:56.667 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 393
2016-12-14 14:08:56.667 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_96_piece0 stored as bytes in memory (estimated size 2.1 KB, free 145.3 KB)
2016-12-14 14:08:56.667 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 391 from persistence list
2016-12-14 14:08:56.667 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 391
2016-12-14 14:08:56.667 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_96_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.668 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 96 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.668 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 390 from persistence list
2016-12-14 14:08:56.668 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[432] at count at LogStream.java:120)
2016-12-14 14:08:56.668 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 96.0 with 1 tasks
2016-12-14 14:08:56.668 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 390
2016-12-14 14:08:56.668 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 389 from persistence list
2016-12-14 14:08:56.669 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 96.0 (TID 96, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:56.669 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 389
2016-12-14 14:08:56.669 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 96.0 (TID 96)
2016-12-14 14:08:56.669 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695729000 ms)
2016-12-14 14:08:56.669 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695729000 ms
2016-12-14 14:08:56.669 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 397 from persistence list
2016-12-14 14:08:56.670 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 397
2016-12-14 14:08:56.670 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:56.670 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:56.670 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[397] at createStream at LogStream.java:100 of time 1481695732000 ms
2016-12-14 14:08:56.670 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 405 from persistence list
2016-12-14 14:08:56.671 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 405
2016-12-14 14:08:56.671 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 404 from persistence list
2016-12-14 14:08:56.671 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 404
2016-12-14 14:08:56.671 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 96.0 (TID 96). 1241 bytes result sent to driver
2016-12-14 14:08:56.672 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 403 from persistence list
2016-12-14 14:08:56.672 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 96.0 (TID 96) in 4 ms on localhost (1/1)
2016-12-14 14:08:56.672 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.672 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 403
2016-12-14 14:08:56.672 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 402 from persistence list
2016-12-14 14:08:56.673 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 402
2016-12-14 14:08:56.673 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 400 from persistence list
2016-12-14 14:08:56.673 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 400
2016-12-14 14:08:56.673 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 399 from persistence list
2016-12-14 14:08:56.673 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 399
2016-12-14 14:08:56.673 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 398 from persistence list
2016-12-14 14:08:56.673 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 96 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:08:56.673 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 398
2016-12-14 14:08:56.673 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695730000 ms)
2016-12-14 14:08:56.673 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695730000 ms
2016-12-14 14:08:56.673 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 406 from persistence list
2016-12-14 14:08:56.674 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 48 finished: take at LogStream.java:127, took 0.019502 s
2016-12-14 14:08:56.674 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 406
2016-12-14 14:08:56.674 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[406] at createStream at LogStream.java:100 of time 1481695733000 ms
2016-12-14 14:08:56.674 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 414 from persistence list
2016-12-14 14:08:56.674 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 414
2016-12-14 14:08:56.674 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 413 from persistence list
2016-12-14 14:08:56.674 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 413
2016-12-14 14:08:56.674 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 412 from persistence list
2016-12-14 14:08:56.675 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 412
2016-12-14 14:08:56.675 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 411 from persistence list
2016-12-14 14:08:56.675 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 411
2016-12-14 14:08:56.675 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 409 from persistence list
2016-12-14 14:08:56.675 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 409
2016-12-14 14:08:56.675 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 408 from persistence list
2016-12-14 14:08:56.675 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 408
2016-12-14 14:08:56.676 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 407 from persistence list
2016-12-14 14:08:56.676 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 407
2016-12-14 14:08:56.676 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695731000 ms)
2016-12-14 14:08:56.676 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695731000 ms
2016-12-14 14:08:56.678 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695734000 ms.1 from job set of time 1481695734000 ms
2016-12-14 14:08:56.678 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 2.678 s for time 1481695734000 ms (execution: 0.029 s)
2016-12-14 14:08:56.678 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 415 from persistence list
2016-12-14 14:08:56.678 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695735000 ms.0 from job set of time 1481695735000 ms
2016-12-14 14:08:56.678 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695735000 ms.0 from job set of time 1481695735000 ms
2016-12-14 14:08:56.678 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 415
2016-12-14 14:08:56.678 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695735000 ms.1 from job set of time 1481695735000 ms
2016-12-14 14:08:56.678 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[415] at createStream at LogStream.java:100 of time 1481695734000 ms
2016-12-14 14:08:56.679 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 423 from persistence list
2016-12-14 14:08:56.679 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 423
2016-12-14 14:08:56.679 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 422 from persistence list
2016-12-14 14:08:56.679 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 422
2016-12-14 14:08:56.679 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 421 from persistence list
2016-12-14 14:08:56.679 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 421
2016-12-14 14:08:56.679 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 420 from persistence list
2016-12-14 14:08:56.680 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 420
2016-12-14 14:08:56.680 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 418 from persistence list
2016-12-14 14:08:56.680 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 418
2016-12-14 14:08:56.680 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 417 from persistence list
2016-12-14 14:08:56.680 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 417
2016-12-14 14:08:56.680 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 416 from persistence list
2016-12-14 14:08:56.680 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 416
2016-12-14 14:08:56.680 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695732000 ms)
2016-12-14 14:08:56.680 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695732000 ms
2016-12-14 14:08:56.683 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:08:56.683 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 438 (union at DStream.scala:617)
2016-12-14 14:08:56.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 49 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:08:56.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 98 (take at LogStream.java:127)
2016-12-14 14:08:56.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 97)
2016-12-14 14:08:56.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 97)
2016-12-14 14:08:56.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 97 (UnionRDD[438] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:08:56.685 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_97 stored as values in memory (estimated size 4.2 KB, free 149.5 KB)
2016-12-14 14:08:56.686 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_97_piece0 stored as bytes in memory (estimated size 2.4 KB, free 151.9 KB)
2016-12-14 14:08:56.686 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_97_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:08:56.687 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 97 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.687 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 97 (UnionRDD[438] at union at DStream.scala:617)
2016-12-14 14:08:56.687 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 97.0 with 1 tasks
2016-12-14 14:08:56.688 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 97.0 (TID 97, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:08:56.688 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 97.0 (TID 97)
2016-12-14 14:08:56.692 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 97.0 (TID 97). 1159 bytes result sent to driver
2016-12-14 14:08:56.692 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 97.0 (TID 97) in 4 ms on localhost (1/1)
2016-12-14 14:08:56.693 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 97 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 98)
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:08:56.693 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 98 (MapPartitionsRDD[441] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:08:56.694 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_98 stored as values in memory (estimated size 3.7 KB, free 155.6 KB)
2016-12-14 14:08:56.695 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_98_piece0 stored as bytes in memory (estimated size 2.1 KB, free 157.7 KB)
2016-12-14 14:08:56.695 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_98_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:08:56.696 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 98 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:08:56.696 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[441] at count at LogStream.java:120)
2016-12-14 14:08:56.696 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 98.0 with 1 tasks
2016-12-14 14:08:56.697 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 98.0 (TID 98, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:08:56.697 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 98.0 (TID 98)
2016-12-14 14:08:56.698 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:08:56.698 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:08:56.699 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 98.0 (TID 98). 1241 bytes result sent to driver
2016-12-14 14:08:56.700 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 98.0 (TID 98) in 3 ms on localhost (1/1)
2016-12-14 14:08:56.700 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2016-12-14 14:08:56.700 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 98 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:08:56.700 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 49 finished: take at LogStream.java:127, took 0.017408 s
2016-12-14 14:08:56.704 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695735000 ms.1 from job set of time 1481695735000 ms
2016-12-14 14:08:56.704 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 1.704 s for time 1481695735000 ms (execution: 0.026 s)
2016-12-14 14:08:56.704 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 424 from persistence list
2016-12-14 14:08:56.704 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695736000 ms.0 from job set of time 1481695736000 ms
2016-12-14 14:08:56.705 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695736000 ms.0 from job set of time 1481695736000 ms
2016-12-14 14:08:56.705 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695736000 ms.1 from job set of time 1481695736000 ms
2016-12-14 14:08:56.705 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 424
2016-12-14 14:08:56.705 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[424] at createStream at LogStream.java:100 of time 1481695735000 ms
2016-12-14 14:08:56.705 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 432 from persistence list
2016-12-14 14:08:56.705 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 432
2016-12-14 14:08:56.705 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 431 from persistence list
2016-12-14 14:08:56.705 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 431
2016-12-14 14:08:56.705 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 430 from persistence list
2016-12-14 14:08:56.706 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 430
2016-12-14 14:08:56.706 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 429 from persistence list
2016-12-14 14:08:56.710 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.504 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 429
2016-12-14 14:09:06.504 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 427 from persistence list
2016-12-14 14:09:06.504 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 426 from persistence list
2016-12-14 14:09:06.504 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 427
2016-12-14 14:09:06.504 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 447 (union at DStream.scala:617)
2016-12-14 14:09:06.504 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 425 from persistence list
2016-12-14 14:09:06.505 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 426
2016-12-14 14:09:06.505 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 50 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.506 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 100 (take at LogStream.java:127)
2016-12-14 14:09:06.506 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 425
2016-12-14 14:09:06.506 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 99)
2016-12-14 14:09:06.506 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695733000 ms)
2016-12-14 14:09:06.506 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 99)
2016-12-14 14:09:06.506 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695733000 ms
2016-12-14 14:09:06.506 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 99 (UnionRDD[447] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.507 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_99 stored as values in memory (estimated size 4.2 KB, free 161.9 KB)
2016-12-14 14:09:06.508 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.4 KB, free 164.4 KB)
2016-12-14 14:09:06.508 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_99_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.509 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 99 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.509 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 99 (UnionRDD[447] at union at DStream.scala:617)
2016-12-14 14:09:06.509 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 99.0 with 1 tasks
2016-12-14 14:09:06.510 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 99.0 (TID 99, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.510 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 99.0 (TID 99)
2016-12-14 14:09:06.516 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 99.0 (TID 99). 1159 bytes result sent to driver
2016-12-14 14:09:06.516 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695737000 ms
2016-12-14 14:09:06.517 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 99.0 (TID 99) in 8 ms on localhost (1/1)
2016-12-14 14:09:06.517 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.517 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 99 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:09:06.517 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.517 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.517 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 100)
2016-12-14 14:09:06.517 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.518 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 100 (MapPartitionsRDD[450] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.519 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_100 stored as values in memory (estimated size 3.7 KB, free 168.0 KB)
2016-12-14 14:09:06.520 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_100_piece0 stored as bytes in memory (estimated size 2.1 KB, free 170.2 KB)
2016-12-14 14:09:06.521 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_100_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.523 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 100 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.523 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[450] at count at LogStream.java:120)
2016-12-14 14:09:06.523 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 100.0 with 1 tasks
2016-12-14 14:09:06.524 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 100.0 (TID 100, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.526 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 100.0 (TID 100)
2016-12-14 14:09:06.527 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695738000 ms
2016-12-14 14:09:06.527 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.527 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.529 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 100.0 (TID 100). 1241 bytes result sent to driver
2016-12-14 14:09:06.531 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 100.0 (TID 100) in 7 ms on localhost (1/1)
2016-12-14 14:09:06.532 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.533 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 100 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:09:06.533 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 50 finished: take at LogStream.java:127, took 0.029748 s
2016-12-14 14:09:06.539 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695739000 ms
2016-12-14 14:09:06.546 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695736000 ms.1 from job set of time 1481695736000 ms
2016-12-14 14:09:06.546 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 10.546 s for time 1481695736000 ms (execution: 9.842 s)
2016-12-14 14:09:06.546 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695737000 ms.0 from job set of time 1481695737000 ms
2016-12-14 14:09:06.546 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695737000 ms.0 from job set of time 1481695737000 ms
2016-12-14 14:09:06.547 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695737000 ms.1 from job set of time 1481695737000 ms
2016-12-14 14:09:06.552 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695740000 ms
2016-12-14 14:09:06.554 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.554 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 456 (union at DStream.scala:617)
2016-12-14 14:09:06.555 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 51 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.555 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 102 (take at LogStream.java:127)
2016-12-14 14:09:06.555 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 101)
2016-12-14 14:09:06.555 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 101)
2016-12-14 14:09:06.555 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 101 (UnionRDD[456] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.556 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_101 stored as values in memory (estimated size 4.2 KB, free 174.4 KB)
2016-12-14 14:09:06.557 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.4 KB, free 176.8 KB)
2016-12-14 14:09:06.559 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_101_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.559 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 101 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.559 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 101 (UnionRDD[456] at union at DStream.scala:617)
2016-12-14 14:09:06.559 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 101.0 with 1 tasks
2016-12-14 14:09:06.560 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 101.0 (TID 101, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.561 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 101.0 (TID 101)
2016-12-14 14:09:06.563 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695741000 ms
2016-12-14 14:09:06.564 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 101.0 (TID 101). 1159 bytes result sent to driver
2016-12-14 14:09:06.566 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 101.0 (TID 101) in 6 ms on localhost (1/1)
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 101 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:09:06.566 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 102)
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.566 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 102 (MapPartitionsRDD[459] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.567 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_102 stored as values in memory (estimated size 3.7 KB, free 180.5 KB)
2016-12-14 14:09:06.568 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_102_piece0 stored as bytes in memory (estimated size 2.1 KB, free 182.6 KB)
2016-12-14 14:09:06.569 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_102_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.569 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 102 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.570 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[459] at count at LogStream.java:120)
2016-12-14 14:09:06.570 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 102.0 with 1 tasks
2016-12-14 14:09:06.570 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 102.0 (TID 102, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.571 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 102.0 (TID 102)
2016-12-14 14:09:06.572 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.572 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.573 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 102.0 (TID 102). 1241 bytes result sent to driver
2016-12-14 14:09:06.573 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695742000 ms
2016-12-14 14:09:06.574 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 102.0 (TID 102) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.574 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.574 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 102 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:06.574 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 51 finished: take at LogStream.java:127, took 0.020260 s
2016-12-14 14:09:06.581 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695737000 ms.1 from job set of time 1481695737000 ms
2016-12-14 14:09:06.581 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 9.581 s for time 1481695737000 ms (execution: 0.035 s)
2016-12-14 14:09:06.581 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695738000 ms.0 from job set of time 1481695738000 ms
2016-12-14 14:09:06.581 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695738000 ms.0 from job set of time 1481695738000 ms
2016-12-14 14:09:06.581 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695738000 ms.1 from job set of time 1481695738000 ms
2016-12-14 14:09:06.583 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695743000 ms
2016-12-14 14:09:06.588 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.589 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 465 (union at DStream.scala:617)
2016-12-14 14:09:06.589 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 52 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.589 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 104 (take at LogStream.java:127)
2016-12-14 14:09:06.589 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 103)
2016-12-14 14:09:06.589 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 103)
2016-12-14 14:09:06.590 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 103 (UnionRDD[465] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.590 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_103 stored as values in memory (estimated size 4.2 KB, free 186.8 KB)
2016-12-14 14:09:06.592 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.4 KB, free 189.3 KB)
2016-12-14 14:09:06.592 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695744000 ms
2016-12-14 14:09:06.594 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_103_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.594 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 103 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.595 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 103 (UnionRDD[465] at union at DStream.scala:617)
2016-12-14 14:09:06.595 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 103.0 with 1 tasks
2016-12-14 14:09:06.598 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 103.0 (TID 103, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.599 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 103.0 (TID 103)
2016-12-14 14:09:06.601 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695745000 ms
2016-12-14 14:09:06.602 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 103.0 (TID 103). 1159 bytes result sent to driver
2016-12-14 14:09:06.602 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 103.0 (TID 103) in 4 ms on localhost (1/1)
2016-12-14 14:09:06.603 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.603 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 103 (union at DStream.scala:617) finished in 0.008 s
2016-12-14 14:09:06.604 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.604 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.604 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 104)
2016-12-14 14:09:06.604 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.604 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 104 (MapPartitionsRDD[468] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.608 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_104 stored as values in memory (estimated size 3.7 KB, free 193.0 KB)
2016-12-14 14:09:06.609 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_104_piece0 stored as bytes in memory (estimated size 2.1 KB, free 195.1 KB)
2016-12-14 14:09:06.610 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_104_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.610 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 104 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.610 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[468] at count at LogStream.java:120)
2016-12-14 14:09:06.610 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 104.0 with 1 tasks
2016-12-14 14:09:06.611 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 104.0 (TID 104, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.611 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695746000 ms
2016-12-14 14:09:06.611 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 104.0 (TID 104)
2016-12-14 14:09:06.611 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 433 from persistence list
2016-12-14 14:09:06.612 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[433] at createStream at LogStream.java:100 of time 1481695736000 ms
2016-12-14 14:09:06.612 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 441 from persistence list
2016-12-14 14:09:06.612 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 433
2016-12-14 14:09:06.613 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.613 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.613 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 440 from persistence list
2016-12-14 14:09:06.613 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 441
2016-12-14 14:09:06.614 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 104.0 (TID 104). 1241 bytes result sent to driver
2016-12-14 14:09:06.614 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 439 from persistence list
2016-12-14 14:09:06.615 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 440
2016-12-14 14:09:06.615 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 438 from persistence list
2016-12-14 14:09:06.615 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 104.0 (TID 104) in 4 ms on localhost (1/1)
2016-12-14 14:09:06.615 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 439
2016-12-14 14:09:06.615 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.616 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 104 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:09:06.616 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 436 from persistence list
2016-12-14 14:09:06.616 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 438
2016-12-14 14:09:06.616 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 52 finished: take at LogStream.java:127, took 0.027584 s
2016-12-14 14:09:06.616 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 435 from persistence list
2016-12-14 14:09:06.616 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 436
2016-12-14 14:09:06.617 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 435
2016-12-14 14:09:06.617 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 434 from persistence list
2016-12-14 14:09:06.617 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695734000 ms)
2016-12-14 14:09:06.617 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695734000 ms
2016-12-14 14:09:06.617 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 442 from persistence list
2016-12-14 14:09:06.618 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 434
2016-12-14 14:09:06.618 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[442] at createStream at LogStream.java:100 of time 1481695737000 ms
2016-12-14 14:09:06.618 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 450 from persistence list
2016-12-14 14:09:06.618 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 442
2016-12-14 14:09:06.619 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 449 from persistence list
2016-12-14 14:09:06.619 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 450
2016-12-14 14:09:06.619 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 448 from persistence list
2016-12-14 14:09:06.619 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 449
2016-12-14 14:09:06.619 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 447 from persistence list
2016-12-14 14:09:06.620 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 448
2016-12-14 14:09:06.620 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 445 from persistence list
2016-12-14 14:09:06.620 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 447
2016-12-14 14:09:06.620 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 445
2016-12-14 14:09:06.620 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 444 from persistence list
2016-12-14 14:09:06.620 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 444
2016-12-14 14:09:06.620 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 443 from persistence list
2016-12-14 14:09:06.621 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 443
2016-12-14 14:09:06.621 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695735000 ms)
2016-12-14 14:09:06.621 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695735000 ms
2016-12-14 14:09:06.622 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695738000 ms.1 from job set of time 1481695738000 ms
2016-12-14 14:09:06.622 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 8.622 s for time 1481695738000 ms (execution: 0.041 s)
2016-12-14 14:09:06.623 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695739000 ms.0 from job set of time 1481695739000 ms
2016-12-14 14:09:06.623 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 451 from persistence list
2016-12-14 14:09:06.623 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695739000 ms.0 from job set of time 1481695739000 ms
2016-12-14 14:09:06.623 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695739000 ms.1 from job set of time 1481695739000 ms
2016-12-14 14:09:06.624 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[451] at createStream at LogStream.java:100 of time 1481695738000 ms
2016-12-14 14:09:06.624 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 459 from persistence list
2016-12-14 14:09:06.624 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 451
2016-12-14 14:09:06.624 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 458 from persistence list
2016-12-14 14:09:06.624 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 459
2016-12-14 14:09:06.625 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 457 from persistence list
2016-12-14 14:09:06.625 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 458
2016-12-14 14:09:06.625 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 456 from persistence list
2016-12-14 14:09:06.625 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 457
2016-12-14 14:09:06.627 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.627 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 454 from persistence list
2016-12-14 14:09:06.627 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 456
2016-12-14 14:09:06.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 474 (union at DStream.scala:617)
2016-12-14 14:09:06.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 53 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 106 (take at LogStream.java:127)
2016-12-14 14:09:06.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 105)
2016-12-14 14:09:06.628 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 105)
2016-12-14 14:09:06.628 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 453 from persistence list
2016-12-14 14:09:06.628 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 454
2016-12-14 14:09:06.629 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 105 (UnionRDD[474] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.629 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 453
2016-12-14 14:09:06.629 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 452 from persistence list
2016-12-14 14:09:06.630 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 452
2016-12-14 14:09:06.630 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695736000 ms)
2016-12-14 14:09:06.630 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695736000 ms
2016-12-14 14:09:06.630 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_105 stored as values in memory (estimated size 4.2 KB, free 199.3 KB)
2016-12-14 14:09:06.631 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.4 KB, free 201.7 KB)
2016-12-14 14:09:06.632 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_105_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.632 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 105 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.632 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 105 (UnionRDD[474] at union at DStream.scala:617)
2016-12-14 14:09:06.632 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 105.0 with 1 tasks
2016-12-14 14:09:06.633 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 105.0 (TID 105, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.633 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 105.0 (TID 105)
2016-12-14 14:09:06.636 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 105.0 (TID 105). 1159 bytes result sent to driver
2016-12-14 14:09:06.638 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 105.0 (TID 105) in 5 ms on localhost (1/1)
2016-12-14 14:09:06.638 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 105 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:09:06.638 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.638 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.639 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.639 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 106)
2016-12-14 14:09:06.639 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.639 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 106 (MapPartitionsRDD[477] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.640 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_106 stored as values in memory (estimated size 3.7 KB, free 205.4 KB)
2016-12-14 14:09:06.641 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_106_piece0 stored as bytes in memory (estimated size 2.1 KB, free 207.5 KB)
2016-12-14 14:09:06.641 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_106_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.641 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 106 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.641 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[477] at count at LogStream.java:120)
2016-12-14 14:09:06.641 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 106.0 with 1 tasks
2016-12-14 14:09:06.642 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 106.0 (TID 106, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.642 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 106.0 (TID 106)
2016-12-14 14:09:06.643 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.643 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.644 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 106.0 (TID 106). 1241 bytes result sent to driver
2016-12-14 14:09:06.645 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 106.0 (TID 106) in 2 ms on localhost (1/1)
2016-12-14 14:09:06.645 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.645 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 106 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.645 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 53 finished: take at LogStream.java:127, took 0.018600 s
2016-12-14 14:09:06.650 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695739000 ms.1 from job set of time 1481695739000 ms
2016-12-14 14:09:06.650 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 7.650 s for time 1481695739000 ms (execution: 0.028 s)
2016-12-14 14:09:06.650 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695740000 ms.0 from job set of time 1481695740000 ms
2016-12-14 14:09:06.651 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 460 from persistence list
2016-12-14 14:09:06.651 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695740000 ms.0 from job set of time 1481695740000 ms
2016-12-14 14:09:06.651 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695740000 ms.1 from job set of time 1481695740000 ms
2016-12-14 14:09:06.651 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 460
2016-12-14 14:09:06.651 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[460] at createStream at LogStream.java:100 of time 1481695739000 ms
2016-12-14 14:09:06.651 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 468 from persistence list
2016-12-14 14:09:06.652 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 468
2016-12-14 14:09:06.652 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 467 from persistence list
2016-12-14 14:09:06.652 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 467
2016-12-14 14:09:06.652 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 466 from persistence list
2016-12-14 14:09:06.652 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 466
2016-12-14 14:09:06.652 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 465 from persistence list
2016-12-14 14:09:06.652 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 465
2016-12-14 14:09:06.652 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 463 from persistence list
2016-12-14 14:09:06.652 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 463
2016-12-14 14:09:06.653 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 462 from persistence list
2016-12-14 14:09:06.653 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 462
2016-12-14 14:09:06.653 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 461 from persistence list
2016-12-14 14:09:06.653 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 461
2016-12-14 14:09:06.653 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695737000 ms)
2016-12-14 14:09:06.653 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695737000 ms
2016-12-14 14:09:06.654 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 483 (union at DStream.scala:617)
2016-12-14 14:09:06.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 54 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 108 (take at LogStream.java:127)
2016-12-14 14:09:06.655 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 107)
2016-12-14 14:09:06.656 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 107)
2016-12-14 14:09:06.656 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 107 (UnionRDD[483] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.657 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_107 stored as values in memory (estimated size 4.2 KB, free 211.7 KB)
2016-12-14 14:09:06.658 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.4 KB, free 214.2 KB)
2016-12-14 14:09:06.658 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_107_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.658 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 107 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.658 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 107 (UnionRDD[483] at union at DStream.scala:617)
2016-12-14 14:09:06.658 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 107.0 with 1 tasks
2016-12-14 14:09:06.660 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 107.0 (TID 107, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.660 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 107.0 (TID 107)
2016-12-14 14:09:06.664 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 107.0 (TID 107). 1159 bytes result sent to driver
2016-12-14 14:09:06.664 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 107.0 (TID 107) in 5 ms on localhost (1/1)
2016-12-14 14:09:06.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 107 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:06.664 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 108)
2016-12-14 14:09:06.664 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.665 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 108 (MapPartitionsRDD[486] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.666 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_108 stored as values in memory (estimated size 3.7 KB, free 217.9 KB)
2016-12-14 14:09:06.667 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_108_piece0 stored as bytes in memory (estimated size 2.1 KB, free 220.0 KB)
2016-12-14 14:09:06.667 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_108_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.667 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 108 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.667 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[486] at count at LogStream.java:120)
2016-12-14 14:09:06.667 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 108.0 with 1 tasks
2016-12-14 14:09:06.668 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 108.0 (TID 108, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.668 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 108.0 (TID 108)
2016-12-14 14:09:06.669 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.669 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.670 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 108.0 (TID 108). 1241 bytes result sent to driver
2016-12-14 14:09:06.671 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 108.0 (TID 108) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.671 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 108 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.671 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.671 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 54 finished: take at LogStream.java:127, took 0.016367 s
2016-12-14 14:09:06.676 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695740000 ms.1 from job set of time 1481695740000 ms
2016-12-14 14:09:06.676 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 6.676 s for time 1481695740000 ms (execution: 0.026 s)
2016-12-14 14:09:06.676 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 469 from persistence list
2016-12-14 14:09:06.676 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695741000 ms.0 from job set of time 1481695741000 ms
2016-12-14 14:09:06.676 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695741000 ms.0 from job set of time 1481695741000 ms
2016-12-14 14:09:06.676 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695741000 ms.1 from job set of time 1481695741000 ms
2016-12-14 14:09:06.676 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 469
2016-12-14 14:09:06.676 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[469] at createStream at LogStream.java:100 of time 1481695740000 ms
2016-12-14 14:09:06.676 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 477 from persistence list
2016-12-14 14:09:06.676 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 477
2016-12-14 14:09:06.677 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 476 from persistence list
2016-12-14 14:09:06.677 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 476
2016-12-14 14:09:06.677 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 475 from persistence list
2016-12-14 14:09:06.677 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 475
2016-12-14 14:09:06.677 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 474 from persistence list
2016-12-14 14:09:06.677 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 474
2016-12-14 14:09:06.677 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 472 from persistence list
2016-12-14 14:09:06.677 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 472
2016-12-14 14:09:06.677 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 471 from persistence list
2016-12-14 14:09:06.677 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 471
2016-12-14 14:09:06.677 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 470 from persistence list
2016-12-14 14:09:06.678 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 470
2016-12-14 14:09:06.678 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695738000 ms)
2016-12-14 14:09:06.678 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695738000 ms
2016-12-14 14:09:06.680 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.681 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 492 (union at DStream.scala:617)
2016-12-14 14:09:06.681 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 55 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.681 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 110 (take at LogStream.java:127)
2016-12-14 14:09:06.681 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 109)
2016-12-14 14:09:06.681 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 109)
2016-12-14 14:09:06.682 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 109 (UnionRDD[492] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.682 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_109 stored as values in memory (estimated size 4.2 KB, free 224.2 KB)
2016-12-14 14:09:06.683 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_109_piece0 stored as bytes in memory (estimated size 2.4 KB, free 226.6 KB)
2016-12-14 14:09:06.684 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_109_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.684 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 109 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.684 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 109 (UnionRDD[492] at union at DStream.scala:617)
2016-12-14 14:09:06.684 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 109.0 with 1 tasks
2016-12-14 14:09:06.685 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 109.0 (TID 109, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.685 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 109.0 (TID 109)
2016-12-14 14:09:06.688 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 109.0 (TID 109). 1159 bytes result sent to driver
2016-12-14 14:09:06.688 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 109.0 (TID 109) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.688 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.688 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 109 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:06.688 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.688 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.688 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 110)
2016-12-14 14:09:06.688 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.689 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 110 (MapPartitionsRDD[495] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.689 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_110 stored as values in memory (estimated size 3.7 KB, free 230.3 KB)
2016-12-14 14:09:06.691 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_110_piece0 stored as bytes in memory (estimated size 2.1 KB, free 232.4 KB)
2016-12-14 14:09:06.691 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_110_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.691 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 110 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.691 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[495] at count at LogStream.java:120)
2016-12-14 14:09:06.691 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 110.0 with 1 tasks
2016-12-14 14:09:06.692 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 110.0 (TID 110, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.692 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 110.0 (TID 110)
2016-12-14 14:09:06.693 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.693 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.694 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 110.0 (TID 110). 1241 bytes result sent to driver
2016-12-14 14:09:06.694 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 110.0 (TID 110) in 2 ms on localhost (1/1)
2016-12-14 14:09:06.695 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 110 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.695 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.695 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 55 finished: take at LogStream.java:127, took 0.014476 s
2016-12-14 14:09:06.702 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695741000 ms.1 from job set of time 1481695741000 ms
2016-12-14 14:09:06.702 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 5.702 s for time 1481695741000 ms (execution: 0.026 s)
2016-12-14 14:09:06.702 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 478 from persistence list
2016-12-14 14:09:06.702 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695742000 ms.0 from job set of time 1481695742000 ms
2016-12-14 14:09:06.702 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695742000 ms.0 from job set of time 1481695742000 ms
2016-12-14 14:09:06.702 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695742000 ms.1 from job set of time 1481695742000 ms
2016-12-14 14:09:06.702 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 478
2016-12-14 14:09:06.702 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[478] at createStream at LogStream.java:100 of time 1481695741000 ms
2016-12-14 14:09:06.702 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 486 from persistence list
2016-12-14 14:09:06.702 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 486
2016-12-14 14:09:06.702 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 485 from persistence list
2016-12-14 14:09:06.702 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 485
2016-12-14 14:09:06.703 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 484 from persistence list
2016-12-14 14:09:06.703 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 484
2016-12-14 14:09:06.703 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 483 from persistence list
2016-12-14 14:09:06.703 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 483
2016-12-14 14:09:06.703 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 481 from persistence list
2016-12-14 14:09:06.703 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 481
2016-12-14 14:09:06.703 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 480 from persistence list
2016-12-14 14:09:06.703 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 480
2016-12-14 14:09:06.703 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 479 from persistence list
2016-12-14 14:09:06.703 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 479
2016-12-14 14:09:06.703 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695739000 ms)
2016-12-14 14:09:06.703 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695739000 ms
2016-12-14 14:09:06.706 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 501 (union at DStream.scala:617)
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 56 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 112 (take at LogStream.java:127)
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 111)
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 111)
2016-12-14 14:09:06.707 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 111 (UnionRDD[501] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.708 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_111 stored as values in memory (estimated size 4.2 KB, free 236.6 KB)
2016-12-14 14:09:06.710 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_111_piece0 stored as bytes in memory (estimated size 2.4 KB, free 239.1 KB)
2016-12-14 14:09:06.710 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_111_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.710 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 111 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.711 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 111 (UnionRDD[501] at union at DStream.scala:617)
2016-12-14 14:09:06.711 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 111.0 with 1 tasks
2016-12-14 14:09:06.711 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 111.0 (TID 111, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.711 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 111.0 (TID 111)
2016-12-14 14:09:06.714 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 111.0 (TID 111). 1159 bytes result sent to driver
2016-12-14 14:09:06.715 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 111.0 (TID 111) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 111 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:06.715 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 112)
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.715 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 112 (MapPartitionsRDD[504] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.716 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_112 stored as values in memory (estimated size 3.7 KB, free 242.8 KB)
2016-12-14 14:09:06.717 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_112_piece0 stored as bytes in memory (estimated size 2.1 KB, free 244.9 KB)
2016-12-14 14:09:06.717 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_112_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.717 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 112 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.718 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[504] at count at LogStream.java:120)
2016-12-14 14:09:06.718 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 112.0 with 1 tasks
2016-12-14 14:09:06.718 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 112.0 (TID 112, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.718 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 112.0 (TID 112)
2016-12-14 14:09:06.719 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.719 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.720 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 112.0 (TID 112). 1241 bytes result sent to driver
2016-12-14 14:09:06.721 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 112.0 (TID 112) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.721 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 112 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.721 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.721 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 56 finished: take at LogStream.java:127, took 0.014878 s
2016-12-14 14:09:06.726 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695742000 ms.1 from job set of time 1481695742000 ms
2016-12-14 14:09:06.726 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 4.726 s for time 1481695742000 ms (execution: 0.024 s)
2016-12-14 14:09:06.726 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 487 from persistence list
2016-12-14 14:09:06.726 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695743000 ms.0 from job set of time 1481695743000 ms
2016-12-14 14:09:06.726 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 487
2016-12-14 14:09:06.726 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695743000 ms.0 from job set of time 1481695743000 ms
2016-12-14 14:09:06.726 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[487] at createStream at LogStream.java:100 of time 1481695742000 ms
2016-12-14 14:09:06.726 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695743000 ms.1 from job set of time 1481695743000 ms
2016-12-14 14:09:06.727 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 495 from persistence list
2016-12-14 14:09:06.727 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 495
2016-12-14 14:09:06.727 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 494 from persistence list
2016-12-14 14:09:06.727 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 494
2016-12-14 14:09:06.727 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 493 from persistence list
2016-12-14 14:09:06.727 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 493
2016-12-14 14:09:06.727 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 492 from persistence list
2016-12-14 14:09:06.727 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 492
2016-12-14 14:09:06.727 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 490 from persistence list
2016-12-14 14:09:06.727 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 490
2016-12-14 14:09:06.727 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 489 from persistence list
2016-12-14 14:09:06.728 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 489
2016-12-14 14:09:06.728 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 488 from persistence list
2016-12-14 14:09:06.728 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 488
2016-12-14 14:09:06.728 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695740000 ms)
2016-12-14 14:09:06.728 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695740000 ms
2016-12-14 14:09:06.730 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 510 (union at DStream.scala:617)
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 57 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 114 (take at LogStream.java:127)
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 113)
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 113)
2016-12-14 14:09:06.731 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 113 (UnionRDD[510] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.732 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_113 stored as values in memory (estimated size 4.2 KB, free 249.1 KB)
2016-12-14 14:09:06.733 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_113_piece0 stored as bytes in memory (estimated size 2.4 KB, free 251.5 KB)
2016-12-14 14:09:06.734 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_113_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.734 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 113 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.734 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 113 (UnionRDD[510] at union at DStream.scala:617)
2016-12-14 14:09:06.734 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 113.0 with 1 tasks
2016-12-14 14:09:06.735 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 113.0 (TID 113, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.735 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 113.0 (TID 113)
2016-12-14 14:09:06.737 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 113.0 (TID 113). 1159 bytes result sent to driver
2016-12-14 14:09:06.738 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 113.0 (TID 113) in 4 ms on localhost (1/1)
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 113 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:06.738 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 114)
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.738 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 114 (MapPartitionsRDD[513] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.739 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_114 stored as values in memory (estimated size 3.7 KB, free 255.2 KB)
2016-12-14 14:09:06.740 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_114_piece0 stored as bytes in memory (estimated size 2.1 KB, free 257.3 KB)
2016-12-14 14:09:06.740 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_114_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.741 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 114 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.741 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[513] at count at LogStream.java:120)
2016-12-14 14:09:06.741 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 114.0 with 1 tasks
2016-12-14 14:09:06.741 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 114.0 (TID 114, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.741 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 114.0 (TID 114)
2016-12-14 14:09:06.742 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.742 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:06.743 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 114.0 (TID 114). 1241 bytes result sent to driver
2016-12-14 14:09:06.744 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 114.0 (TID 114) in 2 ms on localhost (1/1)
2016-12-14 14:09:06.744 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 114 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.744 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.744 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 57 finished: take at LogStream.java:127, took 0.013359 s
2016-12-14 14:09:06.748 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695743000 ms.1 from job set of time 1481695743000 ms
2016-12-14 14:09:06.749 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 3.748 s for time 1481695743000 ms (execution: 0.022 s)
2016-12-14 14:09:06.749 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 496 from persistence list
2016-12-14 14:09:06.749 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695744000 ms.0 from job set of time 1481695744000 ms
2016-12-14 14:09:06.749 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 496
2016-12-14 14:09:06.749 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695744000 ms.0 from job set of time 1481695744000 ms
2016-12-14 14:09:06.749 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[496] at createStream at LogStream.java:100 of time 1481695743000 ms
2016-12-14 14:09:06.749 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695744000 ms.1 from job set of time 1481695744000 ms
2016-12-14 14:09:06.749 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 504 from persistence list
2016-12-14 14:09:06.749 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 504
2016-12-14 14:09:06.749 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 503 from persistence list
2016-12-14 14:09:06.749 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 503
2016-12-14 14:09:06.749 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 502 from persistence list
2016-12-14 14:09:06.750 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 502
2016-12-14 14:09:06.750 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 501 from persistence list
2016-12-14 14:09:06.750 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 501
2016-12-14 14:09:06.750 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 499 from persistence list
2016-12-14 14:09:06.750 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 499
2016-12-14 14:09:06.750 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 498 from persistence list
2016-12-14 14:09:06.750 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 498
2016-12-14 14:09:06.750 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 497 from persistence list
2016-12-14 14:09:06.750 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 497
2016-12-14 14:09:06.750 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695741000 ms)
2016-12-14 14:09:06.750 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695741000 ms
2016-12-14 14:09:06.752 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 519 (union at DStream.scala:617)
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 58 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 116 (take at LogStream.java:127)
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 115)
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 115)
2016-12-14 14:09:06.753 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 115 (UnionRDD[519] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.754 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_115 stored as values in memory (estimated size 4.2 KB, free 261.5 KB)
2016-12-14 14:09:06.755 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_115_piece0 stored as bytes in memory (estimated size 2.4 KB, free 264.0 KB)
2016-12-14 14:09:06.755 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_115_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.756 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 115 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.756 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 115 (UnionRDD[519] at union at DStream.scala:617)
2016-12-14 14:09:06.756 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 115.0 with 1 tasks
2016-12-14 14:09:06.756 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 115.0 (TID 115, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.757 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 115.0 (TID 115)
2016-12-14 14:09:06.760 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 115.0 (TID 115). 1159 bytes result sent to driver
2016-12-14 14:09:06.760 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 115.0 (TID 115) in 4 ms on localhost (1/1)
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 115 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:06.761 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 116)
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.761 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 116 (MapPartitionsRDD[522] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.762 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_116 stored as values in memory (estimated size 3.7 KB, free 267.7 KB)
2016-12-14 14:09:06.763 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_116_piece0 stored as bytes in memory (estimated size 2.1 KB, free 269.8 KB)
2016-12-14 14:09:06.763 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_116_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.764 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 116 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.764 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[522] at count at LogStream.java:120)
2016-12-14 14:09:06.764 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 116.0 with 1 tasks
2016-12-14 14:09:06.764 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 116.0 (TID 116, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.764 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 116.0 (TID 116)
2016-12-14 14:09:06.765 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.766 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:06.766 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 116.0 (TID 116). 1241 bytes result sent to driver
2016-12-14 14:09:06.767 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 116.0 (TID 116) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.767 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 116 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.767 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.767 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 58 finished: take at LogStream.java:127, took 0.014480 s
2016-12-14 14:09:06.772 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695744000 ms.1 from job set of time 1481695744000 ms
2016-12-14 14:09:06.772 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 2.772 s for time 1481695744000 ms (execution: 0.023 s)
2016-12-14 14:09:06.772 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695745000 ms.0 from job set of time 1481695745000 ms
2016-12-14 14:09:06.772 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 505 from persistence list
2016-12-14 14:09:06.772 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 505
2016-12-14 14:09:06.773 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695745000 ms.0 from job set of time 1481695745000 ms
2016-12-14 14:09:06.773 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[505] at createStream at LogStream.java:100 of time 1481695744000 ms
2016-12-14 14:09:06.773 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695745000 ms.1 from job set of time 1481695745000 ms
2016-12-14 14:09:06.773 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 513 from persistence list
2016-12-14 14:09:06.773 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 513
2016-12-14 14:09:06.773 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 512 from persistence list
2016-12-14 14:09:06.773 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 512
2016-12-14 14:09:06.773 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 511 from persistence list
2016-12-14 14:09:06.773 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 511
2016-12-14 14:09:06.773 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 510 from persistence list
2016-12-14 14:09:06.773 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 510
2016-12-14 14:09:06.773 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 508 from persistence list
2016-12-14 14:09:06.774 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 508
2016-12-14 14:09:06.774 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 507 from persistence list
2016-12-14 14:09:06.774 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 507
2016-12-14 14:09:06.774 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 506 from persistence list
2016-12-14 14:09:06.774 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 506
2016-12-14 14:09:06.774 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695742000 ms)
2016-12-14 14:09:06.774 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695742000 ms
2016-12-14 14:09:06.777 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 528 (union at DStream.scala:617)
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 59 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 118 (take at LogStream.java:127)
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 117)
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 117)
2016-12-14 14:09:06.778 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 117 (UnionRDD[528] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.779 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_117 stored as values in memory (estimated size 4.2 KB, free 274.0 KB)
2016-12-14 14:09:06.780 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_117_piece0 stored as bytes in memory (estimated size 2.4 KB, free 276.4 KB)
2016-12-14 14:09:06.781 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_117_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.781 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 117 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.781 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 117 (UnionRDD[528] at union at DStream.scala:617)
2016-12-14 14:09:06.781 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 117.0 with 1 tasks
2016-12-14 14:09:06.782 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 117.0 (TID 117, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.782 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 117.0 (TID 117)
2016-12-14 14:09:06.785 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 117.0 (TID 117). 1159 bytes result sent to driver
2016-12-14 14:09:06.786 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 117.0 (TID 117) in 4 ms on localhost (1/1)
2016-12-14 14:09:06.786 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 117 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 118)
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 118 (MapPartitionsRDD[531] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.787 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_118 stored as values in memory (estimated size 3.7 KB, free 280.1 KB)
2016-12-14 14:09:06.788 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_118_piece0 stored as bytes in memory (estimated size 2.1 KB, free 282.2 KB)
2016-12-14 14:09:06.788 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_118_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.789 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 118 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.789 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[531] at count at LogStream.java:120)
2016-12-14 14:09:06.789 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 118.0 with 1 tasks
2016-12-14 14:09:06.789 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 118.0 (TID 118, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.790 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 118.0 (TID 118)
2016-12-14 14:09:06.790 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.791 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:06.791 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 118.0 (TID 118). 1241 bytes result sent to driver
2016-12-14 14:09:06.792 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 118.0 (TID 118) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.792 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 118 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.792 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.792 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 59 finished: take at LogStream.java:127, took 0.014509 s
2016-12-14 14:09:06.798 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695745000 ms.1 from job set of time 1481695745000 ms
2016-12-14 14:09:06.798 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 1.798 s for time 1481695745000 ms (execution: 0.026 s)
2016-12-14 14:09:06.798 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695746000 ms.0 from job set of time 1481695746000 ms
2016-12-14 14:09:06.798 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 514 from persistence list
2016-12-14 14:09:06.798 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695746000 ms.0 from job set of time 1481695746000 ms
2016-12-14 14:09:06.798 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695746000 ms.1 from job set of time 1481695746000 ms
2016-12-14 14:09:06.798 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 514
2016-12-14 14:09:06.799 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[514] at createStream at LogStream.java:100 of time 1481695745000 ms
2016-12-14 14:09:06.799 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 522 from persistence list
2016-12-14 14:09:06.799 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 522
2016-12-14 14:09:06.799 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 521 from persistence list
2016-12-14 14:09:06.799 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 521
2016-12-14 14:09:06.799 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 520 from persistence list
2016-12-14 14:09:06.799 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 520
2016-12-14 14:09:06.799 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 519 from persistence list
2016-12-14 14:09:06.799 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 519
2016-12-14 14:09:06.799 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 517 from persistence list
2016-12-14 14:09:06.799 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 517
2016-12-14 14:09:06.799 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 516 from persistence list
2016-12-14 14:09:06.800 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 516
2016-12-14 14:09:06.800 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 515 from persistence list
2016-12-14 14:09:06.800 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 515
2016-12-14 14:09:06.800 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695743000 ms)
2016-12-14 14:09:06.800 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695743000 ms
2016-12-14 14:09:06.802 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:06.802 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 537 (union at DStream.scala:617)
2016-12-14 14:09:06.803 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 60 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:06.803 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 120 (take at LogStream.java:127)
2016-12-14 14:09:06.803 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 119)
2016-12-14 14:09:06.803 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 119)
2016-12-14 14:09:06.803 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 119 (UnionRDD[537] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:06.804 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_119 stored as values in memory (estimated size 4.2 KB, free 286.4 KB)
2016-12-14 14:09:06.805 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_119_piece0 stored as bytes in memory (estimated size 2.4 KB, free 288.9 KB)
2016-12-14 14:09:06.805 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_119_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:06.805 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 119 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.805 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 119 (UnionRDD[537] at union at DStream.scala:617)
2016-12-14 14:09:06.806 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 119.0 with 1 tasks
2016-12-14 14:09:06.806 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 119.0 (TID 119, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:06.806 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 119.0 (TID 119)
2016-12-14 14:09:06.808 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 119.0 (TID 119). 1159 bytes result sent to driver
2016-12-14 14:09:06.808 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 119.0 (TID 119) in 2 ms on localhost (1/1)
2016-12-14 14:09:06.809 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 119 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 120)
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:06.809 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 120 (MapPartitionsRDD[540] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:06.810 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_120 stored as values in memory (estimated size 3.7 KB, free 292.6 KB)
2016-12-14 14:09:06.811 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_120_piece0 stored as bytes in memory (estimated size 2.1 KB, free 294.7 KB)
2016-12-14 14:09:06.811 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_120_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:06.811 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 120 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:06.812 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[540] at count at LogStream.java:120)
2016-12-14 14:09:06.812 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 120.0 with 1 tasks
2016-12-14 14:09:06.812 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 120.0 (TID 120, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:06.812 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 120.0 (TID 120)
2016-12-14 14:09:06.814 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:06.814 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:06.815 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 120.0 (TID 120). 1241 bytes result sent to driver
2016-12-14 14:09:06.815 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 120.0 (TID 120) in 3 ms on localhost (1/1)
2016-12-14 14:09:06.815 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 120 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:06.815 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2016-12-14 14:09:06.815 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 60 finished: take at LogStream.java:127, took 0.013455 s
2016-12-14 14:09:06.820 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695746000 ms.1 from job set of time 1481695746000 ms
2016-12-14 14:09:06.821 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.820 s for time 1481695746000 ms (execution: 0.022 s)
2016-12-14 14:09:06.821 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 523 from persistence list
2016-12-14 14:09:06.821 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 523
2016-12-14 14:09:06.821 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[523] at createStream at LogStream.java:100 of time 1481695746000 ms
2016-12-14 14:09:06.821 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 531 from persistence list
2016-12-14 14:09:06.821 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 531
2016-12-14 14:09:06.821 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 530 from persistence list
2016-12-14 14:09:06.821 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 530
2016-12-14 14:09:06.821 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 529 from persistence list
2016-12-14 14:09:06.822 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 529
2016-12-14 14:09:06.822 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 528 from persistence list
2016-12-14 14:09:06.822 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 528
2016-12-14 14:09:06.822 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 526 from persistence list
2016-12-14 14:09:06.822 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 526
2016-12-14 14:09:06.822 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 525 from persistence list
2016-12-14 14:09:06.823 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 525
2016-12-14 14:09:06.823 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 524 from persistence list
2016-12-14 14:09:06.823 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 524
2016-12-14 14:09:06.823 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695744000 ms)
2016-12-14 14:09:06.823 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695744000 ms
2016-12-14 14:09:07.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695747000 ms
2016-12-14 14:09:07.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695747000 ms.0 from job set of time 1481695747000 ms
2016-12-14 14:09:07.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695747000 ms.0 from job set of time 1481695747000 ms
2016-12-14 14:09:07.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695747000 ms.1 from job set of time 1481695747000 ms
2016-12-14 14:09:07.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 546 (union at DStream.scala:617)
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 61 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 122 (take at LogStream.java:127)
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 121)
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 121)
2016-12-14 14:09:07.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 121 (UnionRDD[546] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:07.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_121 stored as values in memory (estimated size 4.2 KB, free 298.9 KB)
2016-12-14 14:09:07.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_121_piece0 stored as bytes in memory (estimated size 2.4 KB, free 301.3 KB)
2016-12-14 14:09:07.018 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_121_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:07.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 121 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:07.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 121 (UnionRDD[546] at union at DStream.scala:617)
2016-12-14 14:09:07.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 121.0 with 1 tasks
2016-12-14 14:09:07.019 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 121.0 (TID 121, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:07.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 121.0 (TID 121)
2016-12-14 14:09:07.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 121.0 (TID 121). 1159 bytes result sent to driver
2016-12-14 14:09:07.022 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 121.0 (TID 121) in 3 ms on localhost (1/1)
2016-12-14 14:09:07.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2016-12-14 14:09:07.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 121 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:07.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:07.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:07.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 122)
2016-12-14 14:09:07.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:07.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 122 (MapPartitionsRDD[549] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:07.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_122 stored as values in memory (estimated size 3.7 KB, free 305.0 KB)
2016-12-14 14:09:07.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_122_piece0 stored as bytes in memory (estimated size 2.1 KB, free 307.1 KB)
2016-12-14 14:09:07.027 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_122_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:07.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 122 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:07.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[549] at count at LogStream.java:120)
2016-12-14 14:09:07.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 122.0 with 1 tasks
2016-12-14 14:09:07.028 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 122.0 (TID 122, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:07.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 122.0 (TID 122)
2016-12-14 14:09:07.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:07.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:07.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 122.0 (TID 122). 1241 bytes result sent to driver
2016-12-14 14:09:07.031 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 122.0 (TID 122) in 3 ms on localhost (1/1)
2016-12-14 14:09:07.031 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2016-12-14 14:09:07.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 122 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:07.031 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 61 finished: take at LogStream.java:127, took 0.017173 s
2016-12-14 14:09:07.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695747000 ms.1 from job set of time 1481695747000 ms
2016-12-14 14:09:07.061 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 532 from persistence list
2016-12-14 14:09:07.061 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.061 s for time 1481695747000 ms (execution: 0.051 s)
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 532
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[532] at createStream at LogStream.java:100 of time 1481695747000 ms
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 540 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 540
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 539 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 539
2016-12-14 14:09:07.062 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 538 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 538
2016-12-14 14:09:07.062 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 537 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 537
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 535 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 535
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 534 from persistence list
2016-12-14 14:09:07.062 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 534
2016-12-14 14:09:07.062 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 533 from persistence list
2016-12-14 14:09:07.063 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 533
2016-12-14 14:09:07.063 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695745000 ms)
2016-12-14 14:09:07.063 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695745000 ms
2016-12-14 14:09:08.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695748000 ms
2016-12-14 14:09:08.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695748000 ms.0 from job set of time 1481695748000 ms
2016-12-14 14:09:08.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695748000 ms.0 from job set of time 1481695748000 ms
2016-12-14 14:09:08.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695748000 ms.1 from job set of time 1481695748000 ms
2016-12-14 14:09:08.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:08.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 555 (union at DStream.scala:617)
2016-12-14 14:09:08.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 62 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:08.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 124 (take at LogStream.java:127)
2016-12-14 14:09:08.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 123)
2016-12-14 14:09:08.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 123)
2016-12-14 14:09:08.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 123 (UnionRDD[555] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:08.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_123 stored as values in memory (estimated size 4.2 KB, free 311.3 KB)
2016-12-14 14:09:08.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_123_piece0 stored as bytes in memory (estimated size 2.4 KB, free 313.8 KB)
2016-12-14 14:09:08.017 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_123_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:08.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 123 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:08.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 123 (UnionRDD[555] at union at DStream.scala:617)
2016-12-14 14:09:08.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 123.0 with 1 tasks
2016-12-14 14:09:08.018 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 123.0 (TID 123, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:08.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 123.0 (TID 123)
2016-12-14 14:09:08.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 123.0 (TID 123). 1159 bytes result sent to driver
2016-12-14 14:09:08.020 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 123.0 (TID 123) in 3 ms on localhost (1/1)
2016-12-14 14:09:08.020 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 123.0, whose tasks have all completed, from pool 
2016-12-14 14:09:08.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 123 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 124)
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 124 (MapPartitionsRDD[558] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:08.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_124 stored as values in memory (estimated size 3.7 KB, free 317.5 KB)
2016-12-14 14:09:08.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_124_piece0 stored as bytes in memory (estimated size 2.1 KB, free 319.6 KB)
2016-12-14 14:09:08.023 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_124_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:08.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 124 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:08.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[558] at count at LogStream.java:120)
2016-12-14 14:09:08.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 124.0 with 1 tasks
2016-12-14 14:09:08.024 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 124.0 (TID 124, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:08.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 124.0 (TID 124)
2016-12-14 14:09:08.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:09.007 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695749000 ms
2016-12-14 14:09:16.700 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 8675 ms
2016-12-14 14:09:16.702 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 124.0 (TID 124). 1241 bytes result sent to driver
2016-12-14 14:09:16.703 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 124.0 (TID 124) in 8679 ms on localhost (1/1)
2016-12-14 14:09:16.703 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 124 (take at LogStream.java:127) finished in 8.679 s
2016-12-14 14:09:16.703 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.703 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 62 finished: take at LogStream.java:127, took 8.689155 s
2016-12-14 14:09:16.710 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695750000 ms
2016-12-14 14:09:16.713 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695748000 ms.1 from job set of time 1481695748000 ms
2016-12-14 14:09:16.713 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 8.713 s for time 1481695748000 ms (execution: 8.703 s)
2016-12-14 14:09:16.713 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695749000 ms.0 from job set of time 1481695749000 ms
2016-12-14 14:09:16.713 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695749000 ms.0 from job set of time 1481695749000 ms
2016-12-14 14:09:16.714 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695749000 ms.1 from job set of time 1481695749000 ms
2016-12-14 14:09:16.717 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.718 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 564 (union at DStream.scala:617)
2016-12-14 14:09:16.718 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 63 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.718 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 126 (take at LogStream.java:127)
2016-12-14 14:09:16.718 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 125)
2016-12-14 14:09:16.719 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 125)
2016-12-14 14:09:16.719 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 125 (UnionRDD[564] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.720 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_125 stored as values in memory (estimated size 4.2 KB, free 323.8 KB)
2016-12-14 14:09:16.721 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_125_piece0 stored as bytes in memory (estimated size 2.4 KB, free 326.2 KB)
2016-12-14 14:09:16.722 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_125_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:16.722 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 125 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.722 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 125 (UnionRDD[564] at union at DStream.scala:617)
2016-12-14 14:09:16.722 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 125.0 with 1 tasks
2016-12-14 14:09:16.723 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 125.0 (TID 125, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.723 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 125.0 (TID 125)
2016-12-14 14:09:16.724 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695751000 ms
2016-12-14 14:09:16.726 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 125.0 (TID 125). 1159 bytes result sent to driver
2016-12-14 14:09:16.726 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 125.0 (TID 125) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.727 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 125.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 125 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 126)
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.727 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 126 (MapPartitionsRDD[567] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.728 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_126 stored as values in memory (estimated size 3.7 KB, free 329.9 KB)
2016-12-14 14:09:16.729 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_126_piece0 stored as bytes in memory (estimated size 2.1 KB, free 332.0 KB)
2016-12-14 14:09:16.729 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_126_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:16.730 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 126 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.730 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[567] at count at LogStream.java:120)
2016-12-14 14:09:16.730 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 126.0 with 1 tasks
2016-12-14 14:09:16.731 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 126.0 (TID 126, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.731 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 126.0 (TID 126)
2016-12-14 14:09:16.732 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.732 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:16.733 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 126.0 (TID 126). 1241 bytes result sent to driver
2016-12-14 14:09:16.734 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 126.0 (TID 126) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.734 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 126 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:16.734 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.734 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 63 finished: take at LogStream.java:127, took 0.017285 s
2016-12-14 14:09:16.737 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695752000 ms
2016-12-14 14:09:16.739 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695749000 ms.1 from job set of time 1481695749000 ms
2016-12-14 14:09:16.740 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 7.739 s for time 1481695749000 ms (execution: 0.026 s)
2016-12-14 14:09:16.740 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695750000 ms.0 from job set of time 1481695750000 ms
2016-12-14 14:09:16.740 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695750000 ms.0 from job set of time 1481695750000 ms
2016-12-14 14:09:16.740 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695750000 ms.1 from job set of time 1481695750000 ms
2016-12-14 14:09:16.744 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.745 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 573 (union at DStream.scala:617)
2016-12-14 14:09:16.745 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 64 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.745 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 128 (take at LogStream.java:127)
2016-12-14 14:09:16.745 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 127)
2016-12-14 14:09:16.745 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 127)
2016-12-14 14:09:16.746 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 127 (UnionRDD[573] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.747 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_127 stored as values in memory (estimated size 4.2 KB, free 336.3 KB)
2016-12-14 14:09:16.748 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_127_piece0 stored as bytes in memory (estimated size 2.4 KB, free 338.7 KB)
2016-12-14 14:09:16.749 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_127_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:16.749 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695753000 ms
2016-12-14 14:09:16.749 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 127 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.749 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 127 (UnionRDD[573] at union at DStream.scala:617)
2016-12-14 14:09:16.749 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 127.0 with 1 tasks
2016-12-14 14:09:16.750 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 127.0 (TID 127, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.751 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 127.0 (TID 127)
2016-12-14 14:09:16.754 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 127.0 (TID 127). 1159 bytes result sent to driver
2016-12-14 14:09:16.754 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 127.0 (TID 127) in 4 ms on localhost (1/1)
2016-12-14 14:09:16.755 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 127.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 127 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 128)
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.755 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 128 (MapPartitionsRDD[576] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.756 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_128 stored as values in memory (estimated size 3.7 KB, free 342.4 KB)
2016-12-14 14:09:16.757 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_128_piece0 stored as bytes in memory (estimated size 2.1 KB, free 344.5 KB)
2016-12-14 14:09:16.757 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_128_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:16.758 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 128 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.758 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[576] at count at LogStream.java:120)
2016-12-14 14:09:16.758 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 128.0 with 1 tasks
2016-12-14 14:09:16.758 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 128.0 (TID 128, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.759 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 128.0 (TID 128)
2016-12-14 14:09:16.760 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.760 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:16.761 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 128.0 (TID 128). 1241 bytes result sent to driver
2016-12-14 14:09:16.762 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 128.0 (TID 128) in 4 ms on localhost (1/1)
2016-12-14 14:09:16.762 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.762 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 128 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:16.762 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 64 finished: take at LogStream.java:127, took 0.017961 s
2016-12-14 14:09:16.764 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695754000 ms
2016-12-14 14:09:16.768 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695750000 ms.1 from job set of time 1481695750000 ms
2016-12-14 14:09:16.768 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 6.768 s for time 1481695750000 ms (execution: 0.028 s)
2016-12-14 14:09:16.768 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695751000 ms.0 from job set of time 1481695751000 ms
2016-12-14 14:09:16.768 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695751000 ms.0 from job set of time 1481695751000 ms
2016-12-14 14:09:16.768 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695751000 ms.1 from job set of time 1481695751000 ms
2016-12-14 14:09:16.772 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 582 (union at DStream.scala:617)
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 65 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 130 (take at LogStream.java:127)
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 129)
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 129)
2016-12-14 14:09:16.773 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 129 (UnionRDD[582] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.774 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_129 stored as values in memory (estimated size 4.2 KB, free 348.7 KB)
2016-12-14 14:09:16.775 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_129_piece0 stored as bytes in memory (estimated size 2.4 KB, free 351.1 KB)
2016-12-14 14:09:16.775 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_129_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:16.776 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 129 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.776 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 129 (UnionRDD[582] at union at DStream.scala:617)
2016-12-14 14:09:16.776 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 129.0 with 1 tasks
2016-12-14 14:09:16.776 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 129.0 (TID 129, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.777 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 129.0 (TID 129)
2016-12-14 14:09:16.778 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695755000 ms
2016-12-14 14:09:16.779 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 129.0 (TID 129). 1159 bytes result sent to driver
2016-12-14 14:09:16.779 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 129.0 (TID 129) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 129 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:16.780 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 129.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 130)
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.780 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 130 (MapPartitionsRDD[585] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.781 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_130 stored as values in memory (estimated size 3.7 KB, free 354.8 KB)
2016-12-14 14:09:16.782 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_130_piece0 stored as bytes in memory (estimated size 2.1 KB, free 357.0 KB)
2016-12-14 14:09:16.782 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_130_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:16.782 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 130 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.783 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[585] at count at LogStream.java:120)
2016-12-14 14:09:16.783 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 130.0 with 1 tasks
2016-12-14 14:09:16.783 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 130.0 (TID 130, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.783 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 130.0 (TID 130)
2016-12-14 14:09:16.784 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.785 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:16.785 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 130.0 (TID 130). 1241 bytes result sent to driver
2016-12-14 14:09:16.786 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 130.0 (TID 130) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.786 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 130 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:16.786 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.786 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 65 finished: take at LogStream.java:127, took 0.014201 s
2016-12-14 14:09:16.790 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695756000 ms
2016-12-14 14:09:16.790 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695751000 ms.1 from job set of time 1481695751000 ms
2016-12-14 14:09:16.791 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 541 from persistence list
2016-12-14 14:09:16.791 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 5.790 s for time 1481695751000 ms (execution: 0.022 s)
2016-12-14 14:09:16.791 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695752000 ms.0 from job set of time 1481695752000 ms
2016-12-14 14:09:16.791 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695752000 ms.0 from job set of time 1481695752000 ms
2016-12-14 14:09:16.791 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695752000 ms.1 from job set of time 1481695752000 ms
2016-12-14 14:09:16.791 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 541
2016-12-14 14:09:16.791 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[541] at createStream at LogStream.java:100 of time 1481695748000 ms
2016-12-14 14:09:16.792 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 549 from persistence list
2016-12-14 14:09:16.792 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 549
2016-12-14 14:09:16.792 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 548 from persistence list
2016-12-14 14:09:16.793 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 548
2016-12-14 14:09:16.793 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 547 from persistence list
2016-12-14 14:09:16.793 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 547
2016-12-14 14:09:16.793 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 546 from persistence list
2016-12-14 14:09:16.793 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 546
2016-12-14 14:09:16.793 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 544 from persistence list
2016-12-14 14:09:16.793 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 544
2016-12-14 14:09:16.793 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 543 from persistence list
2016-12-14 14:09:16.793 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 543
2016-12-14 14:09:16.793 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 542 from persistence list
2016-12-14 14:09:16.794 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 542
2016-12-14 14:09:16.794 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695746000 ms)
2016-12-14 14:09:16.794 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695746000 ms
2016-12-14 14:09:16.794 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 550 from persistence list
2016-12-14 14:09:16.794 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 550
2016-12-14 14:09:16.794 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[550] at createStream at LogStream.java:100 of time 1481695749000 ms
2016-12-14 14:09:16.795 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 558 from persistence list
2016-12-14 14:09:16.795 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 558
2016-12-14 14:09:16.795 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 557 from persistence list
2016-12-14 14:09:16.795 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 557
2016-12-14 14:09:16.795 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 556 from persistence list
2016-12-14 14:09:16.795 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 556
2016-12-14 14:09:16.796 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.796 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 555 from persistence list
2016-12-14 14:09:16.796 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 555
2016-12-14 14:09:16.796 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 553 from persistence list
2016-12-14 14:09:16.796 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 553
2016-12-14 14:09:16.796 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 591 (union at DStream.scala:617)
2016-12-14 14:09:16.796 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 552 from persistence list
2016-12-14 14:09:16.796 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 66 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.797 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 132 (take at LogStream.java:127)
2016-12-14 14:09:16.797 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 131)
2016-12-14 14:09:16.797 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 131)
2016-12-14 14:09:16.797 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 131 (UnionRDD[591] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.797 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 552
2016-12-14 14:09:16.798 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 551 from persistence list
2016-12-14 14:09:16.798 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_131 stored as values in memory (estimated size 4.2 KB, free 361.2 KB)
2016-12-14 14:09:16.798 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 551
2016-12-14 14:09:16.798 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695747000 ms)
2016-12-14 14:09:16.798 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695747000 ms
2016-12-14 14:09:16.798 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 559 from persistence list
2016-12-14 14:09:16.799 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 559
2016-12-14 14:09:16.799 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_131_piece0 stored as bytes in memory (estimated size 2.4 KB, free 363.6 KB)
2016-12-14 14:09:16.799 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[559] at createStream at LogStream.java:100 of time 1481695750000 ms
2016-12-14 14:09:16.799 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_131_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:16.799 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 567 from persistence list
2016-12-14 14:09:16.799 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 131 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.799 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 131 (UnionRDD[591] at union at DStream.scala:617)
2016-12-14 14:09:16.799 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 131.0 with 1 tasks
2016-12-14 14:09:16.799 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 567
2016-12-14 14:09:16.800 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 566 from persistence list
2016-12-14 14:09:16.800 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 131.0 (TID 131, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.800 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 566
2016-12-14 14:09:16.800 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 131.0 (TID 131)
2016-12-14 14:09:16.800 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 565 from persistence list
2016-12-14 14:09:16.801 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 565
2016-12-14 14:09:16.801 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 564 from persistence list
2016-12-14 14:09:16.801 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 564
2016-12-14 14:09:16.801 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 562 from persistence list
2016-12-14 14:09:16.801 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 562
2016-12-14 14:09:16.802 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 561 from persistence list
2016-12-14 14:09:16.802 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 561
2016-12-14 14:09:16.802 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 560 from persistence list
2016-12-14 14:09:16.802 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 560
2016-12-14 14:09:16.802 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695748000 ms)
2016-12-14 14:09:16.802 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695748000 ms
2016-12-14 14:09:16.803 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 568 from persistence list
2016-12-14 14:09:16.803 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 568
2016-12-14 14:09:16.803 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 131.0 (TID 131). 1159 bytes result sent to driver
2016-12-14 14:09:16.803 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[568] at createStream at LogStream.java:100 of time 1481695751000 ms
2016-12-14 14:09:16.803 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 576 from persistence list
2016-12-14 14:09:16.803 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 576
2016-12-14 14:09:16.803 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 131.0 (TID 131) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.804 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 131 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.804 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 575 from persistence list
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 132)
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.804 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 575
2016-12-14 14:09:16.804 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 132 (MapPartitionsRDD[594] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.804 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 574 from persistence list
2016-12-14 14:09:16.804 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 574
2016-12-14 14:09:16.804 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 573 from persistence list
2016-12-14 14:09:16.804 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 573
2016-12-14 14:09:16.804 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 571 from persistence list
2016-12-14 14:09:16.805 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 571
2016-12-14 14:09:16.805 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 570 from persistence list
2016-12-14 14:09:16.805 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 570
2016-12-14 14:09:16.805 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_132 stored as values in memory (estimated size 3.7 KB, free 367.3 KB)
2016-12-14 14:09:16.805 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 569 from persistence list
2016-12-14 14:09:16.806 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 569
2016-12-14 14:09:16.806 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_132_piece0 stored as bytes in memory (estimated size 2.1 KB, free 369.4 KB)
2016-12-14 14:09:16.806 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695749000 ms)
2016-12-14 14:09:16.806 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695749000 ms
2016-12-14 14:09:16.806 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_132_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:16.807 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 132 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.807 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[594] at count at LogStream.java:120)
2016-12-14 14:09:16.807 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 132.0 with 1 tasks
2016-12-14 14:09:16.807 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 132.0 (TID 132, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.807 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 132.0 (TID 132)
2016-12-14 14:09:16.809 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.809 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:16.810 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 132.0 (TID 132). 1241 bytes result sent to driver
2016-12-14 14:09:16.810 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 132.0 (TID 132) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.810 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.810 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 132 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:16.810 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 66 finished: take at LogStream.java:127, took 0.014880 s
2016-12-14 14:09:16.816 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695752000 ms.1 from job set of time 1481695752000 ms
2016-12-14 14:09:16.816 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 4.816 s for time 1481695752000 ms (execution: 0.025 s)
2016-12-14 14:09:16.816 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695753000 ms.0 from job set of time 1481695753000 ms
2016-12-14 14:09:16.816 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695753000 ms.0 from job set of time 1481695753000 ms
2016-12-14 14:09:16.816 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695753000 ms.1 from job set of time 1481695753000 ms
2016-12-14 14:09:16.816 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 577 from persistence list
2016-12-14 14:09:16.816 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 577
2016-12-14 14:09:16.817 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[577] at createStream at LogStream.java:100 of time 1481695752000 ms
2016-12-14 14:09:16.817 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 585 from persistence list
2016-12-14 14:09:16.817 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 585
2016-12-14 14:09:16.817 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 584 from persistence list
2016-12-14 14:09:16.817 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 584
2016-12-14 14:09:16.817 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 583 from persistence list
2016-12-14 14:09:16.817 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 583
2016-12-14 14:09:16.818 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 582 from persistence list
2016-12-14 14:09:16.818 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 582
2016-12-14 14:09:16.818 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 580 from persistence list
2016-12-14 14:09:16.818 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 580
2016-12-14 14:09:16.818 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 579 from persistence list
2016-12-14 14:09:16.819 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 579
2016-12-14 14:09:16.819 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 578 from persistence list
2016-12-14 14:09:16.819 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 578
2016-12-14 14:09:16.819 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695750000 ms)
2016-12-14 14:09:16.819 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695750000 ms
2016-12-14 14:09:16.820 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 600 (union at DStream.scala:617)
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 67 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 134 (take at LogStream.java:127)
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 133)
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 133)
2016-12-14 14:09:16.821 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 133 (UnionRDD[600] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.822 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_133 stored as values in memory (estimated size 4.2 KB, free 373.6 KB)
2016-12-14 14:09:16.823 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_133_piece0 stored as bytes in memory (estimated size 2.4 KB, free 376.1 KB)
2016-12-14 14:09:16.823 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_133_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:16.824 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 133 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.824 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 133 (UnionRDD[600] at union at DStream.scala:617)
2016-12-14 14:09:16.824 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 133.0 with 1 tasks
2016-12-14 14:09:16.825 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 133.0 (TID 133, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.825 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 133.0 (TID 133)
2016-12-14 14:09:16.827 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 133.0 (TID 133). 1159 bytes result sent to driver
2016-12-14 14:09:16.828 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 133.0 (TID 133) in 4 ms on localhost (1/1)
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 133 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:16.828 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 133.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 134)
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.828 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 134 (MapPartitionsRDD[603] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.829 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_134 stored as values in memory (estimated size 3.7 KB, free 379.7 KB)
2016-12-14 14:09:16.830 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_134_piece0 stored as bytes in memory (estimated size 2.1 KB, free 381.9 KB)
2016-12-14 14:09:16.830 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_134_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:16.830 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 134 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.830 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[603] at count at LogStream.java:120)
2016-12-14 14:09:16.830 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 134.0 with 1 tasks
2016-12-14 14:09:16.831 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 134.0 (TID 134, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.831 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 134.0 (TID 134)
2016-12-14 14:09:16.832 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.832 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:16.833 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 134.0 (TID 134). 1241 bytes result sent to driver
2016-12-14 14:09:16.833 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 134.0 (TID 134) in 2 ms on localhost (1/1)
2016-12-14 14:09:16.833 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.833 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 134 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:16.834 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 67 finished: take at LogStream.java:127, took 0.013344 s
2016-12-14 14:09:16.839 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695753000 ms.1 from job set of time 1481695753000 ms
2016-12-14 14:09:16.839 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 3.839 s for time 1481695753000 ms (execution: 0.023 s)
2016-12-14 14:09:16.839 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695754000 ms.0 from job set of time 1481695754000 ms
2016-12-14 14:09:16.839 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 586 from persistence list
2016-12-14 14:09:16.839 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695754000 ms.0 from job set of time 1481695754000 ms
2016-12-14 14:09:16.839 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695754000 ms.1 from job set of time 1481695754000 ms
2016-12-14 14:09:16.839 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 586
2016-12-14 14:09:16.839 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[586] at createStream at LogStream.java:100 of time 1481695753000 ms
2016-12-14 14:09:16.839 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 594 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 594
2016-12-14 14:09:16.840 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 593 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 593
2016-12-14 14:09:16.840 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 592 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 592
2016-12-14 14:09:16.840 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 591 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 591
2016-12-14 14:09:16.840 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 589 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 589
2016-12-14 14:09:16.840 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 588 from persistence list
2016-12-14 14:09:16.840 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 588
2016-12-14 14:09:16.840 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 587 from persistence list
2016-12-14 14:09:16.841 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 587
2016-12-14 14:09:16.841 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695751000 ms)
2016-12-14 14:09:16.841 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695751000 ms
2016-12-14 14:09:16.843 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 609 (union at DStream.scala:617)
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 68 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 136 (take at LogStream.java:127)
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 135)
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 135)
2016-12-14 14:09:16.844 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 135 (UnionRDD[609] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.845 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_135 stored as values in memory (estimated size 4.2 KB, free 386.1 KB)
2016-12-14 14:09:16.846 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_135_piece0 stored as bytes in memory (estimated size 2.4 KB, free 388.5 KB)
2016-12-14 14:09:16.846 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_135_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:16.847 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 135 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.847 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 135 (UnionRDD[609] at union at DStream.scala:617)
2016-12-14 14:09:16.847 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 135.0 with 1 tasks
2016-12-14 14:09:16.847 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 135.0 (TID 135, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.848 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 135.0 (TID 135)
2016-12-14 14:09:16.850 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 135.0 (TID 135). 1159 bytes result sent to driver
2016-12-14 14:09:16.850 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 135.0 (TID 135) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.850 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 135.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.850 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 135 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:16.850 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.850 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.850 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 136)
2016-12-14 14:09:16.850 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.851 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 136 (MapPartitionsRDD[612] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.851 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_136 stored as values in memory (estimated size 3.7 KB, free 392.2 KB)
2016-12-14 14:09:16.852 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_136_piece0 stored as bytes in memory (estimated size 2.1 KB, free 394.3 KB)
2016-12-14 14:09:16.852 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_136_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:16.853 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 136 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.853 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[612] at count at LogStream.java:120)
2016-12-14 14:09:16.853 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 136.0 with 1 tasks
2016-12-14 14:09:16.854 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 136.0 (TID 136, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:16.854 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 136.0 (TID 136)
2016-12-14 14:09:16.855 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:16.855 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:16.855 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 136.0 (TID 136). 1241 bytes result sent to driver
2016-12-14 14:09:16.856 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 136.0 (TID 136) in 3 ms on localhost (1/1)
2016-12-14 14:09:16.856 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 136 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:16.856 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.856 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 68 finished: take at LogStream.java:127, took 0.013086 s
2016-12-14 14:09:16.862 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695754000 ms.1 from job set of time 1481695754000 ms
2016-12-14 14:09:16.862 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 2.862 s for time 1481695754000 ms (execution: 0.023 s)
2016-12-14 14:09:16.862 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695755000 ms.0 from job set of time 1481695755000 ms
2016-12-14 14:09:16.862 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 595 from persistence list
2016-12-14 14:09:16.862 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695755000 ms.0 from job set of time 1481695755000 ms
2016-12-14 14:09:16.862 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695755000 ms.1 from job set of time 1481695755000 ms
2016-12-14 14:09:16.862 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 595
2016-12-14 14:09:16.862 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[595] at createStream at LogStream.java:100 of time 1481695754000 ms
2016-12-14 14:09:16.863 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 603 from persistence list
2016-12-14 14:09:16.863 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 603
2016-12-14 14:09:16.863 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 602 from persistence list
2016-12-14 14:09:16.863 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 602
2016-12-14 14:09:16.863 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 601 from persistence list
2016-12-14 14:09:16.863 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 601
2016-12-14 14:09:16.863 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 600 from persistence list
2016-12-14 14:09:16.864 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 600
2016-12-14 14:09:16.864 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 598 from persistence list
2016-12-14 14:09:16.864 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 598
2016-12-14 14:09:16.864 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 597 from persistence list
2016-12-14 14:09:16.864 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 597
2016-12-14 14:09:16.864 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 596 from persistence list
2016-12-14 14:09:16.864 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 596
2016-12-14 14:09:16.864 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695752000 ms)
2016-12-14 14:09:16.864 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695752000 ms
2016-12-14 14:09:16.866 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:16.867 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 618 (union at DStream.scala:617)
2016-12-14 14:09:16.868 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 69 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:16.868 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 138 (take at LogStream.java:127)
2016-12-14 14:09:16.868 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 137)
2016-12-14 14:09:16.868 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 137)
2016-12-14 14:09:16.868 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 137 (UnionRDD[618] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:16.869 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_137 stored as values in memory (estimated size 4.2 KB, free 398.5 KB)
2016-12-14 14:09:16.870 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_137_piece0 stored as bytes in memory (estimated size 2.4 KB, free 401.0 KB)
2016-12-14 14:09:16.870 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_137_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:16.871 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 137 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:16.871 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 137 (UnionRDD[618] at union at DStream.scala:617)
2016-12-14 14:09:16.871 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 137.0 with 1 tasks
2016-12-14 14:09:16.871 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 137.0 (TID 137, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:16.871 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 137.0 (TID 137)
2016-12-14 14:09:16.873 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 137.0 (TID 137). 1159 bytes result sent to driver
2016-12-14 14:09:16.873 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 137.0 (TID 137) in 2 ms on localhost (1/1)
2016-12-14 14:09:16.873 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 137.0, whose tasks have all completed, from pool 
2016-12-14 14:09:16.873 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 137 (union at DStream.scala:617) finished in 0.002 s
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 138)
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 138 (MapPartitionsRDD[621] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:16.874 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_138 stored as values in memory (estimated size 3.7 KB, free 404.7 KB)
2016-12-14 14:09:17.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695757000 ms
2016-12-14 14:09:17.186 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_138_piece0 stored as bytes in memory (estimated size 2.1 KB, free 406.8 KB)
2016-12-14 14:09:17.187 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_138_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:17.187 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 138 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:17.187 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[621] at count at LogStream.java:120)
2016-12-14 14:09:17.187 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 138.0 with 1 tasks
2016-12-14 14:09:17.188 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 138.0 (TID 138, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:17.188 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 138.0 (TID 138)
2016-12-14 14:09:17.190 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:17.190 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:17.191 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 138.0 (TID 138). 1241 bytes result sent to driver
2016-12-14 14:09:17.191 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 138.0 (TID 138) in 3 ms on localhost (1/1)
2016-12-14 14:09:17.191 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2016-12-14 14:09:17.192 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 138 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:17.192 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 69 finished: take at LogStream.java:127, took 0.325298 s
2016-12-14 14:09:17.197 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695755000 ms.1 from job set of time 1481695755000 ms
2016-12-14 14:09:17.197 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 2.197 s for time 1481695755000 ms (execution: 0.335 s)
2016-12-14 14:09:17.197 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695756000 ms.0 from job set of time 1481695756000 ms
2016-12-14 14:09:17.197 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 604 from persistence list
2016-12-14 14:09:17.197 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695756000 ms.0 from job set of time 1481695756000 ms
2016-12-14 14:09:17.197 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695756000 ms.1 from job set of time 1481695756000 ms
2016-12-14 14:09:17.197 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 604
2016-12-14 14:09:17.198 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[604] at createStream at LogStream.java:100 of time 1481695755000 ms
2016-12-14 14:09:17.198 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 612 from persistence list
2016-12-14 14:09:17.198 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 612
2016-12-14 14:09:17.198 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 611 from persistence list
2016-12-14 14:09:17.198 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 611
2016-12-14 14:09:17.199 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 610 from persistence list
2016-12-14 14:09:17.199 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 610
2016-12-14 14:09:17.199 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 609 from persistence list
2016-12-14 14:09:17.199 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 609
2016-12-14 14:09:17.199 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 607 from persistence list
2016-12-14 14:09:17.200 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 607
2016-12-14 14:09:17.200 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 606 from persistence list
2016-12-14 14:09:17.200 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 606
2016-12-14 14:09:17.201 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 605 from persistence list
2016-12-14 14:09:17.201 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 605
2016-12-14 14:09:17.201 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:17.201 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695753000 ms)
2016-12-14 14:09:17.202 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695753000 ms
2016-12-14 14:09:17.202 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 627 (union at DStream.scala:617)
2016-12-14 14:09:17.203 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 70 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:17.203 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 140 (take at LogStream.java:127)
2016-12-14 14:09:17.203 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 139)
2016-12-14 14:09:17.203 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 139)
2016-12-14 14:09:17.203 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 139 (UnionRDD[627] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:17.204 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_139 stored as values in memory (estimated size 4.2 KB, free 411.0 KB)
2016-12-14 14:09:17.205 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_139_piece0 stored as bytes in memory (estimated size 2.4 KB, free 413.4 KB)
2016-12-14 14:09:17.206 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_139_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:17.206 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 139 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:17.206 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 139 (UnionRDD[627] at union at DStream.scala:617)
2016-12-14 14:09:17.206 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 139.0 with 1 tasks
2016-12-14 14:09:17.207 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 139.0 (TID 139, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:17.207 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 139.0 (TID 139)
2016-12-14 14:09:17.210 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 139.0 (TID 139). 1159 bytes result sent to driver
2016-12-14 14:09:17.210 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 139.0 (TID 139) in 4 ms on localhost (1/1)
2016-12-14 14:09:17.210 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 139.0, whose tasks have all completed, from pool 
2016-12-14 14:09:17.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 139 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:17.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:17.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:17.210 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 140)
2016-12-14 14:09:17.211 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:17.211 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 140 (MapPartitionsRDD[630] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:17.211 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_140 stored as values in memory (estimated size 3.7 KB, free 417.1 KB)
2016-12-14 14:09:17.212 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_140_piece0 stored as bytes in memory (estimated size 2.1 KB, free 419.2 KB)
2016-12-14 14:09:17.213 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_140_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:17.213 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 140 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:17.213 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[630] at count at LogStream.java:120)
2016-12-14 14:09:17.213 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 140.0 with 1 tasks
2016-12-14 14:09:17.214 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 140.0 (TID 140, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:17.214 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 140.0 (TID 140)
2016-12-14 14:09:17.215 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:17.215 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:17.216 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 140.0 (TID 140). 1241 bytes result sent to driver
2016-12-14 14:09:17.216 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 140.0 (TID 140) in 2 ms on localhost (1/1)
2016-12-14 14:09:17.216 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2016-12-14 14:09:17.216 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 140 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:17.217 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 70 finished: take at LogStream.java:127, took 0.015046 s
2016-12-14 14:09:17.222 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695756000 ms.1 from job set of time 1481695756000 ms
2016-12-14 14:09:17.222 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 1.222 s for time 1481695756000 ms (execution: 0.025 s)
2016-12-14 14:09:17.222 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 613 from persistence list
2016-12-14 14:09:17.223 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695757000 ms.0 from job set of time 1481695757000 ms
2016-12-14 14:09:17.223 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695757000 ms.0 from job set of time 1481695757000 ms
2016-12-14 14:09:17.223 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 613
2016-12-14 14:09:17.223 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695757000 ms.1 from job set of time 1481695757000 ms
2016-12-14 14:09:17.223 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[613] at createStream at LogStream.java:100 of time 1481695756000 ms
2016-12-14 14:09:17.223 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 621 from persistence list
2016-12-14 14:09:17.223 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 621
2016-12-14 14:09:17.223 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 620 from persistence list
2016-12-14 14:09:17.223 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 620
2016-12-14 14:09:17.223 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 619 from persistence list
2016-12-14 14:09:17.223 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 619
2016-12-14 14:09:17.223 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 618 from persistence list
2016-12-14 14:09:17.224 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 618
2016-12-14 14:09:17.224 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 616 from persistence list
2016-12-14 14:09:17.224 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 616
2016-12-14 14:09:17.224 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 615 from persistence list
2016-12-14 14:09:17.224 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 615
2016-12-14 14:09:17.224 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 614 from persistence list
2016-12-14 14:09:17.224 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 614
2016-12-14 14:09:17.224 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695754000 ms)
2016-12-14 14:09:17.224 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695754000 ms
2016-12-14 14:09:17.226 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 636 (union at DStream.scala:617)
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 71 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 142 (take at LogStream.java:127)
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 141)
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 141)
2016-12-14 14:09:17.227 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 141 (UnionRDD[636] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:17.228 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_141 stored as values in memory (estimated size 4.2 KB, free 423.4 KB)
2016-12-14 14:09:17.229 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_141_piece0 stored as bytes in memory (estimated size 2.4 KB, free 425.9 KB)
2016-12-14 14:09:17.229 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_141_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:17.229 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 141 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:17.230 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 141 (UnionRDD[636] at union at DStream.scala:617)
2016-12-14 14:09:17.230 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 141.0 with 1 tasks
2016-12-14 14:09:17.230 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 141.0 (TID 141, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:17.230 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 141.0 (TID 141)
2016-12-14 14:09:17.233 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 141.0 (TID 141). 1159 bytes result sent to driver
2016-12-14 14:09:17.233 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 141.0 (TID 141) in 3 ms on localhost (1/1)
2016-12-14 14:09:17.233 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 141.0, whose tasks have all completed, from pool 
2016-12-14 14:09:17.233 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 141 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:17.233 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:17.233 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:17.233 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 142)
2016-12-14 14:09:17.233 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:17.234 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 142 (MapPartitionsRDD[639] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:17.235 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_142 stored as values in memory (estimated size 3.7 KB, free 429.6 KB)
2016-12-14 14:09:17.236 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_142_piece0 stored as bytes in memory (estimated size 2.1 KB, free 431.7 KB)
2016-12-14 14:09:17.237 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_142_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:17.237 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 142 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:17.237 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[639] at count at LogStream.java:120)
2016-12-14 14:09:17.237 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 142.0 with 1 tasks
2016-12-14 14:09:17.238 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 142.0 (TID 142, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:17.238 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 142.0 (TID 142)
2016-12-14 14:09:17.239 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:17.239 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:17.240 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 142.0 (TID 142). 1241 bytes result sent to driver
2016-12-14 14:09:17.240 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 142.0 (TID 142) in 2 ms on localhost (1/1)
2016-12-14 14:09:17.240 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2016-12-14 14:09:17.240 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 142 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:17.240 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 71 finished: take at LogStream.java:127, took 0.014234 s
2016-12-14 14:09:17.246 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695757000 ms.1 from job set of time 1481695757000 ms
2016-12-14 14:09:17.246 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 622 from persistence list
2016-12-14 14:09:17.246 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.246 s for time 1481695757000 ms (execution: 0.024 s)
2016-12-14 14:09:17.246 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 622
2016-12-14 14:09:17.246 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[622] at createStream at LogStream.java:100 of time 1481695757000 ms
2016-12-14 14:09:17.246 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 630 from persistence list
2016-12-14 14:09:17.246 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 630
2016-12-14 14:09:17.246 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 629 from persistence list
2016-12-14 14:09:17.246 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 629
2016-12-14 14:09:17.246 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 628 from persistence list
2016-12-14 14:09:17.246 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 628
2016-12-14 14:09:17.246 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 627 from persistence list
2016-12-14 14:09:17.246 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 627
2016-12-14 14:09:17.247 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 625 from persistence list
2016-12-14 14:09:17.247 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 625
2016-12-14 14:09:17.247 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 624 from persistence list
2016-12-14 14:09:17.247 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 624
2016-12-14 14:09:17.247 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 623 from persistence list
2016-12-14 14:09:17.247 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 623
2016-12-14 14:09:17.247 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695755000 ms)
2016-12-14 14:09:17.247 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695755000 ms
2016-12-14 14:09:18.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695758000 ms
2016-12-14 14:09:18.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695758000 ms.0 from job set of time 1481695758000 ms
2016-12-14 14:09:18.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695758000 ms.0 from job set of time 1481695758000 ms
2016-12-14 14:09:18.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695758000 ms.1 from job set of time 1481695758000 ms
2016-12-14 14:09:18.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 645 (union at DStream.scala:617)
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 72 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 144 (take at LogStream.java:127)
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 143)
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 143)
2016-12-14 14:09:18.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 143 (UnionRDD[645] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:18.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_143 stored as values in memory (estimated size 4.2 KB, free 435.9 KB)
2016-12-14 14:09:18.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_143_piece0 stored as bytes in memory (estimated size 2.4 KB, free 438.3 KB)
2016-12-14 14:09:18.017 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_143_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:18.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 143 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:18.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 143 (UnionRDD[645] at union at DStream.scala:617)
2016-12-14 14:09:18.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 143.0 with 1 tasks
2016-12-14 14:09:18.018 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 143.0 (TID 143, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:18.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 143.0 (TID 143)
2016-12-14 14:09:18.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 143.0 (TID 143). 1159 bytes result sent to driver
2016-12-14 14:09:18.022 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 143.0 (TID 143) in 3 ms on localhost (1/1)
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 143 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:18.022 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 143.0, whose tasks have all completed, from pool 
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 144)
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:18.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 144 (MapPartitionsRDD[648] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:18.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_144 stored as values in memory (estimated size 3.7 KB, free 442.0 KB)
2016-12-14 14:09:18.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_144_piece0 stored as bytes in memory (estimated size 2.1 KB, free 444.1 KB)
2016-12-14 14:09:18.024 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_144_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:18.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 144 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:18.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[648] at count at LogStream.java:120)
2016-12-14 14:09:18.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 144.0 with 1 tasks
2016-12-14 14:09:18.025 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 144.0 (TID 144, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:18.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 144.0 (TID 144)
2016-12-14 14:09:18.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:18.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:18.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 144.0 (TID 144). 1241 bytes result sent to driver
2016-12-14 14:09:18.028 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 144.0 (TID 144) in 3 ms on localhost (1/1)
2016-12-14 14:09:18.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 144 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:18.028 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2016-12-14 14:09:18.028 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 72 finished: take at LogStream.java:127, took 0.014925 s
2016-12-14 14:09:18.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695758000 ms.1 from job set of time 1481695758000 ms
2016-12-14 14:09:18.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.034 s for time 1481695758000 ms (execution: 0.024 s)
2016-12-14 14:09:18.034 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 631 from persistence list
2016-12-14 14:09:18.035 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 631
2016-12-14 14:09:18.035 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[631] at createStream at LogStream.java:100 of time 1481695758000 ms
2016-12-14 14:09:18.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 639 from persistence list
2016-12-14 14:09:18.035 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 639
2016-12-14 14:09:18.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 638 from persistence list
2016-12-14 14:09:18.035 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 638
2016-12-14 14:09:18.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 637 from persistence list
2016-12-14 14:09:18.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 637
2016-12-14 14:09:18.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 636 from persistence list
2016-12-14 14:09:18.036 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 636
2016-12-14 14:09:18.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 634 from persistence list
2016-12-14 14:09:18.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 634
2016-12-14 14:09:18.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 633 from persistence list
2016-12-14 14:09:18.037 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 633
2016-12-14 14:09:18.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 632 from persistence list
2016-12-14 14:09:18.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 632
2016-12-14 14:09:18.037 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695756000 ms)
2016-12-14 14:09:18.037 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695756000 ms
2016-12-14 14:09:19.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695759000 ms
2016-12-14 14:09:19.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695759000 ms.0 from job set of time 1481695759000 ms
2016-12-14 14:09:19.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695759000 ms.0 from job set of time 1481695759000 ms
2016-12-14 14:09:19.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695759000 ms.1 from job set of time 1481695759000 ms
2016-12-14 14:09:19.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:19.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 654 (union at DStream.scala:617)
2016-12-14 14:09:19.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 73 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:19.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 146 (take at LogStream.java:127)
2016-12-14 14:09:19.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 145)
2016-12-14 14:09:19.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 145)
2016-12-14 14:09:19.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 145 (UnionRDD[654] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:19.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_145 stored as values in memory (estimated size 4.2 KB, free 448.3 KB)
2016-12-14 14:09:19.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_145_piece0 stored as bytes in memory (estimated size 2.4 KB, free 450.8 KB)
2016-12-14 14:09:19.018 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_145_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:19.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 145 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:19.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 145 (UnionRDD[654] at union at DStream.scala:617)
2016-12-14 14:09:19.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 145.0 with 1 tasks
2016-12-14 14:09:19.019 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 145.0 (TID 145, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:19.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 145.0 (TID 145)
2016-12-14 14:09:19.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 145.0 (TID 145). 1159 bytes result sent to driver
2016-12-14 14:09:19.022 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 145.0 (TID 145) in 3 ms on localhost (1/1)
2016-12-14 14:09:19.022 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 145.0, whose tasks have all completed, from pool 
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 145 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 146)
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:19.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 146 (MapPartitionsRDD[657] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:19.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_146 stored as values in memory (estimated size 3.7 KB, free 454.5 KB)
2016-12-14 14:09:19.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_146_piece0 stored as bytes in memory (estimated size 2.1 KB, free 456.6 KB)
2016-12-14 14:09:19.026 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_146_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:19.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 146 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:19.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[657] at count at LogStream.java:120)
2016-12-14 14:09:19.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 146.0 with 1 tasks
2016-12-14 14:09:19.027 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 146.0 (TID 146, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:19.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 146.0 (TID 146)
2016-12-14 14:09:19.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:19.028 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:19.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 146.0 (TID 146). 1241 bytes result sent to driver
2016-12-14 14:09:19.029 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 146.0 (TID 146) in 2 ms on localhost (1/1)
2016-12-14 14:09:19.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 146 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:19.029 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2016-12-14 14:09:19.030 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 73 finished: take at LogStream.java:127, took 0.014973 s
2016-12-14 14:09:19.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695759000 ms.1 from job set of time 1481695759000 ms
2016-12-14 14:09:19.035 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 640 from persistence list
2016-12-14 14:09:19.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.035 s for time 1481695759000 ms (execution: 0.024 s)
2016-12-14 14:09:19.035 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 640
2016-12-14 14:09:19.035 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[640] at createStream at LogStream.java:100 of time 1481695759000 ms
2016-12-14 14:09:19.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 648 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 648
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 647 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 647
2016-12-14 14:09:19.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 646 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 646
2016-12-14 14:09:19.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 645 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 645
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 643 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 643
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 642 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 642
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 641 from persistence list
2016-12-14 14:09:19.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 641
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695757000 ms)
2016-12-14 14:09:19.036 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695757000 ms
2016-12-14 14:09:20.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695760000 ms
2016-12-14 14:09:20.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695760000 ms.0 from job set of time 1481695760000 ms
2016-12-14 14:09:20.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695760000 ms.0 from job set of time 1481695760000 ms
2016-12-14 14:09:20.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695760000 ms.1 from job set of time 1481695760000 ms
2016-12-14 14:09:20.014 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 663 (union at DStream.scala:617)
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 74 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 148 (take at LogStream.java:127)
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 147)
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 147)
2016-12-14 14:09:20.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 147 (UnionRDD[663] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:20.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_147 stored as values in memory (estimated size 4.2 KB, free 460.8 KB)
2016-12-14 14:09:20.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_147_piece0 stored as bytes in memory (estimated size 2.4 KB, free 463.2 KB)
2016-12-14 14:09:20.018 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_147_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:20.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 147 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:20.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 147 (UnionRDD[663] at union at DStream.scala:617)
2016-12-14 14:09:20.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 147.0 with 1 tasks
2016-12-14 14:09:20.019 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 147.0 (TID 147, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:20.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 147.0 (TID 147)
2016-12-14 14:09:20.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 147.0 (TID 147). 1159 bytes result sent to driver
2016-12-14 14:09:20.022 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 147.0 (TID 147) in 3 ms on localhost (1/1)
2016-12-14 14:09:20.022 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 147 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 148)
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:20.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 148 (MapPartitionsRDD[666] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:20.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_148 stored as values in memory (estimated size 3.7 KB, free 466.9 KB)
2016-12-14 14:09:20.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_148_piece0 stored as bytes in memory (estimated size 2.1 KB, free 469.0 KB)
2016-12-14 14:09:20.028 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_148_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:20.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 148 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:20.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[666] at count at LogStream.java:120)
2016-12-14 14:09:20.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 148.0 with 1 tasks
2016-12-14 14:09:20.029 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 148.0 (TID 148, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:20.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 148.0 (TID 148)
2016-12-14 14:09:20.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:20.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:20.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 148.0 (TID 148). 1241 bytes result sent to driver
2016-12-14 14:09:20.032 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 148.0 (TID 148) in 3 ms on localhost (1/1)
2016-12-14 14:09:20.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 148 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:20.032 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2016-12-14 14:09:20.032 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 74 finished: take at LogStream.java:127, took 0.017884 s
2016-12-14 14:09:20.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695760000 ms.1 from job set of time 1481695760000 ms
2016-12-14 14:09:20.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.037 s for time 1481695760000 ms (execution: 0.027 s)
2016-12-14 14:09:20.037 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 649 from persistence list
2016-12-14 14:09:20.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 649
2016-12-14 14:09:20.037 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[649] at createStream at LogStream.java:100 of time 1481695760000 ms
2016-12-14 14:09:20.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 657 from persistence list
2016-12-14 14:09:20.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 657
2016-12-14 14:09:20.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 656 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 656
2016-12-14 14:09:20.038 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 655 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 655
2016-12-14 14:09:20.038 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 654 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 654
2016-12-14 14:09:20.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 652 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 652
2016-12-14 14:09:20.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 651 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 651
2016-12-14 14:09:20.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 650 from persistence list
2016-12-14 14:09:20.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 650
2016-12-14 14:09:20.039 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695758000 ms)
2016-12-14 14:09:20.039 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695758000 ms
2016-12-14 14:09:21.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695761000 ms
2016-12-14 14:09:21.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695761000 ms.0 from job set of time 1481695761000 ms
2016-12-14 14:09:21.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695761000 ms.0 from job set of time 1481695761000 ms
2016-12-14 14:09:21.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695761000 ms.1 from job set of time 1481695761000 ms
2016-12-14 14:09:21.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:21.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 672 (union at DStream.scala:617)
2016-12-14 14:09:21.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 75 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:21.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 150 (take at LogStream.java:127)
2016-12-14 14:09:21.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 149)
2016-12-14 14:09:21.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 149)
2016-12-14 14:09:21.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 149 (UnionRDD[672] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:21.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_149 stored as values in memory (estimated size 4.2 KB, free 473.2 KB)
2016-12-14 14:09:21.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_149_piece0 stored as bytes in memory (estimated size 2.4 KB, free 475.7 KB)
2016-12-14 14:09:21.024 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_149_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:21.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 149 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:21.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 149 (UnionRDD[672] at union at DStream.scala:617)
2016-12-14 14:09:21.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 149.0 with 1 tasks
2016-12-14 14:09:21.025 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 149.0 (TID 149, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:21.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 149.0 (TID 149)
2016-12-14 14:09:21.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 149.0 (TID 149). 1159 bytes result sent to driver
2016-12-14 14:09:21.028 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 149.0 (TID 149) in 3 ms on localhost (1/1)
2016-12-14 14:09:21.028 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 149.0, whose tasks have all completed, from pool 
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 149 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 150)
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:21.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 150 (MapPartitionsRDD[675] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:21.029 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_150 stored as values in memory (estimated size 3.7 KB, free 479.4 KB)
2016-12-14 14:09:21.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_150_piece0 stored as bytes in memory (estimated size 2.1 KB, free 481.5 KB)
2016-12-14 14:09:21.030 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_150_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:21.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 150 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:21.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[675] at count at LogStream.java:120)
2016-12-14 14:09:21.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 150.0 with 1 tasks
2016-12-14 14:09:21.031 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 150.0 (TID 150, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:21.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 150.0 (TID 150)
2016-12-14 14:09:21.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:21.032 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:21.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 150.0 (TID 150). 1241 bytes result sent to driver
2016-12-14 14:09:21.033 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 150.0 (TID 150) in 2 ms on localhost (1/1)
2016-12-14 14:09:21.033 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2016-12-14 14:09:21.033 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 150 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:21.033 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 75 finished: take at LogStream.java:127, took 0.018109 s
2016-12-14 14:09:21.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695761000 ms.1 from job set of time 1481695761000 ms
2016-12-14 14:09:21.039 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 658 from persistence list
2016-12-14 14:09:21.039 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.039 s for time 1481695761000 ms (execution: 0.028 s)
2016-12-14 14:09:21.039 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 658
2016-12-14 14:09:21.039 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[658] at createStream at LogStream.java:100 of time 1481695761000 ms
2016-12-14 14:09:21.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 666 from persistence list
2016-12-14 14:09:21.039 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 666
2016-12-14 14:09:21.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 665 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 665
2016-12-14 14:09:21.040 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 664 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 664
2016-12-14 14:09:21.040 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 663 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 663
2016-12-14 14:09:21.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 661 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 661
2016-12-14 14:09:21.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 660 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 660
2016-12-14 14:09:21.040 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 659 from persistence list
2016-12-14 14:09:21.040 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 659
2016-12-14 14:09:21.040 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695759000 ms)
2016-12-14 14:09:21.040 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695759000 ms
2016-12-14 14:09:22.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695762000 ms
2016-12-14 14:09:22.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695762000 ms.0 from job set of time 1481695762000 ms
2016-12-14 14:09:22.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695762000 ms.0 from job set of time 1481695762000 ms
2016-12-14 14:09:22.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695762000 ms.1 from job set of time 1481695762000 ms
2016-12-14 14:09:22.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 681 (union at DStream.scala:617)
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 76 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 152 (take at LogStream.java:127)
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 151)
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 151)
2016-12-14 14:09:22.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 151 (UnionRDD[681] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:22.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_151 stored as values in memory (estimated size 4.2 KB, free 485.7 KB)
2016-12-14 14:09:22.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_151_piece0 stored as bytes in memory (estimated size 2.4 KB, free 488.1 KB)
2016-12-14 14:09:22.019 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_151_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:22.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 151 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:22.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 151 (UnionRDD[681] at union at DStream.scala:617)
2016-12-14 14:09:22.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 151.0 with 1 tasks
2016-12-14 14:09:22.021 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 151.0 (TID 151, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:22.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 151.0 (TID 151)
2016-12-14 14:09:22.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 151.0 (TID 151). 1159 bytes result sent to driver
2016-12-14 14:09:22.025 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 151.0 (TID 151) in 4 ms on localhost (1/1)
2016-12-14 14:09:22.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 151.0, whose tasks have all completed, from pool 
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 151 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 152)
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:22.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 152 (MapPartitionsRDD[684] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:22.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_152 stored as values in memory (estimated size 3.7 KB, free 491.8 KB)
2016-12-14 14:09:22.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_152_piece0 stored as bytes in memory (estimated size 2.1 KB, free 493.9 KB)
2016-12-14 14:09:22.030 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_152_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:22.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 152 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:22.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[684] at count at LogStream.java:120)
2016-12-14 14:09:22.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 152.0 with 1 tasks
2016-12-14 14:09:22.038 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 152.0 (TID 152, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:22.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 152.0 (TID 152)
2016-12-14 14:09:22.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:22.040 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:22.041 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 152.0 (TID 152). 1241 bytes result sent to driver
2016-12-14 14:09:22.041 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 152.0 (TID 152) in 10 ms on localhost (1/1)
2016-12-14 14:09:22.041 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2016-12-14 14:09:22.041 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 152 (take at LogStream.java:127) finished in 0.010 s
2016-12-14 14:09:22.042 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 76 finished: take at LogStream.java:127, took 0.030542 s
2016-12-14 14:09:22.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695762000 ms.1 from job set of time 1481695762000 ms
2016-12-14 14:09:22.048 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.047 s for time 1481695762000 ms (execution: 0.039 s)
2016-12-14 14:09:22.048 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 667 from persistence list
2016-12-14 14:09:22.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 667
2016-12-14 14:09:22.048 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[667] at createStream at LogStream.java:100 of time 1481695762000 ms
2016-12-14 14:09:22.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 675 from persistence list
2016-12-14 14:09:22.048 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 675
2016-12-14 14:09:22.048 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 674 from persistence list
2016-12-14 14:09:22.048 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 674
2016-12-14 14:09:22.048 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 673 from persistence list
2016-12-14 14:09:22.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 673
2016-12-14 14:09:22.049 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 672 from persistence list
2016-12-14 14:09:22.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 672
2016-12-14 14:09:22.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 670 from persistence list
2016-12-14 14:09:22.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 670
2016-12-14 14:09:22.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 669 from persistence list
2016-12-14 14:09:22.049 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 669
2016-12-14 14:09:22.049 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 668 from persistence list
2016-12-14 14:09:22.049 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 668
2016-12-14 14:09:22.049 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695760000 ms)
2016-12-14 14:09:22.049 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695760000 ms
2016-12-14 14:09:23.013 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695763000 ms
2016-12-14 14:09:23.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695763000 ms.0 from job set of time 1481695763000 ms
2016-12-14 14:09:23.015 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695763000 ms.0 from job set of time 1481695763000 ms
2016-12-14 14:09:23.016 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695763000 ms.1 from job set of time 1481695763000 ms
2016-12-14 14:09:23.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:23.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 690 (union at DStream.scala:617)
2016-12-14 14:09:23.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 77 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:23.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 154 (take at LogStream.java:127)
2016-12-14 14:09:23.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 153)
2016-12-14 14:09:23.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 153)
2016-12-14 14:09:23.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 153 (UnionRDD[690] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:23.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_153 stored as values in memory (estimated size 4.2 KB, free 498.1 KB)
2016-12-14 14:09:23.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_153_piece0 stored as bytes in memory (estimated size 2.4 KB, free 500.6 KB)
2016-12-14 14:09:23.028 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_153_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:23.030 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 153 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:23.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 153 (UnionRDD[690] at union at DStream.scala:617)
2016-12-14 14:09:23.030 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 153.0 with 1 tasks
2016-12-14 14:09:23.034 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 153.0 (TID 153, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:23.034 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 153.0 (TID 153)
2016-12-14 14:09:23.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 153.0 (TID 153). 1159 bytes result sent to driver
2016-12-14 14:09:23.039 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 153.0 (TID 153) in 6 ms on localhost (1/1)
2016-12-14 14:09:23.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 153 (union at DStream.scala:617) finished in 0.009 s
2016-12-14 14:09:23.039 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 153.0, whose tasks have all completed, from pool 
2016-12-14 14:09:23.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:23.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:23.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 154)
2016-12-14 14:09:23.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:23.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 154 (MapPartitionsRDD[693] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:23.041 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_154 stored as values in memory (estimated size 3.7 KB, free 504.3 KB)
2016-12-14 14:09:23.045 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_154_piece0 stored as bytes in memory (estimated size 2.1 KB, free 506.4 KB)
2016-12-14 14:09:23.046 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_154_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:23.053 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 154 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:23.053 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[693] at count at LogStream.java:120)
2016-12-14 14:09:23.053 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 154.0 with 1 tasks
2016-12-14 14:09:23.053 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 154.0 (TID 154, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:23.053 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 154.0 (TID 154)
2016-12-14 14:09:23.056 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:23.056 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:23.057 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 154.0 (TID 154). 1241 bytes result sent to driver
2016-12-14 14:09:23.058 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 154.0 (TID 154) in 5 ms on localhost (1/1)
2016-12-14 14:09:23.058 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 154 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:09:23.058 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2016-12-14 14:09:23.058 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 77 finished: take at LogStream.java:127, took 0.039564 s
2016-12-14 14:09:23.063 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695763000 ms.1 from job set of time 1481695763000 ms
2016-12-14 14:09:23.063 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 676 from persistence list
2016-12-14 14:09:23.063 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.063 s for time 1481695763000 ms (execution: 0.049 s)
2016-12-14 14:09:23.063 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 676
2016-12-14 14:09:23.063 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[676] at createStream at LogStream.java:100 of time 1481695763000 ms
2016-12-14 14:09:23.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 684 from persistence list
2016-12-14 14:09:23.063 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 684
2016-12-14 14:09:23.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 683 from persistence list
2016-12-14 14:09:23.064 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 683
2016-12-14 14:09:23.064 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 682 from persistence list
2016-12-14 14:09:23.064 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 682
2016-12-14 14:09:23.064 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 681 from persistence list
2016-12-14 14:09:23.064 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 681
2016-12-14 14:09:23.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 679 from persistence list
2016-12-14 14:09:23.064 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 679
2016-12-14 14:09:23.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 678 from persistence list
2016-12-14 14:09:23.065 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 678
2016-12-14 14:09:23.065 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 677 from persistence list
2016-12-14 14:09:23.065 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 677
2016-12-14 14:09:23.065 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695761000 ms)
2016-12-14 14:09:23.065 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695761000 ms
2016-12-14 14:09:24.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695764000 ms
2016-12-14 14:09:24.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695764000 ms.0 from job set of time 1481695764000 ms
2016-12-14 14:09:24.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695764000 ms.0 from job set of time 1481695764000 ms
2016-12-14 14:09:24.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695764000 ms.1 from job set of time 1481695764000 ms
2016-12-14 14:09:24.021 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 699 (union at DStream.scala:617)
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 78 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 156 (take at LogStream.java:127)
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 155)
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 155)
2016-12-14 14:09:24.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 155 (UnionRDD[699] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:24.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_155 stored as values in memory (estimated size 4.2 KB, free 510.6 KB)
2016-12-14 14:09:24.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_155_piece0 stored as bytes in memory (estimated size 2.4 KB, free 513.0 KB)
2016-12-14 14:09:24.031 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_155_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:24.032 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 155 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:24.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 155 (UnionRDD[699] at union at DStream.scala:617)
2016-12-14 14:09:24.032 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 155.0 with 1 tasks
2016-12-14 14:09:24.033 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 155.0 (TID 155, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:24.033 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 155.0 (TID 155)
2016-12-14 14:09:24.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 155.0 (TID 155). 1159 bytes result sent to driver
2016-12-14 14:09:24.036 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 155.0 (TID 155) in 3 ms on localhost (1/1)
2016-12-14 14:09:24.036 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 155.0, whose tasks have all completed, from pool 
2016-12-14 14:09:24.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 155 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:24.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:24.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:24.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 156)
2016-12-14 14:09:24.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:24.037 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 156 (MapPartitionsRDD[702] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:24.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_156 stored as values in memory (estimated size 3.7 KB, free 516.7 KB)
2016-12-14 14:09:24.043 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_156_piece0 stored as bytes in memory (estimated size 2.1 KB, free 518.8 KB)
2016-12-14 14:09:24.043 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_156_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:24.044 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 156 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:24.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[702] at count at LogStream.java:120)
2016-12-14 14:09:24.045 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 156.0 with 1 tasks
2016-12-14 14:09:24.046 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 156.0 (TID 156, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:24.046 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 156.0 (TID 156)
2016-12-14 14:09:24.047 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:24.048 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:24.049 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 156.0 (TID 156). 1241 bytes result sent to driver
2016-12-14 14:09:24.049 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 156.0 (TID 156) in 3 ms on localhost (1/1)
2016-12-14 14:09:24.049 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2016-12-14 14:09:24.054 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 156 (take at LogStream.java:127) finished in 0.009 s
2016-12-14 14:09:24.055 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 78 finished: take at LogStream.java:127, took 0.033912 s
2016-12-14 14:09:24.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695764000 ms.1 from job set of time 1481695764000 ms
2016-12-14 14:09:24.060 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 685 from persistence list
2016-12-14 14:09:24.060 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.060 s for time 1481695764000 ms (execution: 0.045 s)
2016-12-14 14:09:24.060 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 685
2016-12-14 14:09:24.060 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[685] at createStream at LogStream.java:100 of time 1481695764000 ms
2016-12-14 14:09:24.060 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 693 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 693
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 692 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 692
2016-12-14 14:09:24.061 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 691 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 691
2016-12-14 14:09:24.061 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 690 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 690
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 688 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 688
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 687 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 687
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 686 from persistence list
2016-12-14 14:09:24.061 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 686
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695762000 ms)
2016-12-14 14:09:24.061 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695762000 ms
2016-12-14 14:09:25.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695765000 ms
2016-12-14 14:09:25.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695765000 ms.0 from job set of time 1481695765000 ms
2016-12-14 14:09:25.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695765000 ms.0 from job set of time 1481695765000 ms
2016-12-14 14:09:25.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695765000 ms.1 from job set of time 1481695765000 ms
2016-12-14 14:09:25.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 708 (union at DStream.scala:617)
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 79 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 158 (take at LogStream.java:127)
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 157)
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 157)
2016-12-14 14:09:25.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 157 (UnionRDD[708] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:25.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_157 stored as values in memory (estimated size 4.2 KB, free 523.1 KB)
2016-12-14 14:09:25.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_157_piece0 stored as bytes in memory (estimated size 2.4 KB, free 525.5 KB)
2016-12-14 14:09:25.019 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_157_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:25.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 157 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:25.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 157 (UnionRDD[708] at union at DStream.scala:617)
2016-12-14 14:09:25.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 157.0 with 1 tasks
2016-12-14 14:09:25.020 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 157.0 (TID 157, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:25.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 157.0 (TID 157)
2016-12-14 14:09:25.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 157.0 (TID 157). 1159 bytes result sent to driver
2016-12-14 14:09:25.042 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 157.0 (TID 157) in 22 ms on localhost (1/1)
2016-12-14 14:09:25.043 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 157.0, whose tasks have all completed, from pool 
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 157 (union at DStream.scala:617) finished in 0.024 s
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 158)
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:25.043 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 158 (MapPartitionsRDD[711] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:25.044 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_158 stored as values in memory (estimated size 3.7 KB, free 529.2 KB)
2016-12-14 14:09:25.063 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_158_piece0 stored as bytes in memory (estimated size 2.1 KB, free 531.3 KB)
2016-12-14 14:09:25.072 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_158_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:25.073 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 158 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:25.073 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[711] at count at LogStream.java:120)
2016-12-14 14:09:25.073 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 158.0 with 1 tasks
2016-12-14 14:09:25.074 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 158.0 (TID 158, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:25.074 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 158.0 (TID 158)
2016-12-14 14:09:25.076 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:25.076 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:25.076 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 158.0 (TID 158). 1241 bytes result sent to driver
2016-12-14 14:09:25.077 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 158.0 (TID 158) in 4 ms on localhost (1/1)
2016-12-14 14:09:25.078 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2016-12-14 14:09:25.078 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 158 (take at LogStream.java:127) finished in 0.005 s
2016-12-14 14:09:25.078 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 79 finished: take at LogStream.java:127, took 0.065352 s
2016-12-14 14:09:25.087 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695765000 ms.1 from job set of time 1481695765000 ms
2016-12-14 14:09:25.088 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.087 s for time 1481695765000 ms (execution: 0.077 s)
2016-12-14 14:09:25.088 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 694 from persistence list
2016-12-14 14:09:25.088 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 694
2016-12-14 14:09:25.088 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[694] at createStream at LogStream.java:100 of time 1481695765000 ms
2016-12-14 14:09:25.088 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 702 from persistence list
2016-12-14 14:09:25.088 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 702
2016-12-14 14:09:25.088 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 701 from persistence list
2016-12-14 14:09:25.088 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 701
2016-12-14 14:09:25.088 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 700 from persistence list
2016-12-14 14:09:25.088 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 700
2016-12-14 14:09:25.088 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 699 from persistence list
2016-12-14 14:09:25.089 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 699
2016-12-14 14:09:25.089 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 697 from persistence list
2016-12-14 14:09:25.089 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 697
2016-12-14 14:09:25.089 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 696 from persistence list
2016-12-14 14:09:25.089 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 696
2016-12-14 14:09:25.089 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 695 from persistence list
2016-12-14 14:09:25.089 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 695
2016-12-14 14:09:25.089 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695763000 ms)
2016-12-14 14:09:25.089 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695763000 ms
2016-12-14 14:09:26.014 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695766000 ms
2016-12-14 14:09:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695766000 ms.0 from job set of time 1481695766000 ms
2016-12-14 14:09:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695766000 ms.0 from job set of time 1481695766000 ms
2016-12-14 14:09:26.014 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695766000 ms.1 from job set of time 1481695766000 ms
2016-12-14 14:09:26.018 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 717 (union at DStream.scala:617)
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 80 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 160 (take at LogStream.java:127)
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 159)
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 159)
2016-12-14 14:09:26.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 159 (UnionRDD[717] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:26.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_159 stored as values in memory (estimated size 4.2 KB, free 535.5 KB)
2016-12-14 14:09:26.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_159_piece0 stored as bytes in memory (estimated size 2.4 KB, free 537.9 KB)
2016-12-14 14:09:26.025 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_159_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:26.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 159 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:26.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 159 (UnionRDD[717] at union at DStream.scala:617)
2016-12-14 14:09:26.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 159.0 with 1 tasks
2016-12-14 14:09:26.026 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 159.0 (TID 159, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:26.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 159.0 (TID 159)
2016-12-14 14:09:26.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 159.0 (TID 159). 1159 bytes result sent to driver
2016-12-14 14:09:26.031 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 159.0 (TID 159) in 5 ms on localhost (1/1)
2016-12-14 14:09:26.031 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 159.0, whose tasks have all completed, from pool 
2016-12-14 14:09:26.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 159 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:26.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:26.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:26.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 160)
2016-12-14 14:09:26.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:26.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 160 (MapPartitionsRDD[720] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:26.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_160 stored as values in memory (estimated size 3.7 KB, free 541.6 KB)
2016-12-14 14:09:26.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_160_piece0 stored as bytes in memory (estimated size 2.1 KB, free 543.7 KB)
2016-12-14 14:09:26.036 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_160_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:26.036 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 160 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:26.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[720] at count at LogStream.java:120)
2016-12-14 14:09:26.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 160.0 with 1 tasks
2016-12-14 14:09:26.037 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 160.0 (TID 160, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:26.037 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 160.0 (TID 160)
2016-12-14 14:09:26.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:26.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:26.039 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 160.0 (TID 160). 1241 bytes result sent to driver
2016-12-14 14:09:26.040 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 160.0 (TID 160) in 3 ms on localhost (1/1)
2016-12-14 14:09:26.040 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2016-12-14 14:09:26.040 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 160 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:26.041 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 80 finished: take at LogStream.java:127, took 0.022728 s
2016-12-14 14:09:26.050 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695766000 ms.1 from job set of time 1481695766000 ms
2016-12-14 14:09:26.050 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.050 s for time 1481695766000 ms (execution: 0.036 s)
2016-12-14 14:09:26.050 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 703 from persistence list
2016-12-14 14:09:26.050 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 703
2016-12-14 14:09:26.050 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[703] at createStream at LogStream.java:100 of time 1481695766000 ms
2016-12-14 14:09:26.050 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 711 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 711
2016-12-14 14:09:26.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 710 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 710
2016-12-14 14:09:26.051 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 709 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 709
2016-12-14 14:09:26.051 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 708 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 708
2016-12-14 14:09:26.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 706 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 706
2016-12-14 14:09:26.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 705 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 705
2016-12-14 14:09:26.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 704 from persistence list
2016-12-14 14:09:26.051 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 704
2016-12-14 14:09:26.051 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695764000 ms)
2016-12-14 14:09:26.052 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695764000 ms
2016-12-14 14:09:27.016 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695767000 ms
2016-12-14 14:09:27.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695767000 ms.0 from job set of time 1481695767000 ms
2016-12-14 14:09:27.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695767000 ms.0 from job set of time 1481695767000 ms
2016-12-14 14:09:27.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695767000 ms.1 from job set of time 1481695767000 ms
2016-12-14 14:09:27.021 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:27.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 726 (union at DStream.scala:617)
2016-12-14 14:09:27.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 81 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:27.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 162 (take at LogStream.java:127)
2016-12-14 14:09:27.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 161)
2016-12-14 14:09:27.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 161)
2016-12-14 14:09:27.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 161 (UnionRDD[726] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:27.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_161 stored as values in memory (estimated size 4.2 KB, free 548.0 KB)
2016-12-14 14:09:27.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_161_piece0 stored as bytes in memory (estimated size 2.4 KB, free 550.4 KB)
2016-12-14 14:09:27.026 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_161_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:27.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 161 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:27.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 161 (UnionRDD[726] at union at DStream.scala:617)
2016-12-14 14:09:27.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 161.0 with 1 tasks
2016-12-14 14:09:27.031 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 161.0 (TID 161, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:27.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 161.0 (TID 161)
2016-12-14 14:09:27.035 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 161.0 (TID 161). 1159 bytes result sent to driver
2016-12-14 14:09:27.036 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 161.0 (TID 161) in 5 ms on localhost (1/1)
2016-12-14 14:09:27.036 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 161.0, whose tasks have all completed, from pool 
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 161 (union at DStream.scala:617) finished in 0.010 s
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 162)
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:27.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 162 (MapPartitionsRDD[729] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:27.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_162 stored as values in memory (estimated size 3.7 KB, free 554.1 KB)
2016-12-14 14:09:27.042 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_162_piece0 stored as bytes in memory (estimated size 2.1 KB, free 556.2 KB)
2016-12-14 14:09:27.042 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_162_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:27.042 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 162 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:27.042 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[729] at count at LogStream.java:120)
2016-12-14 14:09:27.043 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 162.0 with 1 tasks
2016-12-14 14:09:27.043 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 162.0 (TID 162, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:27.043 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 162.0 (TID 162)
2016-12-14 14:09:27.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:27.045 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:27.045 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 162.0 (TID 162). 1241 bytes result sent to driver
2016-12-14 14:09:27.046 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 162.0 (TID 162) in 3 ms on localhost (1/1)
2016-12-14 14:09:27.046 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 162 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:27.046 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2016-12-14 14:09:27.047 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 81 finished: take at LogStream.java:127, took 0.025872 s
2016-12-14 14:09:27.054 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695767000 ms.1 from job set of time 1481695767000 ms
2016-12-14 14:09:27.054 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 712 from persistence list
2016-12-14 14:09:27.054 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.054 s for time 1481695767000 ms (execution: 0.036 s)
2016-12-14 14:09:27.054 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 712
2016-12-14 14:09:27.054 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[712] at createStream at LogStream.java:100 of time 1481695767000 ms
2016-12-14 14:09:27.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 720 from persistence list
2016-12-14 14:09:27.054 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 720
2016-12-14 14:09:27.054 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 719 from persistence list
2016-12-14 14:09:27.054 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 719
2016-12-14 14:09:27.054 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 718 from persistence list
2016-12-14 14:09:27.055 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 718
2016-12-14 14:09:27.055 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 717 from persistence list
2016-12-14 14:09:27.055 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 717
2016-12-14 14:09:27.055 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 715 from persistence list
2016-12-14 14:09:27.055 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 715
2016-12-14 14:09:27.055 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 714 from persistence list
2016-12-14 14:09:27.055 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 714
2016-12-14 14:09:27.055 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 713 from persistence list
2016-12-14 14:09:27.055 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 713
2016-12-14 14:09:27.056 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695765000 ms)
2016-12-14 14:09:27.056 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695765000 ms
2016-12-14 14:09:28.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695768000 ms
2016-12-14 14:09:28.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695768000 ms.0 from job set of time 1481695768000 ms
2016-12-14 14:09:28.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695768000 ms.0 from job set of time 1481695768000 ms
2016-12-14 14:09:28.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695768000 ms.1 from job set of time 1481695768000 ms
2016-12-14 14:09:28.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 735 (union at DStream.scala:617)
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 82 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 164 (take at LogStream.java:127)
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 163)
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 163)
2016-12-14 14:09:28.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 163 (UnionRDD[735] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:28.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_163 stored as values in memory (estimated size 4.2 KB, free 560.4 KB)
2016-12-14 14:09:28.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_163_piece0 stored as bytes in memory (estimated size 2.4 KB, free 562.8 KB)
2016-12-14 14:09:28.019 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_163_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:28.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 163 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:28.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 163 (UnionRDD[735] at union at DStream.scala:617)
2016-12-14 14:09:28.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 163.0 with 1 tasks
2016-12-14 14:09:28.020 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 163.0 (TID 163, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:28.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 163.0 (TID 163)
2016-12-14 14:09:28.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 163.0 (TID 163). 1159 bytes result sent to driver
2016-12-14 14:09:28.025 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 163.0 (TID 163) in 5 ms on localhost (1/1)
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 163 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:28.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 163.0, whose tasks have all completed, from pool 
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 164)
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:28.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 164 (MapPartitionsRDD[738] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:28.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_164 stored as values in memory (estimated size 3.7 KB, free 566.5 KB)
2016-12-14 14:09:28.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_164_piece0 stored as bytes in memory (estimated size 2.1 KB, free 568.7 KB)
2016-12-14 14:09:28.028 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_164_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:28.029 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 164 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:28.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[738] at count at LogStream.java:120)
2016-12-14 14:09:28.029 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 164.0 with 1 tasks
2016-12-14 14:09:28.029 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 164.0 (TID 164, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:28.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 164.0 (TID 164)
2016-12-14 14:09:28.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:28.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:28.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 164.0 (TID 164). 1241 bytes result sent to driver
2016-12-14 14:09:28.031 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 164.0 (TID 164) in 2 ms on localhost (1/1)
2016-12-14 14:09:28.031 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2016-12-14 14:09:28.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 164 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:28.032 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 82 finished: take at LogStream.java:127, took 0.019325 s
2016-12-14 14:09:28.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695768000 ms.1 from job set of time 1481695768000 ms
2016-12-14 14:09:28.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.037 s for time 1481695768000 ms (execution: 0.028 s)
2016-12-14 14:09:28.037 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 721 from persistence list
2016-12-14 14:09:28.037 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[721] at createStream at LogStream.java:100 of time 1481695768000 ms
2016-12-14 14:09:28.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 729 from persistence list
2016-12-14 14:09:28.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 721
2016-12-14 14:09:28.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 728 from persistence list
2016-12-14 14:09:28.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 729
2016-12-14 14:09:28.041 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 728
2016-12-14 14:09:28.041 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 727 from persistence list
2016-12-14 14:09:28.041 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 727
2016-12-14 14:09:28.041 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 726 from persistence list
2016-12-14 14:09:28.042 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 726
2016-12-14 14:09:28.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 724 from persistence list
2016-12-14 14:09:28.042 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 724
2016-12-14 14:09:28.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 723 from persistence list
2016-12-14 14:09:28.042 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 723
2016-12-14 14:09:28.042 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 722 from persistence list
2016-12-14 14:09:28.042 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 722
2016-12-14 14:09:28.042 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695766000 ms)
2016-12-14 14:09:28.042 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695766000 ms
2016-12-14 14:09:29.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695769000 ms
2016-12-14 14:09:29.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695769000 ms.0 from job set of time 1481695769000 ms
2016-12-14 14:09:29.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695769000 ms.0 from job set of time 1481695769000 ms
2016-12-14 14:09:29.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695769000 ms.1 from job set of time 1481695769000 ms
2016-12-14 14:09:29.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:29.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 744 (union at DStream.scala:617)
2016-12-14 14:09:29.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 83 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:29.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 166 (take at LogStream.java:127)
2016-12-14 14:09:29.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 165)
2016-12-14 14:09:29.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 165)
2016-12-14 14:09:29.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 165 (UnionRDD[744] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:29.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_165 stored as values in memory (estimated size 4.2 KB, free 572.9 KB)
2016-12-14 14:09:29.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_165_piece0 stored as bytes in memory (estimated size 2.4 KB, free 575.3 KB)
2016-12-14 14:09:29.022 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_165_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:29.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 165 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:29.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 165 (UnionRDD[744] at union at DStream.scala:617)
2016-12-14 14:09:29.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 165.0 with 1 tasks
2016-12-14 14:09:29.029 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 165.0 (TID 165, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:29.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 165.0 (TID 165)
2016-12-14 14:09:29.031 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 165.0 (TID 165). 1159 bytes result sent to driver
2016-12-14 14:09:29.031 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 165.0 (TID 165) in 3 ms on localhost (1/1)
2016-12-14 14:09:29.032 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 165.0, whose tasks have all completed, from pool 
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 165 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 166)
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:29.032 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 166 (MapPartitionsRDD[747] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:29.033 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_166 stored as values in memory (estimated size 3.7 KB, free 579.0 KB)
2016-12-14 14:09:29.035 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_166_piece0 stored as bytes in memory (estimated size 2.1 KB, free 581.1 KB)
2016-12-14 14:09:29.035 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_166_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:29.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 166 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:29.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[747] at count at LogStream.java:120)
2016-12-14 14:09:29.036 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 166.0 with 1 tasks
2016-12-14 14:09:29.036 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 166.0 (TID 166, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:29.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 166.0 (TID 166)
2016-12-14 14:09:29.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:29.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:29.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 166.0 (TID 166). 1241 bytes result sent to driver
2016-12-14 14:09:29.038 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 166.0 (TID 166) in 2 ms on localhost (1/1)
2016-12-14 14:09:29.038 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2016-12-14 14:09:29.038 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 166 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:29.038 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 83 finished: take at LogStream.java:127, took 0.024846 s
2016-12-14 14:09:29.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695769000 ms.1 from job set of time 1481695769000 ms
2016-12-14 14:09:29.043 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 730 from persistence list
2016-12-14 14:09:29.043 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.043 s for time 1481695769000 ms (execution: 0.033 s)
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 730
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[730] at createStream at LogStream.java:100 of time 1481695769000 ms
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 738 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 738
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 737 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 737
2016-12-14 14:09:29.044 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 736 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 736
2016-12-14 14:09:29.044 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 735 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 735
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 733 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 733
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 732 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 732
2016-12-14 14:09:29.044 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 731 from persistence list
2016-12-14 14:09:29.044 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 731
2016-12-14 14:09:29.045 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695767000 ms)
2016-12-14 14:09:29.045 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695767000 ms
2016-12-14 14:09:30.017 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695770000 ms
2016-12-14 14:09:30.017 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695770000 ms.0 from job set of time 1481695770000 ms
2016-12-14 14:09:30.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695770000 ms.0 from job set of time 1481695770000 ms
2016-12-14 14:09:30.018 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695770000 ms.1 from job set of time 1481695770000 ms
2016-12-14 14:09:30.034 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:30.036 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 116
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 753 (union at DStream.scala:617)
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 84 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 168 (take at LogStream.java:127)
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 167)
2016-12-14 14:09:30.036 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 57
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 167)
2016-12-14 14:09:30.036 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 167 (UnionRDD[753] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:30.037 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_114_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.037 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_167 stored as values in memory (estimated size 4.2 KB, free 583.2 KB)
2016-12-14 14:09:30.038 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 115
2016-12-14 14:09:30.038 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_167_piece0 stored as bytes in memory (estimated size 2.4 KB, free 581.9 KB)
2016-12-14 14:09:30.038 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_167_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.039 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_113_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.039 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 167 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:30.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 167 (UnionRDD[753] at union at DStream.scala:617)
2016-12-14 14:09:30.039 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 114
2016-12-14 14:09:30.039 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 167.0 with 1 tasks
2016-12-14 14:09:30.039 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 56
2016-12-14 14:09:30.040 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 167.0 (TID 167, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:30.040 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 167.0 (TID 167)
2016-12-14 14:09:30.040 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_112_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.040 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 113
2016-12-14 14:09:30.044 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_111_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.044 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 167.0 (TID 167). 1159 bytes result sent to driver
2016-12-14 14:09:30.044 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 112
2016-12-14 14:09:30.044 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 167.0 (TID 167) in 5 ms on localhost (1/1)
2016-12-14 14:09:30.045 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 167.0, whose tasks have all completed, from pool 
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 167 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 168)
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:30.045 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 168 (MapPartitionsRDD[756] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:30.045 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 55
2016-12-14 14:09:30.046 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_168 stored as values in memory (estimated size 3.7 KB, free 566.5 KB)
2016-12-14 14:09:30.050 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_110_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.050 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_168_piece0 stored as bytes in memory (estimated size 2.1 KB, free 566.5 KB)
2016-12-14 14:09:30.051 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_168_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.051 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 111
2016-12-14 14:09:30.051 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 168 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:30.051 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[756] at count at LogStream.java:120)
2016-12-14 14:09:30.051 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 168.0 with 1 tasks
2016-12-14 14:09:30.052 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_109_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.052 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 168.0 (TID 168, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:30.052 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 168.0 (TID 168)
2016-12-14 14:09:30.053 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 110
2016-12-14 14:09:30.053 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 54
2016-12-14 14:09:30.054 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:30.054 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:30.054 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_108_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.054 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 109
2016-12-14 14:09:30.055 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_107_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.055 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 168.0 (TID 168). 1241 bytes result sent to driver
2016-12-14 14:09:30.055 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 108
2016-12-14 14:09:30.055 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 168.0 (TID 168) in 3 ms on localhost (1/1)
2016-12-14 14:09:30.055 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 53
2016-12-14 14:09:30.055 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2016-12-14 14:09:30.056 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_106_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.056 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 107
2016-12-14 14:09:30.056 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 168 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:30.056 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 84 finished: take at LogStream.java:127, took 0.021956 s
2016-12-14 14:09:30.057 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_105_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.057 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 106
2016-12-14 14:09:30.057 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 52
2016-12-14 14:09:30.057 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_104_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.058 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 105
2016-12-14 14:09:30.058 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_103_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.059 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 104
2016-12-14 14:09:30.059 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 51
2016-12-14 14:09:30.059 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_102_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.060 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 103
2016-12-14 14:09:30.060 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_101_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.060 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 102
2016-12-14 14:09:30.061 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 50
2016-12-14 14:09:30.061 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_100_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.061 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 101
2016-12-14 14:09:30.062 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695770000 ms.1 from job set of time 1481695770000 ms
2016-12-14 14:09:30.062 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_99_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.062 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.062 s for time 1481695770000 ms (execution: 0.045 s)
2016-12-14 14:09:30.062 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 739 from persistence list
2016-12-14 14:09:30.062 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 100
2016-12-14 14:09:30.062 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 739
2016-12-14 14:09:30.062 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 49
2016-12-14 14:09:30.063 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[739] at createStream at LogStream.java:100 of time 1481695770000 ms
2016-12-14 14:09:30.063 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_98_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 747 from persistence list
2016-12-14 14:09:30.063 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 747
2016-12-14 14:09:30.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 746 from persistence list
2016-12-14 14:09:30.063 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 99
2016-12-14 14:09:30.063 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 746
2016-12-14 14:09:30.063 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 745 from persistence list
2016-12-14 14:09:30.063 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 745
2016-12-14 14:09:30.063 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 744 from persistence list
2016-12-14 14:09:30.063 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_97_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.063 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 744
2016-12-14 14:09:30.063 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 742 from persistence list
2016-12-14 14:09:30.064 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 98
2016-12-14 14:09:30.064 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 742
2016-12-14 14:09:30.064 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 48
2016-12-14 14:09:30.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 741 from persistence list
2016-12-14 14:09:30.064 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 741
2016-12-14 14:09:30.064 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_96_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.064 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 740 from persistence list
2016-12-14 14:09:30.065 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 740
2016-12-14 14:09:30.065 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 97
2016-12-14 14:09:30.065 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695768000 ms)
2016-12-14 14:09:30.065 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695768000 ms
2016-12-14 14:09:30.065 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_95_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.065 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 96
2016-12-14 14:09:30.065 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 47
2016-12-14 14:09:30.066 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_94_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.066 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 95
2016-12-14 14:09:30.066 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_93_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.067 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 94
2016-12-14 14:09:30.067 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 46
2016-12-14 14:09:30.067 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_92_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.068 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 141
2016-12-14 14:09:30.068 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_139_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.068 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 140
2016-12-14 14:09:30.068 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 69
2016-12-14 14:09:30.069 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_138_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.069 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 139
2016-12-14 14:09:30.069 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_137_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 138
2016-12-14 14:09:30.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 68
2016-12-14 14:09:30.070 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_136_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.070 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 137
2016-12-14 14:09:30.071 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_135_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.071 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 136
2016-12-14 14:09:30.071 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 67
2016-12-14 14:09:30.071 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_134_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.072 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 135
2016-12-14 14:09:30.072 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_133_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.072 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 134
2016-12-14 14:09:30.072 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 66
2016-12-14 14:09:30.073 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_132_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 133
2016-12-14 14:09:30.073 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_131_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 132
2016-12-14 14:09:30.073 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 65
2016-12-14 14:09:30.074 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_130_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.2 MB)
2016-12-14 14:09:30.074 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 131
2016-12-14 14:09:30.074 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_129_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.2 MB)
2016-12-14 14:09:30.075 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 130
2016-12-14 14:09:30.075 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 64
2016-12-14 14:09:30.075 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_128_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.075 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 129
2016-12-14 14:09:30.076 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_127_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.076 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 128
2016-12-14 14:09:30.076 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 63
2016-12-14 14:09:30.077 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_126_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.077 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 127
2016-12-14 14:09:30.077 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_125_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.077 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 126
2016-12-14 14:09:30.078 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 62
2016-12-14 14:09:30.078 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_124_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.078 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 125
2016-12-14 14:09:30.079 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_123_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.079 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 124
2016-12-14 14:09:30.079 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 61
2016-12-14 14:09:30.080 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_122_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.080 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 123
2016-12-14 14:09:30.080 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_121_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.080 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 122
2016-12-14 14:09:30.081 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 60
2016-12-14 14:09:30.081 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_120_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.081 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 121
2016-12-14 14:09:30.081 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_119_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.082 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 120
2016-12-14 14:09:30.082 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 59
2016-12-14 14:09:30.082 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_118_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.082 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 119
2016-12-14 14:09:30.083 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_117_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 118
2016-12-14 14:09:30.083 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 58
2016-12-14 14:09:30.084 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_116_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.084 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 117
2016-12-14 14:09:30.084 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_115_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.085 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_166_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.085 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 167
2016-12-14 14:09:30.086 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_165_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.086 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 166
2016-12-14 14:09:30.086 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_164_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.087 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 165
2016-12-14 14:09:30.087 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_163_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.087 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 164
2016-12-14 14:09:30.087 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 81
2016-12-14 14:09:30.088 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_162_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.088 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 163
2016-12-14 14:09:30.088 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_161_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.089 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 162
2016-12-14 14:09:30.089 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 80
2016-12-14 14:09:30.089 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_160_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.089 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 161
2016-12-14 14:09:30.090 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_159_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.090 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 160
2016-12-14 14:09:30.090 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 79
2016-12-14 14:09:30.090 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_158_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.090 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 159
2016-12-14 14:09:30.091 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_157_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.091 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 158
2016-12-14 14:09:30.091 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 78
2016-12-14 14:09:30.092 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_156_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.092 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 157
2016-12-14 14:09:30.092 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_155_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.092 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 156
2016-12-14 14:09:30.092 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 77
2016-12-14 14:09:30.093 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_154_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.093 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 155
2016-12-14 14:09:30.093 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_153_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.094 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 154
2016-12-14 14:09:30.094 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 76
2016-12-14 14:09:30.094 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_152_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.094 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 153
2016-12-14 14:09:30.095 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_151_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.095 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 152
2016-12-14 14:09:30.095 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 75
2016-12-14 14:09:30.096 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_150_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.096 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 151
2016-12-14 14:09:30.096 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_149_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.096 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 150
2016-12-14 14:09:30.097 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 74
2016-12-14 14:09:30.097 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_148_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.097 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 149
2016-12-14 14:09:30.098 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_147_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.098 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 148
2016-12-14 14:09:30.098 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 73
2016-12-14 14:09:30.099 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_146_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.099 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 147
2016-12-14 14:09:30.099 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_145_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.099 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 146
2016-12-14 14:09:30.100 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 72
2016-12-14 14:09:30.100 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_144_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.100 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 145
2016-12-14 14:09:30.100 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_143_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.101 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 144
2016-12-14 14:09:30.101 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 71
2016-12-14 14:09:30.101 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_142_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:30.102 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 143
2016-12-14 14:09:30.102 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_141_piece0 on localhost:60466 in memory (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:30.102 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned accumulator 142
2016-12-14 14:09:30.102 [Spark Context Cleaner] INFO  org.apache.spark.ContextCleaner - Cleaned shuffle 70
2016-12-14 14:09:30.103 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_140_piece0 on localhost:60466 in memory (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:31.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695771000 ms
2016-12-14 14:09:31.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695771000 ms.0 from job set of time 1481695771000 ms
2016-12-14 14:09:31.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695771000 ms.0 from job set of time 1481695771000 ms
2016-12-14 14:09:31.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695771000 ms.1 from job set of time 1481695771000 ms
2016-12-14 14:09:31.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 762 (union at DStream.scala:617)
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 85 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 170 (take at LogStream.java:127)
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 169)
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 169)
2016-12-14 14:09:31.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 169 (UnionRDD[762] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:31.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_169 stored as values in memory (estimated size 4.2 KB, free 131.2 KB)
2016-12-14 14:09:31.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_169_piece0 stored as bytes in memory (estimated size 2.4 KB, free 133.6 KB)
2016-12-14 14:09:31.016 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_169_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:31.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 169 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:31.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 169 (UnionRDD[762] at union at DStream.scala:617)
2016-12-14 14:09:31.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 169.0 with 1 tasks
2016-12-14 14:09:31.017 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 169.0 (TID 169, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:31.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 169.0 (TID 169)
2016-12-14 14:09:31.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 169.0 (TID 169). 1159 bytes result sent to driver
2016-12-14 14:09:31.021 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 169.0 (TID 169) in 4 ms on localhost (1/1)
2016-12-14 14:09:31.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 169 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:31.021 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 169.0, whose tasks have all completed, from pool 
2016-12-14 14:09:31.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:31.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:31.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 170)
2016-12-14 14:09:31.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:31.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 170 (MapPartitionsRDD[765] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:31.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_170 stored as values in memory (estimated size 3.7 KB, free 137.3 KB)
2016-12-14 14:09:31.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_170_piece0 stored as bytes in memory (estimated size 2.1 KB, free 139.4 KB)
2016-12-14 14:09:31.025 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_170_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:31.025 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 170 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:31.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[765] at count at LogStream.java:120)
2016-12-14 14:09:31.025 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 170.0 with 1 tasks
2016-12-14 14:09:31.026 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 170.0 (TID 170, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:31.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 170.0 (TID 170)
2016-12-14 14:09:31.027 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:31.027 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:31.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 170.0 (TID 170). 1241 bytes result sent to driver
2016-12-14 14:09:31.028 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 170.0 (TID 170) in 2 ms on localhost (1/1)
2016-12-14 14:09:31.028 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2016-12-14 14:09:31.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 170 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:31.029 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 85 finished: take at LogStream.java:127, took 0.015388 s
2016-12-14 14:09:31.033 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695771000 ms.1 from job set of time 1481695771000 ms
2016-12-14 14:09:31.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.033 s for time 1481695771000 ms (execution: 0.024 s)
2016-12-14 14:09:31.034 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 748 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 748
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[748] at createStream at LogStream.java:100 of time 1481695771000 ms
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 756 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 756
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 755 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 755
2016-12-14 14:09:31.034 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 754 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 754
2016-12-14 14:09:31.034 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 753 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 753
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 751 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 751
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 750 from persistence list
2016-12-14 14:09:31.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 750
2016-12-14 14:09:31.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 749 from persistence list
2016-12-14 14:09:31.035 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 749
2016-12-14 14:09:31.035 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695769000 ms)
2016-12-14 14:09:31.035 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695769000 ms
2016-12-14 14:09:32.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695772000 ms
2016-12-14 14:09:32.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695772000 ms.0 from job set of time 1481695772000 ms
2016-12-14 14:09:32.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695772000 ms.0 from job set of time 1481695772000 ms
2016-12-14 14:09:32.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695772000 ms.1 from job set of time 1481695772000 ms
2016-12-14 14:09:32.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 771 (union at DStream.scala:617)
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 86 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 172 (take at LogStream.java:127)
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 171)
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 171)
2016-12-14 14:09:32.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 171 (UnionRDD[771] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:32.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_171 stored as values in memory (estimated size 4.2 KB, free 143.7 KB)
2016-12-14 14:09:32.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_171_piece0 stored as bytes in memory (estimated size 2.4 KB, free 146.1 KB)
2016-12-14 14:09:32.014 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_171_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:32.015 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 171 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:32.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 171 (UnionRDD[771] at union at DStream.scala:617)
2016-12-14 14:09:32.015 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 171.0 with 1 tasks
2016-12-14 14:09:32.015 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 171.0 (TID 171, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:32.015 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 171.0 (TID 171)
2016-12-14 14:09:32.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 171.0 (TID 171). 1159 bytes result sent to driver
2016-12-14 14:09:32.019 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 171.0 (TID 171) in 4 ms on localhost (1/1)
2016-12-14 14:09:32.019 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 171.0, whose tasks have all completed, from pool 
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 171 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 172)
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:32.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 172 (MapPartitionsRDD[774] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:32.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_172 stored as values in memory (estimated size 3.7 KB, free 149.8 KB)
2016-12-14 14:09:32.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_172_piece0 stored as bytes in memory (estimated size 2.1 KB, free 151.9 KB)
2016-12-14 14:09:32.022 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_172_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:32.022 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 172 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:32.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[774] at count at LogStream.java:120)
2016-12-14 14:09:32.022 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 172.0 with 1 tasks
2016-12-14 14:09:32.022 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 172.0 (TID 172, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:32.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 172.0 (TID 172)
2016-12-14 14:09:32.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:32.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:32.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 172.0 (TID 172). 1241 bytes result sent to driver
2016-12-14 14:09:32.025 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 172.0 (TID 172) in 3 ms on localhost (1/1)
2016-12-14 14:09:32.025 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2016-12-14 14:09:32.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 172 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:32.025 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 86 finished: take at LogStream.java:127, took 0.014050 s
2016-12-14 14:09:32.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695772000 ms.1 from job set of time 1481695772000 ms
2016-12-14 14:09:32.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.030 s for time 1481695772000 ms (execution: 0.021 s)
2016-12-14 14:09:32.030 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 757 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 757
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[757] at createStream at LogStream.java:100 of time 1481695772000 ms
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 765 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 765
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 764 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 764
2016-12-14 14:09:32.031 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 763 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 763
2016-12-14 14:09:32.031 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 762 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 762
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 760 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 760
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 759 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 759
2016-12-14 14:09:32.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 758 from persistence list
2016-12-14 14:09:32.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 758
2016-12-14 14:09:32.032 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695770000 ms)
2016-12-14 14:09:32.032 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695770000 ms
2016-12-14 14:09:33.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695773000 ms
2016-12-14 14:09:33.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695773000 ms.0 from job set of time 1481695773000 ms
2016-12-14 14:09:33.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695773000 ms.0 from job set of time 1481695773000 ms
2016-12-14 14:09:33.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695773000 ms.1 from job set of time 1481695773000 ms
2016-12-14 14:09:33.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:33.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 780 (union at DStream.scala:617)
2016-12-14 14:09:33.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 87 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 174 (take at LogStream.java:127)
2016-12-14 14:09:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 173)
2016-12-14 14:09:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 173)
2016-12-14 14:09:33.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 173 (UnionRDD[780] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:33.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_173 stored as values in memory (estimated size 4.2 KB, free 156.1 KB)
2016-12-14 14:09:33.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_173_piece0 stored as bytes in memory (estimated size 2.4 KB, free 158.6 KB)
2016-12-14 14:09:33.018 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_173_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:33.018 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 173 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:33.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 173 (UnionRDD[780] at union at DStream.scala:617)
2016-12-14 14:09:33.018 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 173.0 with 1 tasks
2016-12-14 14:09:33.019 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 173.0 (TID 173, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:33.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 173.0 (TID 173)
2016-12-14 14:09:33.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 173.0 (TID 173). 1159 bytes result sent to driver
2016-12-14 14:09:33.023 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 173.0 (TID 173) in 4 ms on localhost (1/1)
2016-12-14 14:09:33.023 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 173.0, whose tasks have all completed, from pool 
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 173 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 174)
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:33.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 174 (MapPartitionsRDD[783] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:33.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_174 stored as values in memory (estimated size 3.7 KB, free 162.2 KB)
2016-12-14 14:09:33.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_174_piece0 stored as bytes in memory (estimated size 2.1 KB, free 164.4 KB)
2016-12-14 14:09:33.025 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_174_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:33.026 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 174 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:33.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[783] at count at LogStream.java:120)
2016-12-14 14:09:33.026 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 174.0 with 1 tasks
2016-12-14 14:09:33.026 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 174.0 (TID 174, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:33.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 174.0 (TID 174)
2016-12-14 14:09:33.027 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:33.027 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:33.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 174.0 (TID 174). 1241 bytes result sent to driver
2016-12-14 14:09:33.029 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 174.0 (TID 174) in 3 ms on localhost (1/1)
2016-12-14 14:09:33.029 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2016-12-14 14:09:33.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 174 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:33.029 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 87 finished: take at LogStream.java:127, took 0.014459 s
2016-12-14 14:09:33.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695773000 ms.1 from job set of time 1481695773000 ms
2016-12-14 14:09:33.034 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.034 s for time 1481695773000 ms (execution: 0.022 s)
2016-12-14 14:09:33.034 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 766 from persistence list
2016-12-14 14:09:33.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 766
2016-12-14 14:09:33.034 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[766] at createStream at LogStream.java:100 of time 1481695773000 ms
2016-12-14 14:09:33.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 774 from persistence list
2016-12-14 14:09:33.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 774
2016-12-14 14:09:33.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 773 from persistence list
2016-12-14 14:09:33.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 773
2016-12-14 14:09:33.034 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 772 from persistence list
2016-12-14 14:09:33.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 772
2016-12-14 14:09:33.035 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 771 from persistence list
2016-12-14 14:09:33.035 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 771
2016-12-14 14:09:33.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 769 from persistence list
2016-12-14 14:09:33.035 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 769
2016-12-14 14:09:33.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 768 from persistence list
2016-12-14 14:09:33.035 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 768
2016-12-14 14:09:33.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 767 from persistence list
2016-12-14 14:09:33.035 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 767
2016-12-14 14:09:33.035 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695771000 ms)
2016-12-14 14:09:33.035 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695771000 ms
2016-12-14 14:09:34.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695774000 ms
2016-12-14 14:09:34.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695774000 ms.0 from job set of time 1481695774000 ms
2016-12-14 14:09:34.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695774000 ms.0 from job set of time 1481695774000 ms
2016-12-14 14:09:34.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695774000 ms.1 from job set of time 1481695774000 ms
2016-12-14 14:09:34.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:34.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 789 (union at DStream.scala:617)
2016-12-14 14:09:34.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 88 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:34.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 176 (take at LogStream.java:127)
2016-12-14 14:09:34.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 175)
2016-12-14 14:09:34.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 175)
2016-12-14 14:09:34.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 175 (UnionRDD[789] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:34.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_175 stored as values in memory (estimated size 4.2 KB, free 168.6 KB)
2016-12-14 14:09:34.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_175_piece0 stored as bytes in memory (estimated size 2.4 KB, free 171.0 KB)
2016-12-14 14:09:34.017 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_175_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:34.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 175 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:34.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 175 (UnionRDD[789] at union at DStream.scala:617)
2016-12-14 14:09:34.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 175.0 with 1 tasks
2016-12-14 14:09:34.018 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 175.0 (TID 175, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:34.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 175.0 (TID 175)
2016-12-14 14:09:34.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 175.0 (TID 175). 1159 bytes result sent to driver
2016-12-14 14:09:34.021 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 175.0 (TID 175) in 3 ms on localhost (1/1)
2016-12-14 14:09:34.021 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 175.0, whose tasks have all completed, from pool 
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 175 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 176)
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:34.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 176 (MapPartitionsRDD[792] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:34.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_176 stored as values in memory (estimated size 3.7 KB, free 174.7 KB)
2016-12-14 14:09:34.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_176_piece0 stored as bytes in memory (estimated size 2.1 KB, free 176.8 KB)
2016-12-14 14:09:34.024 [dispatcher-event-loop-3] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_176_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:34.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 176 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:34.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[792] at count at LogStream.java:120)
2016-12-14 14:09:34.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 176.0 with 1 tasks
2016-12-14 14:09:34.025 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 176.0 (TID 176, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:34.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 176.0 (TID 176)
2016-12-14 14:09:34.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:34.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:34.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 176.0 (TID 176). 1241 bytes result sent to driver
2016-12-14 14:09:34.027 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 176.0 (TID 176) in 2 ms on localhost (1/1)
2016-12-14 14:09:34.027 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2016-12-14 14:09:34.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 176 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:34.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 88 finished: take at LogStream.java:127, took 0.013892 s
2016-12-14 14:09:34.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695774000 ms.1 from job set of time 1481695774000 ms
2016-12-14 14:09:34.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.032 s for time 1481695774000 ms (execution: 0.022 s)
2016-12-14 14:09:34.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 775 from persistence list
2016-12-14 14:09:34.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 775
2016-12-14 14:09:34.032 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[775] at createStream at LogStream.java:100 of time 1481695774000 ms
2016-12-14 14:09:34.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 783 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 783
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 782 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 782
2016-12-14 14:09:34.033 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 781 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 781
2016-12-14 14:09:34.033 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 780 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 780
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 778 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 778
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 777 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 777
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 776 from persistence list
2016-12-14 14:09:34.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 776
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695772000 ms)
2016-12-14 14:09:34.033 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695772000 ms
2016-12-14 14:09:35.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695775000 ms
2016-12-14 14:09:35.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695775000 ms.0 from job set of time 1481695775000 ms
2016-12-14 14:09:35.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695775000 ms.0 from job set of time 1481695775000 ms
2016-12-14 14:09:35.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695775000 ms.1 from job set of time 1481695775000 ms
2016-12-14 14:09:35.016 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 798 (union at DStream.scala:617)
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 89 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 178 (take at LogStream.java:127)
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 177)
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 177)
2016-12-14 14:09:35.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 177 (UnionRDD[798] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:35.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_177 stored as values in memory (estimated size 4.2 KB, free 181.0 KB)
2016-12-14 14:09:35.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_177_piece0 stored as bytes in memory (estimated size 2.4 KB, free 183.5 KB)
2016-12-14 14:09:35.019 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_177_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:35.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 177 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:35.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 177 (UnionRDD[798] at union at DStream.scala:617)
2016-12-14 14:09:35.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 177.0 with 1 tasks
2016-12-14 14:09:35.021 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 177.0 (TID 177, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:35.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 177.0 (TID 177)
2016-12-14 14:09:35.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 177.0 (TID 177). 1159 bytes result sent to driver
2016-12-14 14:09:35.026 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 177.0 (TID 177) in 5 ms on localhost (1/1)
2016-12-14 14:09:35.026 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 177.0, whose tasks have all completed, from pool 
2016-12-14 14:09:35.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 177 (union at DStream.scala:617) finished in 0.006 s
2016-12-14 14:09:35.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:35.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:35.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 178)
2016-12-14 14:09:35.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:35.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 178 (MapPartitionsRDD[801] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:35.028 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_178 stored as values in memory (estimated size 3.7 KB, free 187.2 KB)
2016-12-14 14:09:35.030 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_178_piece0 stored as bytes in memory (estimated size 2.1 KB, free 189.3 KB)
2016-12-14 14:09:35.030 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_178_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:35.031 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 178 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:35.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[801] at count at LogStream.java:120)
2016-12-14 14:09:35.031 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 178.0 with 1 tasks
2016-12-14 14:09:35.032 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 178.0 (TID 178, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:35.032 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 178.0 (TID 178)
2016-12-14 14:09:35.037 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:35.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:35.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 178.0 (TID 178). 1241 bytes result sent to driver
2016-12-14 14:09:35.039 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 178.0 (TID 178) in 7 ms on localhost (1/1)
2016-12-14 14:09:35.039 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2016-12-14 14:09:35.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 178 (take at LogStream.java:127) finished in 0.008 s
2016-12-14 14:09:35.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 89 finished: take at LogStream.java:127, took 0.023967 s
2016-12-14 14:09:35.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695775000 ms.1 from job set of time 1481695775000 ms
2016-12-14 14:09:35.046 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.045 s for time 1481695775000 ms (execution: 0.033 s)
2016-12-14 14:09:35.046 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 784 from persistence list
2016-12-14 14:09:35.046 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 784
2016-12-14 14:09:35.046 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[784] at createStream at LogStream.java:100 of time 1481695775000 ms
2016-12-14 14:09:35.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 792 from persistence list
2016-12-14 14:09:35.046 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 792
2016-12-14 14:09:35.046 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 791 from persistence list
2016-12-14 14:09:35.046 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 791
2016-12-14 14:09:35.046 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 790 from persistence list
2016-12-14 14:09:35.046 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 790
2016-12-14 14:09:35.046 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 789 from persistence list
2016-12-14 14:09:35.047 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 789
2016-12-14 14:09:35.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 787 from persistence list
2016-12-14 14:09:35.047 [block-manager-slave-async-thread-pool-1] INFO  o.apache.spark.storage.BlockManager - Removing RDD 787
2016-12-14 14:09:35.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 786 from persistence list
2016-12-14 14:09:35.047 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 786
2016-12-14 14:09:35.047 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 785 from persistence list
2016-12-14 14:09:35.047 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 785
2016-12-14 14:09:35.047 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695773000 ms)
2016-12-14 14:09:35.047 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695773000 ms
2016-12-14 14:09:36.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695776000 ms
2016-12-14 14:09:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695776000 ms.0 from job set of time 1481695776000 ms
2016-12-14 14:09:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695776000 ms.0 from job set of time 1481695776000 ms
2016-12-14 14:09:36.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695776000 ms.1 from job set of time 1481695776000 ms
2016-12-14 14:09:36.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 807 (union at DStream.scala:617)
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 90 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 180 (take at LogStream.java:127)
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 179)
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 179)
2016-12-14 14:09:36.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 179 (UnionRDD[807] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:36.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_179 stored as values in memory (estimated size 4.2 KB, free 193.5 KB)
2016-12-14 14:09:36.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_179_piece0 stored as bytes in memory (estimated size 2.4 KB, free 195.9 KB)
2016-12-14 14:09:36.016 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_179_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:36.016 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 179 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:36.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 179 (UnionRDD[807] at union at DStream.scala:617)
2016-12-14 14:09:36.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 179.0 with 1 tasks
2016-12-14 14:09:36.017 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 179.0 (TID 179, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:36.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 179.0 (TID 179)
2016-12-14 14:09:36.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 179.0 (TID 179). 1159 bytes result sent to driver
2016-12-14 14:09:36.020 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 179.0 (TID 179) in 3 ms on localhost (1/1)
2016-12-14 14:09:36.020 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 179.0, whose tasks have all completed, from pool 
2016-12-14 14:09:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 179 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 180)
2016-12-14 14:09:36.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:36.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 180 (MapPartitionsRDD[810] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:36.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_180 stored as values in memory (estimated size 3.7 KB, free 199.6 KB)
2016-12-14 14:09:36.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_180_piece0 stored as bytes in memory (estimated size 2.1 KB, free 201.7 KB)
2016-12-14 14:09:36.023 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_180_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:36.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 180 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:36.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[810] at count at LogStream.java:120)
2016-12-14 14:09:36.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 180.0 with 1 tasks
2016-12-14 14:09:36.024 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 180.0 (TID 180, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:36.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 180.0 (TID 180)
2016-12-14 14:09:36.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:36.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:36.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 180.0 (TID 180). 1241 bytes result sent to driver
2016-12-14 14:09:36.026 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 180.0 (TID 180) in 3 ms on localhost (1/1)
2016-12-14 14:09:36.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 180 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:36.026 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2016-12-14 14:09:36.026 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 90 finished: take at LogStream.java:127, took 0.013208 s
2016-12-14 14:09:36.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695776000 ms.1 from job set of time 1481695776000 ms
2016-12-14 14:09:36.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.031 s for time 1481695776000 ms (execution: 0.021 s)
2016-12-14 14:09:36.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 793 from persistence list
2016-12-14 14:09:36.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 793
2016-12-14 14:09:36.032 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[793] at createStream at LogStream.java:100 of time 1481695776000 ms
2016-12-14 14:09:36.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 801 from persistence list
2016-12-14 14:09:36.032 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 801
2016-12-14 14:09:36.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 800 from persistence list
2016-12-14 14:09:36.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 800
2016-12-14 14:09:36.032 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 799 from persistence list
2016-12-14 14:09:36.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 799
2016-12-14 14:09:36.032 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 798 from persistence list
2016-12-14 14:09:36.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 798
2016-12-14 14:09:36.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 796 from persistence list
2016-12-14 14:09:36.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 796
2016-12-14 14:09:36.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 795 from persistence list
2016-12-14 14:09:36.033 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 795
2016-12-14 14:09:36.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 794 from persistence list
2016-12-14 14:09:36.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 794
2016-12-14 14:09:36.033 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695774000 ms)
2016-12-14 14:09:36.033 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695774000 ms
2016-12-14 14:09:37.012 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695777000 ms
2016-12-14 14:09:37.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695777000 ms.0 from job set of time 1481695777000 ms
2016-12-14 14:09:37.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695777000 ms.0 from job set of time 1481695777000 ms
2016-12-14 14:09:37.013 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695777000 ms.1 from job set of time 1481695777000 ms
2016-12-14 14:09:37.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 816 (union at DStream.scala:617)
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 91 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 182 (take at LogStream.java:127)
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 181)
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 181)
2016-12-14 14:09:37.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 181 (UnionRDD[816] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:37.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_181 stored as values in memory (estimated size 4.2 KB, free 205.9 KB)
2016-12-14 14:09:37.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_181_piece0 stored as bytes in memory (estimated size 2.4 KB, free 208.4 KB)
2016-12-14 14:09:37.020 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_181_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:37.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 181 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:37.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 181 (UnionRDD[816] at union at DStream.scala:617)
2016-12-14 14:09:37.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 181.0 with 1 tasks
2016-12-14 14:09:37.021 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 181.0 (TID 181, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:37.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 181.0 (TID 181)
2016-12-14 14:09:37.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 181.0 (TID 181). 1159 bytes result sent to driver
2016-12-14 14:09:37.024 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 181.0 (TID 181) in 3 ms on localhost (1/1)
2016-12-14 14:09:37.024 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 181.0, whose tasks have all completed, from pool 
2016-12-14 14:09:37.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 181 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 182)
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 182 (MapPartitionsRDD[819] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:37.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_182 stored as values in memory (estimated size 3.7 KB, free 212.1 KB)
2016-12-14 14:09:37.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_182_piece0 stored as bytes in memory (estimated size 2.1 KB, free 214.2 KB)
2016-12-14 14:09:37.027 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_182_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:37.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 182 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:37.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[819] at count at LogStream.java:120)
2016-12-14 14:09:37.027 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 182.0 with 1 tasks
2016-12-14 14:09:37.028 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 182.0 (TID 182, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:37.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 182.0 (TID 182)
2016-12-14 14:09:37.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:37.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:37.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 182.0 (TID 182). 1241 bytes result sent to driver
2016-12-14 14:09:37.031 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 182.0 (TID 182) in 2 ms on localhost (1/1)
2016-12-14 14:09:37.031 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2016-12-14 14:09:37.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 182 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:37.031 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 91 finished: take at LogStream.java:127, took 0.015690 s
2016-12-14 14:09:37.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695777000 ms.1 from job set of time 1481695777000 ms
2016-12-14 14:09:37.037 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.037 s for time 1481695777000 ms (execution: 0.025 s)
2016-12-14 14:09:37.038 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 802 from persistence list
2016-12-14 14:09:37.038 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 802
2016-12-14 14:09:37.038 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[802] at createStream at LogStream.java:100 of time 1481695777000 ms
2016-12-14 14:09:37.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 810 from persistence list
2016-12-14 14:09:37.038 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 810
2016-12-14 14:09:37.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 809 from persistence list
2016-12-14 14:09:37.038 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 809
2016-12-14 14:09:37.038 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 808 from persistence list
2016-12-14 14:09:37.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 808
2016-12-14 14:09:37.038 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 807 from persistence list
2016-12-14 14:09:37.038 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 807
2016-12-14 14:09:37.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 805 from persistence list
2016-12-14 14:09:37.039 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 805
2016-12-14 14:09:37.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 804 from persistence list
2016-12-14 14:09:37.039 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 804
2016-12-14 14:09:37.039 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 803 from persistence list
2016-12-14 14:09:37.039 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 803
2016-12-14 14:09:37.039 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695775000 ms)
2016-12-14 14:09:37.039 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695775000 ms
2016-12-14 14:09:38.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695778000 ms
2016-12-14 14:09:38.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695778000 ms.0 from job set of time 1481695778000 ms
2016-12-14 14:09:38.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695778000 ms.0 from job set of time 1481695778000 ms
2016-12-14 14:09:38.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695778000 ms.1 from job set of time 1481695778000 ms
2016-12-14 14:09:38.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:38.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 825 (union at DStream.scala:617)
2016-12-14 14:09:38.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 92 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:38.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 184 (take at LogStream.java:127)
2016-12-14 14:09:38.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 183)
2016-12-14 14:09:38.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 183)
2016-12-14 14:09:38.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 183 (UnionRDD[825] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:38.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_183 stored as values in memory (estimated size 4.2 KB, free 218.4 KB)
2016-12-14 14:09:38.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_183_piece0 stored as bytes in memory (estimated size 2.4 KB, free 220.8 KB)
2016-12-14 14:09:38.019 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_183_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:38.020 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 183 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:38.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 183 (UnionRDD[825] at union at DStream.scala:617)
2016-12-14 14:09:38.020 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 183.0 with 1 tasks
2016-12-14 14:09:38.021 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 183.0 (TID 183, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:38.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 183.0 (TID 183)
2016-12-14 14:09:38.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 183.0 (TID 183). 1159 bytes result sent to driver
2016-12-14 14:09:38.025 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 183.0 (TID 183) in 4 ms on localhost (1/1)
2016-12-14 14:09:38.025 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 183.0, whose tasks have all completed, from pool 
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 183 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 184)
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:38.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 184 (MapPartitionsRDD[828] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:38.026 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_184 stored as values in memory (estimated size 3.7 KB, free 224.5 KB)
2016-12-14 14:09:38.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_184_piece0 stored as bytes in memory (estimated size 2.1 KB, free 226.6 KB)
2016-12-14 14:09:38.027 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_184_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:38.028 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 184 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:38.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[828] at count at LogStream.java:120)
2016-12-14 14:09:38.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 184.0 with 1 tasks
2016-12-14 14:09:38.028 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 184.0 (TID 184, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:38.029 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 184.0 (TID 184)
2016-12-14 14:09:38.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:38.030 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:38.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 184.0 (TID 184). 1241 bytes result sent to driver
2016-12-14 14:09:38.031 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 184.0 (TID 184) in 3 ms on localhost (1/1)
2016-12-14 14:09:38.031 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 184 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:38.031 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2016-12-14 14:09:38.031 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 92 finished: take at LogStream.java:127, took 0.016115 s
2016-12-14 14:09:38.036 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695778000 ms.1 from job set of time 1481695778000 ms
2016-12-14 14:09:38.036 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.036 s for time 1481695778000 ms (execution: 0.025 s)
2016-12-14 14:09:38.036 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 811 from persistence list
2016-12-14 14:09:38.036 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 811
2016-12-14 14:09:38.036 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[811] at createStream at LogStream.java:100 of time 1481695778000 ms
2016-12-14 14:09:38.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 819 from persistence list
2016-12-14 14:09:38.036 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 819
2016-12-14 14:09:38.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 818 from persistence list
2016-12-14 14:09:38.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 818
2016-12-14 14:09:38.037 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 817 from persistence list
2016-12-14 14:09:38.037 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 817
2016-12-14 14:09:38.037 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 816 from persistence list
2016-12-14 14:09:38.038 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 816
2016-12-14 14:09:38.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 814 from persistence list
2016-12-14 14:09:38.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 814
2016-12-14 14:09:38.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 813 from persistence list
2016-12-14 14:09:38.038 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 813
2016-12-14 14:09:38.038 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 812 from persistence list
2016-12-14 14:09:38.038 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 812
2016-12-14 14:09:38.038 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695776000 ms)
2016-12-14 14:09:38.038 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695776000 ms
2016-12-14 14:09:39.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695779000 ms
2016-12-14 14:09:39.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695779000 ms.0 from job set of time 1481695779000 ms
2016-12-14 14:09:39.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695779000 ms.0 from job set of time 1481695779000 ms
2016-12-14 14:09:39.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695779000 ms.1 from job set of time 1481695779000 ms
2016-12-14 14:09:39.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:39.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 834 (union at DStream.scala:617)
2016-12-14 14:09:39.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 93 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:39.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 186 (take at LogStream.java:127)
2016-12-14 14:09:39.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 185)
2016-12-14 14:09:39.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 185)
2016-12-14 14:09:39.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 185 (UnionRDD[834] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:39.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_185 stored as values in memory (estimated size 4.2 KB, free 230.8 KB)
2016-12-14 14:09:39.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_185_piece0 stored as bytes in memory (estimated size 2.4 KB, free 233.3 KB)
2016-12-14 14:09:39.016 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_185_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:39.016 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 185 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:39.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 185 (UnionRDD[834] at union at DStream.scala:617)
2016-12-14 14:09:39.016 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 185.0 with 1 tasks
2016-12-14 14:09:39.017 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 185.0 (TID 185, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:39.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 185.0 (TID 185)
2016-12-14 14:09:39.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 185.0 (TID 185). 1159 bytes result sent to driver
2016-12-14 14:09:39.020 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 185.0 (TID 185) in 3 ms on localhost (1/1)
2016-12-14 14:09:39.020 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 185.0, whose tasks have all completed, from pool 
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 185 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 186)
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:39.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 186 (MapPartitionsRDD[837] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:39.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_186 stored as values in memory (estimated size 3.7 KB, free 237.0 KB)
2016-12-14 14:09:39.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_186_piece0 stored as bytes in memory (estimated size 2.1 KB, free 239.1 KB)
2016-12-14 14:09:39.023 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_186_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:39.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 186 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:39.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[837] at count at LogStream.java:120)
2016-12-14 14:09:39.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 186.0 with 1 tasks
2016-12-14 14:09:39.024 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 186.0 (TID 186, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:39.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 186.0 (TID 186)
2016-12-14 14:09:39.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:39.025 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:39.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 186.0 (TID 186). 1241 bytes result sent to driver
2016-12-14 14:09:39.027 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 186.0 (TID 186) in 4 ms on localhost (1/1)
2016-12-14 14:09:39.027 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2016-12-14 14:09:39.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 186 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:39.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 93 finished: take at LogStream.java:127, took 0.014962 s
2016-12-14 14:09:39.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695779000 ms.1 from job set of time 1481695779000 ms
2016-12-14 14:09:39.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.032 s for time 1481695779000 ms (execution: 0.023 s)
2016-12-14 14:09:39.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 820 from persistence list
2016-12-14 14:09:39.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 820
2016-12-14 14:09:39.032 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[820] at createStream at LogStream.java:100 of time 1481695779000 ms
2016-12-14 14:09:39.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 828 from persistence list
2016-12-14 14:09:39.032 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 828
2016-12-14 14:09:39.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 827 from persistence list
2016-12-14 14:09:39.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 827
2016-12-14 14:09:39.032 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 826 from persistence list
2016-12-14 14:09:39.032 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 826
2016-12-14 14:09:39.033 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 825 from persistence list
2016-12-14 14:09:39.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 825
2016-12-14 14:09:39.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 823 from persistence list
2016-12-14 14:09:39.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 823
2016-12-14 14:09:39.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 822 from persistence list
2016-12-14 14:09:39.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 822
2016-12-14 14:09:39.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 821 from persistence list
2016-12-14 14:09:39.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 821
2016-12-14 14:09:39.033 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695777000 ms)
2016-12-14 14:09:39.033 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695777000 ms
2016-12-14 14:09:40.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695780000 ms
2016-12-14 14:09:40.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695780000 ms.0 from job set of time 1481695780000 ms
2016-12-14 14:09:40.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695780000 ms.0 from job set of time 1481695780000 ms
2016-12-14 14:09:40.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695780000 ms.1 from job set of time 1481695780000 ms
2016-12-14 14:09:40.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:40.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 843 (union at DStream.scala:617)
2016-12-14 14:09:40.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 94 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:40.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 188 (take at LogStream.java:127)
2016-12-14 14:09:40.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 187)
2016-12-14 14:09:40.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 187)
2016-12-14 14:09:40.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 187 (UnionRDD[843] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:40.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_187 stored as values in memory (estimated size 4.2 KB, free 243.3 KB)
2016-12-14 14:09:40.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_187_piece0 stored as bytes in memory (estimated size 2.4 KB, free 245.7 KB)
2016-12-14 14:09:40.017 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_187_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:40.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 187 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:40.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 187 (UnionRDD[843] at union at DStream.scala:617)
2016-12-14 14:09:40.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 187.0 with 1 tasks
2016-12-14 14:09:40.018 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 187.0 (TID 187, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:40.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 187.0 (TID 187)
2016-12-14 14:09:40.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 187.0 (TID 187). 1159 bytes result sent to driver
2016-12-14 14:09:40.021 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 187.0 (TID 187) in 3 ms on localhost (1/1)
2016-12-14 14:09:40.021 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 187.0, whose tasks have all completed, from pool 
2016-12-14 14:09:40.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 187 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 188)
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 188 (MapPartitionsRDD[846] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:40.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_188 stored as values in memory (estimated size 3.7 KB, free 249.4 KB)
2016-12-14 14:09:40.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_188_piece0 stored as bytes in memory (estimated size 2.1 KB, free 251.5 KB)
2016-12-14 14:09:40.024 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_188_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:40.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 188 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:40.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[846] at count at LogStream.java:120)
2016-12-14 14:09:40.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 188.0 with 1 tasks
2016-12-14 14:09:40.025 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 188.0 (TID 188, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:40.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 188.0 (TID 188)
2016-12-14 14:09:40.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:40.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:40.026 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 188.0 (TID 188). 1241 bytes result sent to driver
2016-12-14 14:09:40.027 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 188.0 (TID 188) in 3 ms on localhost (1/1)
2016-12-14 14:09:40.027 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2016-12-14 14:09:40.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 188 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:40.027 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 94 finished: take at LogStream.java:127, took 0.014818 s
2016-12-14 14:09:40.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695780000 ms.1 from job set of time 1481695780000 ms
2016-12-14 14:09:40.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.032 s for time 1481695780000 ms (execution: 0.023 s)
2016-12-14 14:09:40.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 829 from persistence list
2016-12-14 14:09:40.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 829
2016-12-14 14:09:40.033 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[829] at createStream at LogStream.java:100 of time 1481695780000 ms
2016-12-14 14:09:40.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 837 from persistence list
2016-12-14 14:09:40.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 837
2016-12-14 14:09:40.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 836 from persistence list
2016-12-14 14:09:40.033 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 835 from persistence list
2016-12-14 14:09:40.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 836
2016-12-14 14:09:40.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 835
2016-12-14 14:09:40.033 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 834 from persistence list
2016-12-14 14:09:40.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 834
2016-12-14 14:09:40.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 832 from persistence list
2016-12-14 14:09:40.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 832
2016-12-14 14:09:40.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 831 from persistence list
2016-12-14 14:09:40.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 831
2016-12-14 14:09:40.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 830 from persistence list
2016-12-14 14:09:40.034 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 830
2016-12-14 14:09:40.034 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695778000 ms)
2016-12-14 14:09:40.034 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695778000 ms
2016-12-14 14:09:41.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695781000 ms
2016-12-14 14:09:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695781000 ms.0 from job set of time 1481695781000 ms
2016-12-14 14:09:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695781000 ms.0 from job set of time 1481695781000 ms
2016-12-14 14:09:41.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695781000 ms.1 from job set of time 1481695781000 ms
2016-12-14 14:09:41.013 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 852 (union at DStream.scala:617)
2016-12-14 14:09:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 95 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 190 (take at LogStream.java:127)
2016-12-14 14:09:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 189)
2016-12-14 14:09:41.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 189)
2016-12-14 14:09:41.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 189 (UnionRDD[852] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:41.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_189 stored as values in memory (estimated size 4.2 KB, free 255.7 KB)
2016-12-14 14:09:41.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_189_piece0 stored as bytes in memory (estimated size 2.4 KB, free 258.2 KB)
2016-12-14 14:09:41.017 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_189_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:41.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 189 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:41.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 189 (UnionRDD[852] at union at DStream.scala:617)
2016-12-14 14:09:41.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 189.0 with 1 tasks
2016-12-14 14:09:41.018 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 189.0 (TID 189, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:41.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 189.0 (TID 189)
2016-12-14 14:09:41.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 189.0 (TID 189). 1159 bytes result sent to driver
2016-12-14 14:09:41.022 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 189.0 (TID 189) in 4 ms on localhost (1/1)
2016-12-14 14:09:41.022 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 189.0, whose tasks have all completed, from pool 
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 189 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 190)
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:41.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 190 (MapPartitionsRDD[855] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:41.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_190 stored as values in memory (estimated size 3.7 KB, free 261.9 KB)
2016-12-14 14:09:41.024 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_190_piece0 stored as bytes in memory (estimated size 2.1 KB, free 264.0 KB)
2016-12-14 14:09:41.024 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_190_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:41.024 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 190 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:41.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[855] at count at LogStream.java:120)
2016-12-14 14:09:41.024 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 190.0 with 1 tasks
2016-12-14 14:09:41.025 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 190.0 (TID 190, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:41.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 190.0 (TID 190)
2016-12-14 14:09:41.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:41.026 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:41.027 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 190.0 (TID 190). 1241 bytes result sent to driver
2016-12-14 14:09:41.027 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 190.0 (TID 190) in 2 ms on localhost (1/1)
2016-12-14 14:09:41.027 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2016-12-14 14:09:41.027 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 190 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:41.028 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 95 finished: take at LogStream.java:127, took 0.014216 s
2016-12-14 14:09:41.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695781000 ms.1 from job set of time 1481695781000 ms
2016-12-14 14:09:41.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 838 from persistence list
2016-12-14 14:09:41.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.032 s for time 1481695781000 ms (execution: 0.022 s)
2016-12-14 14:09:41.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 838
2016-12-14 14:09:41.032 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[838] at createStream at LogStream.java:100 of time 1481695781000 ms
2016-12-14 14:09:41.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 846 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 846
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 845 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 845
2016-12-14 14:09:41.033 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 844 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 844
2016-12-14 14:09:41.033 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 843 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 843
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 841 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 841
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 840 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 840
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 839 from persistence list
2016-12-14 14:09:41.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 839
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695779000 ms)
2016-12-14 14:09:41.033 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695779000 ms
2016-12-14 14:09:42.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695782000 ms
2016-12-14 14:09:42.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695782000 ms.0 from job set of time 1481695782000 ms
2016-12-14 14:09:42.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695782000 ms.0 from job set of time 1481695782000 ms
2016-12-14 14:09:42.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695782000 ms.1 from job set of time 1481695782000 ms
2016-12-14 14:09:42.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:42.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 861 (union at DStream.scala:617)
2016-12-14 14:09:42.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 96 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:42.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 192 (take at LogStream.java:127)
2016-12-14 14:09:42.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 191)
2016-12-14 14:09:42.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 191)
2016-12-14 14:09:42.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 191 (UnionRDD[861] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:42.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_191 stored as values in memory (estimated size 4.2 KB, free 268.2 KB)
2016-12-14 14:09:42.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_191_piece0 stored as bytes in memory (estimated size 2.4 KB, free 270.6 KB)
2016-12-14 14:09:42.016 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_191_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:42.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 191 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:42.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 191 (UnionRDD[861] at union at DStream.scala:617)
2016-12-14 14:09:42.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 191.0 with 1 tasks
2016-12-14 14:09:42.018 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 191.0 (TID 191, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:42.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 191.0 (TID 191)
2016-12-14 14:09:42.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 191.0 (TID 191). 1159 bytes result sent to driver
2016-12-14 14:09:42.026 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 191.0 (TID 191) in 9 ms on localhost (1/1)
2016-12-14 14:09:42.026 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 191.0, whose tasks have all completed, from pool 
2016-12-14 14:09:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 191 (union at DStream.scala:617) finished in 0.011 s
2016-12-14 14:09:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 192)
2016-12-14 14:09:42.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:42.029 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 192 (MapPartitionsRDD[864] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:42.032 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_192 stored as values in memory (estimated size 3.7 KB, free 274.3 KB)
2016-12-14 14:09:42.034 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_192_piece0 stored as bytes in memory (estimated size 2.1 KB, free 276.4 KB)
2016-12-14 14:09:42.035 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_192_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:42.035 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 192 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:42.035 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[864] at count at LogStream.java:120)
2016-12-14 14:09:42.035 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 192.0 with 1 tasks
2016-12-14 14:09:42.036 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 192.0 (TID 192, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:42.036 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 192.0 (TID 192)
2016-12-14 14:09:42.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:42.038 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:42.038 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 192.0 (TID 192). 1241 bytes result sent to driver
2016-12-14 14:09:42.039 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 192.0 (TID 192) in 3 ms on localhost (1/1)
2016-12-14 14:09:42.039 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2016-12-14 14:09:42.039 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 192 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:42.040 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 96 finished: take at LogStream.java:127, took 0.027963 s
2016-12-14 14:09:42.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695782000 ms.1 from job set of time 1481695782000 ms
2016-12-14 14:09:42.049 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.049 s for time 1481695782000 ms (execution: 0.040 s)
2016-12-14 14:09:42.049 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 847 from persistence list
2016-12-14 14:09:42.051 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[847] at createStream at LogStream.java:100 of time 1481695782000 ms
2016-12-14 14:09:42.051 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 847
2016-12-14 14:09:42.051 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 855 from persistence list
2016-12-14 14:09:42.052 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 854 from persistence list
2016-12-14 14:09:42.052 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 855
2016-12-14 14:09:42.052 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 853 from persistence list
2016-12-14 14:09:42.052 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 854
2016-12-14 14:09:42.053 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 852 from persistence list
2016-12-14 14:09:42.053 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 853
2016-12-14 14:09:42.053 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 852
2016-12-14 14:09:42.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 850 from persistence list
2016-12-14 14:09:42.053 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 850
2016-12-14 14:09:42.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 849 from persistence list
2016-12-14 14:09:42.053 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 849
2016-12-14 14:09:42.053 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 848 from persistence list
2016-12-14 14:09:42.054 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695780000 ms)
2016-12-14 14:09:42.054 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695780000 ms
2016-12-14 14:09:42.054 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 848
2016-12-14 14:09:43.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695783000 ms
2016-12-14 14:09:43.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695783000 ms.0 from job set of time 1481695783000 ms
2016-12-14 14:09:43.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:43.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695783000 ms.0 from job set of time 1481695783000 ms
2016-12-14 14:09:43.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695783000 ms.1 from job set of time 1481695783000 ms
2016-12-14 14:09:43.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 870 (union at DStream.scala:617)
2016-12-14 14:09:43.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 97 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:43.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 194 (take at LogStream.java:127)
2016-12-14 14:09:43.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 193)
2016-12-14 14:09:43.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 193)
2016-12-14 14:09:43.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 193 (UnionRDD[870] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:43.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_193 stored as values in memory (estimated size 4.2 KB, free 280.7 KB)
2016-12-14 14:09:43.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_193_piece0 stored as bytes in memory (estimated size 2.4 KB, free 283.1 KB)
2016-12-14 14:09:43.014 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_193_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:43.014 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 193 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:43.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 193 (UnionRDD[870] at union at DStream.scala:617)
2016-12-14 14:09:43.015 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 193.0 with 1 tasks
2016-12-14 14:09:43.015 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 193.0 (TID 193, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:43.015 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 193.0 (TID 193)
2016-12-14 14:09:43.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 193.0 (TID 193). 1159 bytes result sent to driver
2016-12-14 14:09:43.018 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 193.0 (TID 193) in 3 ms on localhost (1/1)
2016-12-14 14:09:43.018 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 193.0, whose tasks have all completed, from pool 
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 193 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 194)
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:43.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 194 (MapPartitionsRDD[873] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:43.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_194 stored as values in memory (estimated size 3.7 KB, free 286.8 KB)
2016-12-14 14:09:43.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_194_piece0 stored as bytes in memory (estimated size 2.1 KB, free 288.9 KB)
2016-12-14 14:09:43.021 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_194_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:43.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 194 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:43.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 194 (MapPartitionsRDD[873] at count at LogStream.java:120)
2016-12-14 14:09:43.022 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 194.0 with 1 tasks
2016-12-14 14:09:43.022 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 194.0 (TID 194, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:43.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 194.0 (TID 194)
2016-12-14 14:09:43.023 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:43.023 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:43.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 194.0 (TID 194). 1241 bytes result sent to driver
2016-12-14 14:09:43.024 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 194.0 (TID 194) in 2 ms on localhost (1/1)
2016-12-14 14:09:43.024 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2016-12-14 14:09:43.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 194 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:43.024 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 97 finished: take at LogStream.java:127, took 0.013399 s
2016-12-14 14:09:43.029 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695783000 ms.1 from job set of time 1481695783000 ms
2016-12-14 14:09:43.029 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.029 s for time 1481695783000 ms (execution: 0.021 s)
2016-12-14 14:09:43.029 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 856 from persistence list
2016-12-14 14:09:43.029 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 856
2016-12-14 14:09:43.029 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[856] at createStream at LogStream.java:100 of time 1481695783000 ms
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 864 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 864
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 863 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 863
2016-12-14 14:09:43.030 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 862 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 862
2016-12-14 14:09:43.030 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 861 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 861
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 859 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 859
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 858 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 858
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 857 from persistence list
2016-12-14 14:09:43.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 857
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695781000 ms)
2016-12-14 14:09:43.030 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695781000 ms
2016-12-14 14:09:44.005 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695784000 ms
2016-12-14 14:09:44.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695784000 ms.0 from job set of time 1481695784000 ms
2016-12-14 14:09:44.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695784000 ms.0 from job set of time 1481695784000 ms
2016-12-14 14:09:44.005 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695784000 ms.1 from job set of time 1481695784000 ms
2016-12-14 14:09:44.007 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 879 (union at DStream.scala:617)
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 98 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 196 (take at LogStream.java:127)
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 195)
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 195)
2016-12-14 14:09:44.008 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 195 (UnionRDD[879] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:44.009 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_195 stored as values in memory (estimated size 4.2 KB, free 293.1 KB)
2016-12-14 14:09:44.010 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_195_piece0 stored as bytes in memory (estimated size 2.4 KB, free 295.5 KB)
2016-12-14 14:09:44.010 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_195_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:44.010 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 195 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:44.010 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 195 (UnionRDD[879] at union at DStream.scala:617)
2016-12-14 14:09:44.010 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 195.0 with 1 tasks
2016-12-14 14:09:44.011 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 195.0 (TID 195, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:44.011 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 195.0 (TID 195)
2016-12-14 14:09:44.013 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 195.0 (TID 195). 1159 bytes result sent to driver
2016-12-14 14:09:44.014 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 195.0 (TID 195) in 3 ms on localhost (1/1)
2016-12-14 14:09:44.014 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 195.0, whose tasks have all completed, from pool 
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 195 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 196)
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:44.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 196 (MapPartitionsRDD[882] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:44.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_196 stored as values in memory (estimated size 3.7 KB, free 299.2 KB)
2016-12-14 14:09:44.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_196_piece0 stored as bytes in memory (estimated size 2.1 KB, free 301.4 KB)
2016-12-14 14:09:44.016 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_196_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:44.016 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 196 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:44.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[882] at count at LogStream.java:120)
2016-12-14 14:09:44.016 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 196.0 with 1 tasks
2016-12-14 14:09:44.017 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 196.0 (TID 196, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:44.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 196.0 (TID 196)
2016-12-14 14:09:44.017 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:44.018 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2016-12-14 14:09:44.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 196.0 (TID 196). 1241 bytes result sent to driver
2016-12-14 14:09:44.019 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 196.0 (TID 196) in 2 ms on localhost (1/1)
2016-12-14 14:09:44.019 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2016-12-14 14:09:44.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 196 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:44.019 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 98 finished: take at LogStream.java:127, took 0.011893 s
2016-12-14 14:09:44.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695784000 ms.1 from job set of time 1481695784000 ms
2016-12-14 14:09:44.024 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.024 s for time 1481695784000 ms (execution: 0.019 s)
2016-12-14 14:09:44.024 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 865 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 865
2016-12-14 14:09:44.025 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[865] at createStream at LogStream.java:100 of time 1481695784000 ms
2016-12-14 14:09:44.025 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 873 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 873
2016-12-14 14:09:44.025 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 872 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 872
2016-12-14 14:09:44.025 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 871 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 871
2016-12-14 14:09:44.025 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 870 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 870
2016-12-14 14:09:44.025 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 868 from persistence list
2016-12-14 14:09:44.025 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 868
2016-12-14 14:09:44.025 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 867 from persistence list
2016-12-14 14:09:44.026 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 866 from persistence list
2016-12-14 14:09:44.026 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 867
2016-12-14 14:09:44.026 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 866
2016-12-14 14:09:44.026 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695782000 ms)
2016-12-14 14:09:44.026 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695782000 ms
2016-12-14 14:09:45.010 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695785000 ms
2016-12-14 14:09:45.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695785000 ms.0 from job set of time 1481695785000 ms
2016-12-14 14:09:45.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695785000 ms.0 from job set of time 1481695785000 ms
2016-12-14 14:09:45.010 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695785000 ms.1 from job set of time 1481695785000 ms
2016-12-14 14:09:45.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:45.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 888 (union at DStream.scala:617)
2016-12-14 14:09:45.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 99 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:45.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 198 (take at LogStream.java:127)
2016-12-14 14:09:45.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 197)
2016-12-14 14:09:45.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 197)
2016-12-14 14:09:45.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 197 (UnionRDD[888] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:45.015 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_197 stored as values in memory (estimated size 4.2 KB, free 305.6 KB)
2016-12-14 14:09:45.016 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_197_piece0 stored as bytes in memory (estimated size 2.4 KB, free 308.0 KB)
2016-12-14 14:09:45.017 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_197_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:45.017 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 197 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:45.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 197 (UnionRDD[888] at union at DStream.scala:617)
2016-12-14 14:09:45.017 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 197.0 with 1 tasks
2016-12-14 14:09:45.017 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 197.0 (TID 197, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:45.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 197.0 (TID 197)
2016-12-14 14:09:45.019 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 197.0 (TID 197). 1159 bytes result sent to driver
2016-12-14 14:09:45.020 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 197.0 (TID 197) in 3 ms on localhost (1/1)
2016-12-14 14:09:45.020 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 197.0, whose tasks have all completed, from pool 
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 197 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 198)
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:45.020 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 198 (MapPartitionsRDD[891] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:45.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_198 stored as values in memory (estimated size 3.7 KB, free 311.7 KB)
2016-12-14 14:09:45.021 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_198_piece0 stored as bytes in memory (estimated size 2.1 KB, free 313.8 KB)
2016-12-14 14:09:45.022 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_198_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:45.022 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 198 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:45.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[891] at count at LogStream.java:120)
2016-12-14 14:09:45.022 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 198.0 with 1 tasks
2016-12-14 14:09:45.023 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 198.0 (TID 198, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:45.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 198.0 (TID 198)
2016-12-14 14:09:45.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:45.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:45.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 198.0 (TID 198). 1241 bytes result sent to driver
2016-12-14 14:09:45.026 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 198.0 (TID 198) in 4 ms on localhost (1/1)
2016-12-14 14:09:45.026 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 198 (take at LogStream.java:127) finished in 0.004 s
2016-12-14 14:09:45.026 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2016-12-14 14:09:45.026 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 99 finished: take at LogStream.java:127, took 0.013832 s
2016-12-14 14:09:45.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695785000 ms.1 from job set of time 1481695785000 ms
2016-12-14 14:09:45.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.030 s for time 1481695785000 ms (execution: 0.020 s)
2016-12-14 14:09:45.031 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 874 from persistence list
2016-12-14 14:09:45.031 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 874
2016-12-14 14:09:45.031 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[874] at createStream at LogStream.java:100 of time 1481695785000 ms
2016-12-14 14:09:45.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 882 from persistence list
2016-12-14 14:09:45.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 882
2016-12-14 14:09:45.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 881 from persistence list
2016-12-14 14:09:45.031 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 881
2016-12-14 14:09:45.031 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 880 from persistence list
2016-12-14 14:09:45.031 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 880
2016-12-14 14:09:45.031 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 879 from persistence list
2016-12-14 14:09:45.031 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 879
2016-12-14 14:09:45.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 877 from persistence list
2016-12-14 14:09:45.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 877
2016-12-14 14:09:45.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 876 from persistence list
2016-12-14 14:09:45.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 876
2016-12-14 14:09:45.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 875 from persistence list
2016-12-14 14:09:45.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 875
2016-12-14 14:09:45.032 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695783000 ms)
2016-12-14 14:09:45.032 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695783000 ms
2016-12-14 14:09:46.009 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695786000 ms
2016-12-14 14:09:46.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695786000 ms.0 from job set of time 1481695786000 ms
2016-12-14 14:09:46.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695786000 ms.0 from job set of time 1481695786000 ms
2016-12-14 14:09:46.009 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695786000 ms.1 from job set of time 1481695786000 ms
2016-12-14 14:09:46.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 897 (union at DStream.scala:617)
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 100 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 200 (take at LogStream.java:127)
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 199)
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 199)
2016-12-14 14:09:46.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 199 (UnionRDD[897] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:46.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_199 stored as values in memory (estimated size 4.2 KB, free 318.0 KB)
2016-12-14 14:09:46.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_199_piece0 stored as bytes in memory (estimated size 2.4 KB, free 320.4 KB)
2016-12-14 14:09:46.014 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_199_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:46.014 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 199 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:46.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 199 (UnionRDD[897] at union at DStream.scala:617)
2016-12-14 14:09:46.014 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 199.0 with 1 tasks
2016-12-14 14:09:46.015 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 199.0 (TID 199, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:46.015 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 199.0 (TID 199)
2016-12-14 14:09:46.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 199.0 (TID 199). 1159 bytes result sent to driver
2016-12-14 14:09:46.019 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 199.0 (TID 199) in 4 ms on localhost (1/1)
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 199 (union at DStream.scala:617) finished in 0.005 s
2016-12-14 14:09:46.019 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 199.0, whose tasks have all completed, from pool 
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 200)
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 200 (MapPartitionsRDD[900] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:46.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_200 stored as values in memory (estimated size 3.7 KB, free 324.1 KB)
2016-12-14 14:09:46.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_200_piece0 stored as bytes in memory (estimated size 2.1 KB, free 326.3 KB)
2016-12-14 14:09:46.020 [dispatcher-event-loop-2] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_200_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:46.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 200 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:46.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[900] at count at LogStream.java:120)
2016-12-14 14:09:46.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 200.0 with 1 tasks
2016-12-14 14:09:46.021 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 200.0 (TID 200, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:46.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 200.0 (TID 200)
2016-12-14 14:09:46.022 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:46.022 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:46.022 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 200.0 (TID 200). 1241 bytes result sent to driver
2016-12-14 14:09:46.023 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 200.0 (TID 200) in 2 ms on localhost (1/1)
2016-12-14 14:09:46.023 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2016-12-14 14:09:46.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 200 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:46.023 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 100 finished: take at LogStream.java:127, took 0.011662 s
2016-12-14 14:09:46.028 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695786000 ms.1 from job set of time 1481695786000 ms
2016-12-14 14:09:46.028 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.028 s for time 1481695786000 ms (execution: 0.019 s)
2016-12-14 14:09:46.028 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 883 from persistence list
2016-12-14 14:09:46.028 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 883
2016-12-14 14:09:46.029 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[883] at createStream at LogStream.java:100 of time 1481695786000 ms
2016-12-14 14:09:46.029 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 891 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 891
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 890 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 890
2016-12-14 14:09:46.030 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 889 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 889
2016-12-14 14:09:46.030 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 888 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 888
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 886 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 886
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 885 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 885
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 884 from persistence list
2016-12-14 14:09:46.030 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 884
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695784000 ms)
2016-12-14 14:09:46.030 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695784000 ms
2016-12-14 14:09:47.007 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695787000 ms
2016-12-14 14:09:47.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695787000 ms.0 from job set of time 1481695787000 ms
2016-12-14 14:09:47.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695787000 ms.0 from job set of time 1481695787000 ms
2016-12-14 14:09:47.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695787000 ms.1 from job set of time 1481695787000 ms
2016-12-14 14:09:47.010 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 906 (union at DStream.scala:617)
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 101 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 202 (take at LogStream.java:127)
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 201)
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 201)
2016-12-14 14:09:47.011 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 201 (UnionRDD[906] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:47.012 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_201 stored as values in memory (estimated size 4.2 KB, free 330.5 KB)
2016-12-14 14:09:47.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_201_piece0 stored as bytes in memory (estimated size 2.4 KB, free 332.9 KB)
2016-12-14 14:09:47.013 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_201_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:47.013 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 201 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:47.014 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 201 (UnionRDD[906] at union at DStream.scala:617)
2016-12-14 14:09:47.014 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 201.0 with 1 tasks
2016-12-14 14:09:47.014 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 201.0 (TID 201, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:47.014 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 201.0 (TID 201)
2016-12-14 14:09:47.016 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 201.0 (TID 201). 1159 bytes result sent to driver
2016-12-14 14:09:47.017 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 201.0 (TID 201) in 3 ms on localhost (1/1)
2016-12-14 14:09:47.017 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 201.0, whose tasks have all completed, from pool 
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 201 (union at DStream.scala:617) finished in 0.003 s
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 202)
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:47.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 202 (MapPartitionsRDD[909] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:47.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_202 stored as values in memory (estimated size 3.7 KB, free 336.6 KB)
2016-12-14 14:09:47.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_202_piece0 stored as bytes in memory (estimated size 2.1 KB, free 338.7 KB)
2016-12-14 14:09:47.019 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_202_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:47.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 202 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:47.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[909] at count at LogStream.java:120)
2016-12-14 14:09:47.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 202.0 with 1 tasks
2016-12-14 14:09:47.020 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 202.0 (TID 202, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:47.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 202.0 (TID 202)
2016-12-14 14:09:47.021 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:47.021 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:47.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 202.0 (TID 202). 1241 bytes result sent to driver
2016-12-14 14:09:47.022 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 202.0 (TID 202) in 2 ms on localhost (1/1)
2016-12-14 14:09:47.022 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 202 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:47.022 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2016-12-14 14:09:47.022 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 101 finished: take at LogStream.java:127, took 0.011614 s
2016-12-14 14:09:47.027 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695787000 ms.1 from job set of time 1481695787000 ms
2016-12-14 14:09:47.027 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.027 s for time 1481695787000 ms (execution: 0.020 s)
2016-12-14 14:09:47.027 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 892 from persistence list
2016-12-14 14:09:47.027 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 892
2016-12-14 14:09:47.027 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[892] at createStream at LogStream.java:100 of time 1481695787000 ms
2016-12-14 14:09:47.027 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 900 from persistence list
2016-12-14 14:09:47.027 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 900
2016-12-14 14:09:47.027 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 899 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 899
2016-12-14 14:09:47.028 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 898 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 898
2016-12-14 14:09:47.028 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 897 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 897
2016-12-14 14:09:47.028 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 895 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 895
2016-12-14 14:09:47.028 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 894 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 894
2016-12-14 14:09:47.028 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 893 from persistence list
2016-12-14 14:09:47.028 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 893
2016-12-14 14:09:47.028 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695785000 ms)
2016-12-14 14:09:47.028 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695785000 ms
2016-12-14 14:09:48.011 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695788000 ms
2016-12-14 14:09:48.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695788000 ms.0 from job set of time 1481695788000 ms
2016-12-14 14:09:48.011 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695788000 ms.0 from job set of time 1481695788000 ms
2016-12-14 14:09:48.012 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695788000 ms.1 from job set of time 1481695788000 ms
2016-12-14 14:09:48.015 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:48.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 915 (union at DStream.scala:617)
2016-12-14 14:09:48.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 102 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:48.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 204 (take at LogStream.java:127)
2016-12-14 14:09:48.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 203)
2016-12-14 14:09:48.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 203)
2016-12-14 14:09:48.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 203 (UnionRDD[915] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:48.017 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_203 stored as values in memory (estimated size 4.2 KB, free 342.9 KB)
2016-12-14 14:09:48.018 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_203_piece0 stored as bytes in memory (estimated size 2.4 KB, free 345.4 KB)
2016-12-14 14:09:48.019 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_203_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:48.019 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 203 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:48.019 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 203 (UnionRDD[915] at union at DStream.scala:617)
2016-12-14 14:09:48.019 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 203.0 with 1 tasks
2016-12-14 14:09:48.020 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 203.0 (TID 203, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:48.020 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 203.0 (TID 203)
2016-12-14 14:09:48.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 203.0 (TID 203). 1159 bytes result sent to driver
2016-12-14 14:09:48.023 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 203.0 (TID 203) in 3 ms on localhost (1/1)
2016-12-14 14:09:48.023 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 203.0, whose tasks have all completed, from pool 
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 203 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 204)
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:48.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 204 (MapPartitionsRDD[918] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:48.025 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_204 stored as values in memory (estimated size 3.7 KB, free 349.1 KB)
2016-12-14 14:09:48.027 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_204_piece0 stored as bytes in memory (estimated size 2.1 KB, free 351.2 KB)
2016-12-14 14:09:48.027 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_204_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:48.027 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 204 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:48.028 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[918] at count at LogStream.java:120)
2016-12-14 14:09:48.028 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 204.0 with 1 tasks
2016-12-14 14:09:48.028 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 204.0 (TID 204, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:48.028 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 204.0 (TID 204)
2016-12-14 14:09:48.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:48.029 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:48.030 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 204.0 (TID 204). 1241 bytes result sent to driver
2016-12-14 14:09:48.030 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 204.0 (TID 204) in 2 ms on localhost (1/1)
2016-12-14 14:09:48.030 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2016-12-14 14:09:48.030 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 204 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:48.030 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 102 finished: take at LogStream.java:127, took 0.015547 s
2016-12-14 14:09:48.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695788000 ms.1 from job set of time 1481695788000 ms
2016-12-14 14:09:48.035 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.035 s for time 1481695788000 ms (execution: 0.024 s)
2016-12-14 14:09:48.035 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 901 from persistence list
2016-12-14 14:09:48.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 901
2016-12-14 14:09:48.036 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[901] at createStream at LogStream.java:100 of time 1481695788000 ms
2016-12-14 14:09:48.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 909 from persistence list
2016-12-14 14:09:48.036 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 909
2016-12-14 14:09:48.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 908 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 908
2016-12-14 14:09:48.037 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 907 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 907
2016-12-14 14:09:48.037 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 906 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 906
2016-12-14 14:09:48.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 904 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 904
2016-12-14 14:09:48.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 903 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 903
2016-12-14 14:09:48.037 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 902 from persistence list
2016-12-14 14:09:48.037 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 902
2016-12-14 14:09:48.037 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695786000 ms)
2016-12-14 14:09:48.037 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695786000 ms
2016-12-14 14:09:49.008 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695789000 ms
2016-12-14 14:09:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695789000 ms.0 from job set of time 1481695789000 ms
2016-12-14 14:09:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695789000 ms.0 from job set of time 1481695789000 ms
2016-12-14 14:09:49.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695789000 ms.1 from job set of time 1481695789000 ms
2016-12-14 14:09:49.011 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 924 (union at DStream.scala:617)
2016-12-14 14:09:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 103 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 206 (take at LogStream.java:127)
2016-12-14 14:09:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 205)
2016-12-14 14:09:49.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 205)
2016-12-14 14:09:49.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 205 (UnionRDD[924] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:49.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_205 stored as values in memory (estimated size 4.2 KB, free 355.4 KB)
2016-12-14 14:09:49.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_205_piece0 stored as bytes in memory (estimated size 2.4 KB, free 357.8 KB)
2016-12-14 14:09:49.015 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_205_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:49.016 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 205 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:49.016 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 205 (UnionRDD[924] at union at DStream.scala:617)
2016-12-14 14:09:49.016 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 205.0 with 1 tasks
2016-12-14 14:09:49.018 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 205.0 (TID 205, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:49.018 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 205.0 (TID 205)
2016-12-14 14:09:49.021 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 205.0 (TID 205). 1159 bytes result sent to driver
2016-12-14 14:09:49.021 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 205.0 (TID 205) in 4 ms on localhost (1/1)
2016-12-14 14:09:49.021 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 205.0, whose tasks have all completed, from pool 
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 205 (union at DStream.scala:617) finished in 0.004 s
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 206)
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:49.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 206 (MapPartitionsRDD[927] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:49.022 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_206 stored as values in memory (estimated size 3.7 KB, free 361.5 KB)
2016-12-14 14:09:49.023 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_206_piece0 stored as bytes in memory (estimated size 2.1 KB, free 363.6 KB)
2016-12-14 14:09:49.023 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_206_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:49.023 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 206 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:49.023 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[927] at count at LogStream.java:120)
2016-12-14 14:09:49.023 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 206.0 with 1 tasks
2016-12-14 14:09:49.024 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 206.0 (TID 206, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:49.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 206.0 (TID 206)
2016-12-14 14:09:49.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:49.024 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:49.025 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 206.0 (TID 206). 1241 bytes result sent to driver
2016-12-14 14:09:49.025 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 206.0 (TID 206) in 1 ms on localhost (1/1)
2016-12-14 14:09:49.025 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2016-12-14 14:09:49.025 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 206 (take at LogStream.java:127) finished in 0.002 s
2016-12-14 14:09:49.026 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 103 finished: take at LogStream.java:127, took 0.014110 s
2016-12-14 14:09:49.031 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695789000 ms.1 from job set of time 1481695789000 ms
2016-12-14 14:09:49.032 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.031 s for time 1481695789000 ms (execution: 0.023 s)
2016-12-14 14:09:49.032 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 910 from persistence list
2016-12-14 14:09:49.033 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 910
2016-12-14 14:09:49.034 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[910] at createStream at LogStream.java:100 of time 1481695789000 ms
2016-12-14 14:09:49.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 918 from persistence list
2016-12-14 14:09:49.035 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 918
2016-12-14 14:09:49.035 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 917 from persistence list
2016-12-14 14:09:49.035 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 917
2016-12-14 14:09:49.036 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 916 from persistence list
2016-12-14 14:09:49.036 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 916
2016-12-14 14:09:49.036 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 915 from persistence list
2016-12-14 14:09:49.036 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 915
2016-12-14 14:09:49.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 913 from persistence list
2016-12-14 14:09:49.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 913
2016-12-14 14:09:49.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 912 from persistence list
2016-12-14 14:09:49.036 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 912
2016-12-14 14:09:49.036 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 911 from persistence list
2016-12-14 14:09:49.036 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 911
2016-12-14 14:09:49.036 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695787000 ms)
2016-12-14 14:09:49.036 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695787000 ms
2016-12-14 14:09:49.847 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - Invoking stop(stopGracefully=false) from shutdown hook
2016-12-14 14:09:49.852 [dispatcher-event-loop-1] INFO  o.a.s.s.scheduler.ReceiverTracker - Sent stop signal to all 1 receivers
2016-12-14 14:09:49.852 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Received stop signal
2016-12-14 14:09:49.854 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopping receiver with message: Stopped by driver: 
2016-12-14 14:09:49.874 [dispatcher-event-loop-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x158e2b957aa05b1 closed
2016-12-14 14:09:49.874 [Executor task launch worker-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down
2016-12-14 14:09:49.876 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Called receiver onStop
2016-12-14 14:09:49.876 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Deregistering receiver 0
2016-12-14 14:09:49.878 [dispatcher-event-loop-2] ERROR o.a.s.s.scheduler.ReceiverTracker - Deregistered receiver for stream 0: Stopped by driver
2016-12-14 14:09:49.879 [dispatcher-event-loop-3] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver 0
2016-12-14 14:09:49.880 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Stopping BlockGenerator
2016-12-14 14:09:50.007 [JobGenerator] INFO  o.a.s.s.scheduler.JobScheduler - Added jobs for time 1481695790000 ms
2016-12-14 14:09:50.007 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695790000 ms.0 from job set of time 1481695790000 ms
2016-12-14 14:09:50.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695790000 ms.0 from job set of time 1481695790000 ms
2016-12-14 14:09:50.008 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Starting job streaming job 1481695790000 ms.1 from job set of time 1481695790000 ms
2016-12-14 14:09:50.012 [streaming-job-executor-0] INFO  org.apache.spark.SparkContext - Starting job: take at LogStream.java:127
2016-12-14 14:09:50.012 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 933 (union at DStream.scala:617)
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 104 (take at LogStream.java:127) with 1 output partitions
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 208 (take at LogStream.java:127)
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 207)
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 207)
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 207 (UnionRDD[933] at union at DStream.scala:617), which has no missing parents
2016-12-14 14:09:50.013 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_207 stored as values in memory (estimated size 4.2 KB, free 367.8 KB)
2016-12-14 14:09:50.014 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_207_piece0 stored as bytes in memory (estimated size 2.4 KB, free 370.3 KB)
2016-12-14 14:09:50.014 [dispatcher-event-loop-0] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_207_piece0 in memory on localhost:60466 (size: 2.4 KB, free: 1140.3 MB)
2016-12-14 14:09:50.015 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 207 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:50.015 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 207 (UnionRDD[933] at union at DStream.scala:617)
2016-12-14 14:09:50.015 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 207.0 with 1 tasks
2016-12-14 14:09:50.015 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 207.0 (TID 207, localhost, partition 0,PROCESS_LOCAL, 2229 bytes)
2016-12-14 14:09:50.015 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 207.0 (TID 207)
2016-12-14 14:09:50.017 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 207.0 (TID 207). 1159 bytes result sent to driver
2016-12-14 14:09:50.017 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 207.0 (TID 207) in 2 ms on localhost (1/1)
2016-12-14 14:09:50.017 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 207.0, whose tasks have all completed, from pool 
2016-12-14 14:09:50.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 207 (union at DStream.scala:617) finished in 0.002 s
2016-12-14 14:09:50.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2016-12-14 14:09:50.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: Set(ResultStage 0)
2016-12-14 14:09:50.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 208)
2016-12-14 14:09:50.017 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
2016-12-14 14:09:50.018 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 208 (MapPartitionsRDD[936] at count at LogStream.java:120), which has no missing parents
2016-12-14 14:09:50.019 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_208 stored as values in memory (estimated size 3.7 KB, free 374.0 KB)
2016-12-14 14:09:50.020 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_208_piece0 stored as bytes in memory (estimated size 2.1 KB, free 376.1 KB)
2016-12-14 14:09:50.021 [dispatcher-event-loop-1] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_208_piece0 in memory on localhost:60466 (size: 2.1 KB, free: 1140.3 MB)
2016-12-14 14:09:50.021 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 208 from broadcast at DAGScheduler.scala:1008
2016-12-14 14:09:50.021 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 208 (MapPartitionsRDD[936] at count at LogStream.java:120)
2016-12-14 14:09:50.021 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 208.0 with 1 tasks
2016-12-14 14:09:50.022 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 208.0 (TID 208, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-12-14 14:09:50.023 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 208.0 (TID 208)
2016-12-14 14:09:50.023 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2016-12-14 14:09:50.023 [Executor task launch worker-1] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2016-12-14 14:09:50.024 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 208.0 (TID 208). 1241 bytes result sent to driver
2016-12-14 14:09:50.024 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 208.0 (TID 208) in 2 ms on localhost (1/1)
2016-12-14 14:09:50.024 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2016-12-14 14:09:50.024 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 208 (take at LogStream.java:127) finished in 0.003 s
2016-12-14 14:09:50.024 [streaming-job-executor-0] INFO  o.a.spark.scheduler.DAGScheduler - Job 104 finished: take at LogStream.java:127, took 0.012459 s
2016-12-14 14:09:50.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Finished job streaming job 1481695790000 ms.1 from job set of time 1481695790000 ms
2016-12-14 14:09:50.030 [JobScheduler] INFO  o.a.s.s.scheduler.JobScheduler - Total delay: 0.030 s for time 1481695790000 ms (execution: 0.023 s)
2016-12-14 14:09:50.030 [JobGenerator] INFO  org.apache.spark.rdd.BlockRDD - Removing RDD 919 from persistence list
2016-12-14 14:09:50.030 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 919
2016-12-14 14:09:50.031 [JobGenerator] INFO  o.a.s.s.kafka.KafkaInputDStream - Removing blocks of RDD BlockRDD[919] at createStream at LogStream.java:100 of time 1481695790000 ms
2016-12-14 14:09:50.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 927 from persistence list
2016-12-14 14:09:50.031 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 927
2016-12-14 14:09:50.031 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 926 from persistence list
2016-12-14 14:09:50.031 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 926
2016-12-14 14:09:50.031 [JobGenerator] INFO  org.apache.spark.rdd.ShuffledRDD - Removing RDD 925 from persistence list
2016-12-14 14:09:50.032 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 925
2016-12-14 14:09:50.032 [JobGenerator] INFO  org.apache.spark.rdd.UnionRDD - Removing RDD 924 from persistence list
2016-12-14 14:09:50.032 [block-manager-slave-async-thread-pool-4] INFO  o.apache.spark.storage.BlockManager - Removing RDD 924
2016-12-14 14:09:50.032 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 922 from persistence list
2016-12-14 14:09:50.033 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 921 from persistence list
2016-12-14 14:09:50.033 [block-manager-slave-async-thread-pool-0] INFO  o.apache.spark.storage.BlockManager - Removing RDD 922
2016-12-14 14:09:50.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 921
2016-12-14 14:09:50.034 [JobGenerator] INFO  o.apache.spark.rdd.MapPartitionsRDD - Removing RDD 920 from persistence list
2016-12-14 14:09:50.034 [block-manager-slave-async-thread-pool-3] INFO  o.apache.spark.storage.BlockManager - Removing RDD 920
2016-12-14 14:09:50.034 [JobGenerator] INFO  o.a.s.s.s.ReceivedBlockTracker - Deleting batches ArrayBuffer(1481695788000 ms)
2016-12-14 14:09:50.035 [JobGenerator] INFO  o.a.s.s.scheduler.InputInfoTracker - remove old batch metadata: 1481695788000 ms
2016-12-14 14:09:50.201 [dispatcher-event-loop-3] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for BlockGenerator after time 1481695790200
2016-12-14 14:09:50.202 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Waiting for block pushing thread to terminate
2016-12-14 14:09:50.214 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Pushing out the last 0 blocks
2016-12-14 14:09:50.214 [Thread-23] INFO  o.a.s.s.receiver.BlockGenerator - Stopped block pushing thread
2016-12-14 14:09:50.215 [dispatcher-event-loop-3] INFO  o.a.s.s.receiver.BlockGenerator - Stopped BlockGenerator
2016-12-14 14:09:50.215 [Executor task launch worker-0] INFO  o.a.s.s.r.ReceiverSupervisorImpl - Stopped receiver without error
2016-12-14 14:09:50.216 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 915 bytes result sent to driver
2016-12-14 14:09:50.217 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 103560 ms on localhost (1/1)
2016-12-14 14:09:50.217 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (start at LogStream.java:135) finished in 103.574 s
2016-12-14 14:09:50.217 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-12-14 14:09:50.218 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - All of the receivers have deregistered successfully
2016-12-14 14:09:50.219 [pool-2-thread-1] INFO  o.a.s.s.scheduler.ReceiverTracker - ReceiverTracker stopped
2016-12-14 14:09:50.220 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopping JobGenerator immediately
2016-12-14 14:09:50.221 [pool-2-thread-1] INFO  o.a.s.streaming.util.RecurringTimer - Stopped timer for JobGenerator after time 1481695790000
2016-12-14 14:09:50.223 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobGenerator - Stopped JobGenerator
2016-12-14 14:09:50.226 [pool-2-thread-1] INFO  o.a.s.s.scheduler.JobScheduler - Stopped JobScheduler
2016-12-14 14:09:50.232 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming,null}
2016-12-14 14:09:50.233 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch,null}
2016-12-14 14:09:50.236 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static/streaming,null}
2016-12-14 14:09:50.237 [pool-2-thread-1] INFO  o.a.spark.streaming.StreamingContext - StreamingContext stopped successfully
2016-12-14 14:09:50.238 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2016-12-14 14:09:50.253 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/batch/json,null}
2016-12-14 14:09:50.254 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/streaming/json,null}
2016-12-14 14:09:50.254 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-12-14 14:09:50.255 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-12-14 14:09:50.256 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-12-14 14:09:50.256 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
2016-12-14 14:09:50.257 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-12-14 14:09:50.258 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-12-14 14:09:50.258 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-12-14 14:09:50.258 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-12-14 14:09:50.259 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-12-14 14:09:50.259 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-12-14 14:09:50.260 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-12-14 14:09:50.260 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-12-14 14:09:50.260 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-12-14 14:09:50.261 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-12-14 14:09:50.262 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-12-14 14:09:50.262 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-12-14 14:09:50.262 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-12-14 14:09:50.262 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-12-14 14:09:50.262 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-12-14 14:09:50.263 [pool-2-thread-1] INFO  o.s.j.server.handler.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-12-14 14:09:50.315 [pool-2-thread-1] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.109.104:4040
2016-12-14 14:09:50.329 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2016-12-14 14:09:50.360 [pool-2-thread-1] INFO  org.apache.spark.storage.MemoryStore - MemoryStore cleared
2016-12-14 14:09:50.362 [pool-2-thread-1] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2016-12-14 14:09:50.363 [pool-2-thread-1] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2016-12-14 14:09:50.366 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2016-12-14 14:09:50.370 [pool-2-thread-1] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2016-12-14 14:09:50.375 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:09:50.377 [sparkDriverActorSystem-akka.actor.default-dispatcher-15] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Shutting down remote daemon.
2016-12-14 14:09:50.378 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-79abb043-89be-4865-ad0d-f67443052c7a
2016-12-14 14:09:50.379 [sparkDriverActorSystem-akka.actor.default-dispatcher-15] INFO  a.r.RemoteActorRefProvider$RemotingTerminator - Remote daemon shut down; proceeding with flushing remote transports.
2016-12-14 14:28:22.020 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:28:22.563 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:28:22.607 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:28:23.238 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-12-14 14:28:23.505 [main] INFO  o.a.h.h.z.RecoverableZooKeeper - Process identifier=hconnection-0x4ef37659 connecting to ZooKeeper ensemble=hdp1:2181
2016-12-14 14:28:23.512 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2016-12-14 14:28:23.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=192.168.109.104
2016-12-14 14:28:23.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
2016-12-14 14:28:23.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2016-12-14 14:28:23.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre
2016-12-14 14:28:23.513 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/lib/tools.jar:/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo/target/classes:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar:/Users/zhangyoulei/.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-api/1.7.6/slf4j-api-1.7.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka_2.10/0.10.0.2.5.0.0-1245/kafka_2.10-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/101tec/zkclient/0.8/zkclient-0.8.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/slf4j-log4j12/1.7.21/slf4j-log4j12-1.7.21.jar:/Users/zhangyoulei/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/kafka/kafka-clients/0.10.0.2.5.0.0-1245/kafka-clients-0.10.0.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/Users/zhangyoulei/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/Users/zhangyoulei/.m2/repository/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar:/Users/zhangyoulei/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/Users/zhangyoulei/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2.2.5.0.0-1245/spark-streaming_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2.2.5.0.0-1245/spark-core_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/zhangyoulei/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/zhangyoulei/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/zhangyoulei/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-launcher_2.10/1.6.2.2.5.0.0-1245/spark-launcher_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-common_2.10/1.6.2.2.5.0.0-1245/spark-network-common_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-network-shuffle_2.10/1.6.2.2.5.0.0-1245/spark-network-shuffle_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.4.4/jackson-annotations-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-unsafe_2.10/1.6.2.2.5.0.0-1245/spark-unsafe_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/net/java/dev/jets3t/jets3t/0.9.3/jets3t-0.9.3.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpcore/4.3.3/httpcore-4.3.3.jar:/Users/zhangyoulei/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/zhangyoulei/.m2/repository/mx4j/mx4j/3.0.2/mx4j-3.0.2.jar:/Users/zhangyoulei/.m2/repository/javax/mail/mail/1.4.7/mail-1.4.7.jar:/Users/zhangyoulei/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar:/Users/zhangyoulei/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.0/java-xmlbuilder-1.0.jar:/Users/zhangyoulei/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/zhangyoulei/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/zhangyoulei/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jul-to-slf4j/1.7.10/jul-to-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.10/jcl-over-slf4j-1.7.10.jar:/Users/zhangyoulei/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/zhangyoulei/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/Users/zhangyoulei/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-remote_2.10/2.3.11/akka-remote_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-actor_2.10/2.3.11/akka-actor_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/zhangyoulei/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/zhangyoulei/.m2/repository/com/typesafe/akka/akka-slf4j_2.10/2.3.11/akka-slf4j_2.10-2.3.11.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/mesos/mesos/0.21.1/mesos-0.21.1-shaded-protobuf.jar:/Users/zhangyoulei/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.2/metrics-jvm-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.2/metrics-json-3.1.2.jar:/Users/zhangyoulei/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.2/metrics-graphite-3.1.2.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.4.4/jackson-databind-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.4.4/jackson-core-2.4.4.jar:/Users/zhangyoulei/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.10/2.4.4/jackson-module-scala_2.10-2.4.4.jar:/Users/zhangyoulei/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/zhangyoulei/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/zhangyoulei/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/zhangyoulei/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-client/0.8.2/tachyon-client-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-hdfs/0.8.2/tachyon-underfs-hdfs-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-s3/0.8.2/tachyon-underfs-s3-0.8.2.jar:/Users/zhangyoulei/.m2/repository/org/tachyonproject/tachyon-underfs-local/0.8.2/tachyon-underfs-local-0.8.2.jar:/Users/zhangyoulei/.m2/repository/net/razorvine/pyrolite/4.9/pyrolite-4.9.jar:/Users/zhangyoulei/.m2/repository/net/sf/py4j/py4j/0.9/py4j-0.9.jar:/Users/zhangyoulei/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2.2.5.0.0-1245/spark-streaming-kafka_2.10-1.6.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-client/1.1.2.2.5.0.0-1245/hbase-client-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-annotations/1.1.2.2.5.0.0-1245/hbase-annotations-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-protocol/1.1.2.2.5.0.0-1245/hbase-protocol-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/Users/zhangyoulei/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/zhangyoulei/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/zhangyoulei/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/Users/zhangyoulei/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/Users/zhangyoulei/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/zhangyoulei/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/zhangyoulei/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/Users/zhangyoulei/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.3.2.5.0.0-1245/hadoop-auth-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/zhangyoulei/.m2/repository/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/Users/zhangyoulei/.m2/repository/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/Users/zhangyoulei/.m2/repository/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-common/2.7.3.2.5.0.0-1245/hadoop-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.3.2.5.0.0-1245/hadoop-annotations-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/zhangyoulei/.m2/repository/com/microsoft/windowsazure/storage/microsoft-windowsazure-storage-sdk/0.6.0/microsoft-windowsazure-storage-sdk-0.6.0.jar:/Users/zhangyoulei/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/zhangyoulei/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/zhangyoulei/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/Users/zhangyoulei/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/zhangyoulei/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/zhangyoulei/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/zhangyoulei/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-core-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.3.2.5.0.0-1245/hadoop-yarn-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/zhangyoulei/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/zhangyoulei/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-server/1.1.2.2.5.0.0-1245/hbase-server-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-procedure/1.1.2.2.5.0.0-1245/hbase-procedure-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-common/1.1.2.2.5.0.0-1245/hbase-common-1.1.2.2.5.0.0-1245-tests.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.1.2.2.5.0.0-1245/hbase-prefix-tree-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-distcp/2.7.3.2.5.0.0-1245/hadoop-distcp-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.1.2.2.5.0.0-1245/hbase-hadoop-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.1.2.2.5.0.0-1245/hbase-hadoop2-compat-1.1.2.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/zhangyoulei/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/Users/zhangyoulei/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/zhangyoulei/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/zhangyoulei/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/zhangyoulei/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty/6.1.26.hwx/jetty-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.hwx/jetty-util-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.hwx/jetty-sslengine-6.1.26.hwx.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/zhangyoulei/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/zhangyoulei/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/zhangyoulei/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/zhangyoulei/.m2/repository/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar:/Users/zhangyoulei/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-client/2.7.3.2.5.0.0-1245/hadoop-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-app-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.3.2.5.0.0-1245/hadoop-yarn-client-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.3.2.5.0.0-1245/hadoop-yarn-server-common-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-registry/2.7.3.2.5.0.0-1245/hadoop-yarn-registry-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-shuffle-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.3.2.5.0.0-1245/hadoop-yarn-api-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.3.2.5.0.0-1245/hadoop-mapreduce-client-jobclient-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.3.2.5.0.0-1245/hadoop-hdfs-2.7.3.2.5.0.0-1245.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/Users/zhangyoulei/.m2/repository/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/Users/zhangyoulei/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/zhangyoulei/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/Users/zhangyoulei/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/Users/zhangyoulei/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/zhangyoulei/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.11.3
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=zhangyoulei
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/zhangyoulei
2016-12-14 14:28:23.514 [main] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/zhangyoulei/Documents/workspace/kafka_spark_hbase_demo
2016-12-14 14:28:23.515 [main] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=hdp1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@29e495ff
2016-12-14 14:28:23.546 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server hdp1/10.0.1.101:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-14 14:28:23.567 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to hdp1/10.0.1.101:2181, initiating session
2016-12-14 14:28:23.583 [main-SendThread(hdp1:2181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server hdp1/10.0.1.101:2181, sessionid = 0x158e2b957aa05b2, negotiated timeout = 40000
2016-12-14 14:28:23.668 [main] WARN  o.a.h.h.io.util.HeapMemorySizeUtil - hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size
2016-12-14 14:28:24.942 [main] INFO  org.mortbay.log - Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2016-12-14 14:28:24.951 [main] INFO  o.a.h.s.a.s.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-14 14:28:24.957 [main] WARN  o.apache.hadoop.http.HttpRequestLog - Jetty request log can only be enabled using Log4j
2016-12-14 14:28:24.961 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-14 14:28:24.964 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recsys
2016-12-14 14:28:24.964 [main] INFO  org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-14 14:28:24.964 [main] INFO  o.a.h.s.HttpCrossOriginFilterInitializer - CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2016-12-14 14:28:24.977 [main] INFO  org.apache.hadoop.http.HttpServer2 - Jetty bound to port 8089
2016-12-14 14:28:24.977 [main] INFO  org.mortbay.log - jetty-6.1.26.hwx
2016-12-14 14:28:25.559 [main] INFO  org.mortbay.log - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8089
2016-12-14 14:28:25.560 [main] INFO  com.wankun.logcount.spark.LogStream - ------open hbase----------
2016-12-14 14:28:25.932 [main] INFO  org.apache.spark.SparkContext - Running Spark version 1.6.2
2016-12-14 14:28:26.025 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: zhangyoulei
2016-12-14 14:28:26.025 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: zhangyoulei
2016-12-14 14:28:26.026 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zhangyoulei); users with modify permissions: Set(zhangyoulei)
2016-12-14 14:28:26.798 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61098.
2016-12-14 14:28:27.451 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2016-12-14 14:28:27.524 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2016-12-14 14:28:27.710 [sparkDriverActorSystem-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.109.104:61099]
2016-12-14 14:28:27.719 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriverActorSystem' on port 61099.
2016-12-14 14:28:27.739 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2016-12-14 14:28:27.762 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2016-12-14 14:28:27.786 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/blockmgr-ac188c86-16dc-4f40-ada9-46ac84ee91d6
2016-12-14 14:28:27.798 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 1140.4 MB
2016-12-14 14:28:27.871 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2016-12-14 14:28:28.101 [main] INFO  o.spark-project.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2016-12-14 14:28:28.157 [main] INFO  o.s.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2016-12-14 14:28:28.157 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2016-12-14 14:28:28.160 [main] INFO  org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.109.104:4040
2016-12-14 14:28:28.318 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2016-12-14 14:28:28.354 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61100.
2016-12-14 14:28:28.355 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on 61100
2016-12-14 14:28:28.357 [main] INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
2016-12-14 14:28:28.362 [dispatcher-event-loop-2] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager localhost:61100 with 1140.4 MB RAM, BlockManagerId(driver, localhost, 61100)
2016-12-14 14:28:28.364 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
2016-12-14 14:28:28.561 [pool-2-thread-1] INFO  o.a.spark.storage.DiskBlockManager - Shutdown hook called
2016-12-14 14:28:28.567 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2016-12-14 14:28:28.569 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-6b25e44f-a452-4f3f-b1de-cbe21b3a82b7
2016-12-14 14:28:28.569 [pool-2-thread-1] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/58/fltns16j2_qbm_xqwqk05hh80000gn/T/spark-6b25e44f-a452-4f3f-b1de-cbe21b3a82b7/userFiles-9ea10358-6309-4bd6-af3c-554674dcd2f4
